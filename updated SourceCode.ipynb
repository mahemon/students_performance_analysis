{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd \n",
    "\n",
    "# Numpy\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ipython tool for figsize\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Imputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "# FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Function Transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# ROC AUC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "#from sklearn import impute\n",
    "from sklearn import metrics\n",
    "from scipy.stats import chisquare\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 as sklearn_chi2\n",
    "\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('E:\\(survey)Worksheet 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>nationality</th>\n",
       "      <th>placeOfBirth</th>\n",
       "      <th>department</th>\n",
       "      <th>batch</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>lastSemesterGradePoint</th>\n",
       "      <th>questionsAskInTheClassroom</th>\n",
       "      <th>questionsAskedInTheClassroom</th>\n",
       "      <th>goThroughCourseMaterials</th>\n",
       "      <th>goThroughCourseMaterial</th>\n",
       "      <th>meetWithAcademicAdviser</th>\n",
       "      <th>groupStudyHours</th>\n",
       "      <th>studentAbsenceDays</th>\n",
       "      <th>parentsSatisfaction</th>\n",
       "      <th>educationStatusofParents</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>SWE</td>\n",
       "      <td>16</td>\n",
       "      <td>Summer</td>\n",
       "      <td>A</td>\n",
       "      <td>3.66</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>L</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Above HSC</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Munshiganj</td>\n",
       "      <td>SWE</td>\n",
       "      <td>17</td>\n",
       "      <td>Summer</td>\n",
       "      <td>B</td>\n",
       "      <td>2.25</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Above HSC</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Cumilla</td>\n",
       "      <td>SWE</td>\n",
       "      <td>17</td>\n",
       "      <td>Spring</td>\n",
       "      <td>A</td>\n",
       "      <td>3.25</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>HSC</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>SWE</td>\n",
       "      <td>18</td>\n",
       "      <td>Summer</td>\n",
       "      <td>B</td>\n",
       "      <td>3.50</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>Above HSC</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender nationality placeOfBirth department  batch semester section  \\\n",
       "0      M  Bangladesh        Dhaka        SWE     16   Summer       A   \n",
       "1      M  Bangladesh   Munshiganj        SWE     17   Summer       B   \n",
       "2      M  Bangladesh      Cumilla        SWE     17   Spring       A   \n",
       "3      F  Bangladesh        Dhaka        SWE     18   Summer       B   \n",
       "\n",
       "   lastSemesterGradePoint questionsAskInTheClassroom  \\\n",
       "0                    3.66                          M   \n",
       "1                    2.25                          M   \n",
       "2                    3.25                          M   \n",
       "3                    3.50                          M   \n",
       "\n",
       "   questionsAskedInTheClassroom  goThroughCourseMaterials  \\\n",
       "0                             10                        L   \n",
       "1                              8                        M   \n",
       "2                              5                        M   \n",
       "3                              2                        M   \n",
       "\n",
       "   goThroughCourseMaterial  meetWithAcademicAdviser  groupStudyHours  \\\n",
       "0                       24                        3               10   \n",
       "1                      118                        4               30   \n",
       "2                       12                        2                4   \n",
       "3                       11                        2                3   \n",
       "\n",
       "   studentAbsenceDays parentsSatisfaction educationStatusofParents Class  \n",
       "0                   5                 Yes                Above HSC     M  \n",
       "1                  19                 Yes                Above HSC     L  \n",
       "2                   2                 Yes                      HSC     L  \n",
       "3                   7                  No                Above HSC     M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Value Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print (data_frame.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2195dd30748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_frame[\"Class\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>nationality</th>\n",
       "      <th>placeOfBirth</th>\n",
       "      <th>department</th>\n",
       "      <th>batch</th>\n",
       "      <th>semester</th>\n",
       "      <th>section</th>\n",
       "      <th>lastSemesterGradePoint</th>\n",
       "      <th>questionsAskInTheClassroom</th>\n",
       "      <th>questionsAskedInTheClassroom</th>\n",
       "      <th>goThroughCourseMaterials</th>\n",
       "      <th>goThroughCourseMaterial</th>\n",
       "      <th>meetWithAcademicAdviser</th>\n",
       "      <th>groupStudyHours</th>\n",
       "      <th>studentAbsenceDays</th>\n",
       "      <th>parentsSatisfaction</th>\n",
       "      <th>educationStatusofParents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>SWE</td>\n",
       "      <td>16</td>\n",
       "      <td>Summer</td>\n",
       "      <td>A</td>\n",
       "      <td>3.66</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>L</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Above HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Munshiganj</td>\n",
       "      <td>SWE</td>\n",
       "      <td>17</td>\n",
       "      <td>Summer</td>\n",
       "      <td>B</td>\n",
       "      <td>2.25</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Above HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Cumilla</td>\n",
       "      <td>SWE</td>\n",
       "      <td>17</td>\n",
       "      <td>Spring</td>\n",
       "      <td>A</td>\n",
       "      <td>3.25</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>SWE</td>\n",
       "      <td>18</td>\n",
       "      <td>Summer</td>\n",
       "      <td>B</td>\n",
       "      <td>3.50</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>Above HSC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender nationality placeOfBirth department  batch semester section  \\\n",
       "0      M  Bangladesh        Dhaka        SWE     16   Summer       A   \n",
       "1      M  Bangladesh   Munshiganj        SWE     17   Summer       B   \n",
       "2      M  Bangladesh      Cumilla        SWE     17   Spring       A   \n",
       "3      F  Bangladesh        Dhaka        SWE     18   Summer       B   \n",
       "\n",
       "   lastSemesterGradePoint questionsAskInTheClassroom  \\\n",
       "0                    3.66                          M   \n",
       "1                    2.25                          M   \n",
       "2                    3.25                          M   \n",
       "3                    3.50                          M   \n",
       "\n",
       "   questionsAskedInTheClassroom  goThroughCourseMaterials  \\\n",
       "0                             10                        L   \n",
       "1                              8                        M   \n",
       "2                              5                        M   \n",
       "3                              2                        M   \n",
       "\n",
       "   goThroughCourseMaterial  meetWithAcademicAdviser  groupStudyHours  \\\n",
       "0                       24                        3               10   \n",
       "1                      118                        4               30   \n",
       "2                       12                        2                4   \n",
       "3                       11                        2                3   \n",
       "\n",
       "   studentAbsenceDays parentsSatisfaction educationStatusofParents  \n",
       "0                   5                 Yes                Above HSC  \n",
       "1                  19                 Yes                Above HSC  \n",
       "2                   2                 Yes                      HSC  \n",
       "3                   7                  No                Above HSC  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X and y\n",
    "Without_class_data_frame = data_frame.drop(columns=['Class'])\n",
    "Without_class_data_frame.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>lastSemesterGradePoint</th>\n",
       "      <th>questionsAskedInTheClassroom</th>\n",
       "      <th>goThroughCourseMaterial</th>\n",
       "      <th>meetWithAcademicAdviser</th>\n",
       "      <th>groupStudyHours</th>\n",
       "      <th>studentAbsenceDays</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>nationality_Bangladesh</th>\n",
       "      <th>...</th>\n",
       "      <th>questionsAskInTheClassroom_M</th>\n",
       "      <th>goThroughCourseMaterials_H</th>\n",
       "      <th>goThroughCourseMaterials_L</th>\n",
       "      <th>goThroughCourseMaterials_M</th>\n",
       "      <th>parentsSatisfaction_No</th>\n",
       "      <th>parentsSatisfaction_Yes</th>\n",
       "      <th>parentsSatisfaction_Yes</th>\n",
       "      <th>educationStatusofParents_Above HSC</th>\n",
       "      <th>educationStatusofParents_HSC</th>\n",
       "      <th>educationStatusofParents_SSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3.66</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch  lastSemesterGradePoint  questionsAskedInTheClassroom   \\\n",
       "0     16                    3.66                             10   \n",
       "1     17                    2.25                              8   \n",
       "\n",
       "   goThroughCourseMaterial  meetWithAcademicAdviser  groupStudyHours  \\\n",
       "0                       24                        3               10   \n",
       "1                      118                        4               30   \n",
       "\n",
       "   studentAbsenceDays  gender_F  gender_M  nationality_Bangladesh  ...  \\\n",
       "0                   5         0         1                       1  ...   \n",
       "1                  19         0         1                       1  ...   \n",
       "\n",
       "   questionsAskInTheClassroom_M  goThroughCourseMaterials_H  \\\n",
       "0                             1                           0   \n",
       "1                             1                           0   \n",
       "\n",
       "   goThroughCourseMaterials_L  goThroughCourseMaterials_M  \\\n",
       "0                           1                           0   \n",
       "1                           0                           1   \n",
       "\n",
       "   parentsSatisfaction_No  parentsSatisfaction_Yes  parentsSatisfaction_Yes   \\\n",
       "0                       0                        1                         0   \n",
       "1                       0                        1                         0   \n",
       "\n",
       "   educationStatusofParents_Above HSC  educationStatusofParents_HSC  \\\n",
       "0                                   1                             0   \n",
       "1                                   1                             0   \n",
       "\n",
       "   educationStatusofParents_SSC  \n",
       "0                             0  \n",
       "1                             0  \n",
       "\n",
       "[2 rows x 158 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummies\n",
    "Without_class_data_frame = pd.get_dummies(Without_class_data_frame)\n",
    "\n",
    "# data_frame head\n",
    "Without_class_data_frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeOfBirth</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Munshiganj</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Cumilla</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  placeOfBirth Class\n",
       "0        Dhaka     M\n",
       "1   Munshiganj     L\n",
       "2      Cumilla     L"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Class_data_frame = data_frame.drop(columns=['gender','batch','nationality',\n",
    "                                            'department','semester',\n",
    "                                            'section','lastSemesterGradePoint',\n",
    "                                            'questionsAskInTheClassroom',\n",
    "                                            'questionsAskedInTheClassroom ',\n",
    "                                            'goThroughCourseMaterials',\n",
    "                                            'goThroughCourseMaterial',\n",
    "                                            'meetWithAcademicAdviser',\n",
    "                                            'groupStudyHours',\n",
    "                                            'studentAbsenceDays',\n",
    "                                            'parentsSatisfaction','educationStatusofParents'])\n",
    "Class_data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'L', 'H'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_data_frame['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "\n",
    "# Encode labels in column 'Class'. \n",
    "Class_data_frame['Class']= label_encoder.fit_transform(Class_data_frame['Class']) \n",
    "  \n",
    "Class_data_frame['Class'].unique() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      2\n",
       "1      1\n",
       "2      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_data_frame = pd.DataFrame(Class_data_frame['Class'])\n",
    "Class_data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>lastSemesterGradePoint</th>\n",
       "      <th>questionsAskedInTheClassroom</th>\n",
       "      <th>goThroughCourseMaterial</th>\n",
       "      <th>meetWithAcademicAdviser</th>\n",
       "      <th>groupStudyHours</th>\n",
       "      <th>studentAbsenceDays</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>nationality_Bangladesh</th>\n",
       "      <th>...</th>\n",
       "      <th>goThroughCourseMaterials_H</th>\n",
       "      <th>goThroughCourseMaterials_L</th>\n",
       "      <th>goThroughCourseMaterials_M</th>\n",
       "      <th>parentsSatisfaction_No</th>\n",
       "      <th>parentsSatisfaction_Yes</th>\n",
       "      <th>parentsSatisfaction_Yes</th>\n",
       "      <th>educationStatusofParents_Above HSC</th>\n",
       "      <th>educationStatusofParents_HSC</th>\n",
       "      <th>educationStatusofParents_SSC</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3.66</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.25</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch  lastSemesterGradePoint  questionsAskedInTheClassroom   \\\n",
       "0     16                    3.66                             10   \n",
       "1     17                    2.25                              8   \n",
       "2     17                    3.25                              5   \n",
       "3     18                    3.50                              2   \n",
       "\n",
       "   goThroughCourseMaterial  meetWithAcademicAdviser  groupStudyHours  \\\n",
       "0                       24                        3               10   \n",
       "1                      118                        4               30   \n",
       "2                       12                        2                4   \n",
       "3                       11                        2                3   \n",
       "\n",
       "   studentAbsenceDays  gender_F  gender_M  nationality_Bangladesh  ...  \\\n",
       "0                   5         0         1                       1  ...   \n",
       "1                  19         0         1                       1  ...   \n",
       "2                   2         0         1                       1  ...   \n",
       "3                   7         1         0                       1  ...   \n",
       "\n",
       "   goThroughCourseMaterials_H  goThroughCourseMaterials_L  \\\n",
       "0                           0                           1   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "\n",
       "   goThroughCourseMaterials_M  parentsSatisfaction_No  \\\n",
       "0                           0                       0   \n",
       "1                           1                       0   \n",
       "2                           1                       0   \n",
       "3                           1                       1   \n",
       "\n",
       "   parentsSatisfaction_Yes  parentsSatisfaction_Yes   \\\n",
       "0                        1                         0   \n",
       "1                        1                         0   \n",
       "2                        1                         0   \n",
       "3                        0                         0   \n",
       "\n",
       "   educationStatusofParents_Above HSC  educationStatusofParents_HSC  \\\n",
       "0                                   1                             0   \n",
       "1                                   1                             0   \n",
       "2                                   0                             1   \n",
       "3                                   1                             0   \n",
       "\n",
       "   educationStatusofParents_SSC  Class  \n",
       "0                             0      2  \n",
       "1                             0      1  \n",
       "2                             0      1  \n",
       "3                             0      2  \n",
       "\n",
       "[4 rows x 159 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_data_frame = pd.concat([Without_class_data_frame, Class_data_frame], axis = 1)\n",
    "final_data_frame.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-relation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>lastSemesterGradePoint</th>\n",
       "      <th>questionsAskedInTheClassroom</th>\n",
       "      <th>goThroughCourseMaterial</th>\n",
       "      <th>meetWithAcademicAdviser</th>\n",
       "      <th>groupStudyHours</th>\n",
       "      <th>studentAbsenceDays</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>nationality_Bangladesh</th>\n",
       "      <th>...</th>\n",
       "      <th>goThroughCourseMaterials_H</th>\n",
       "      <th>goThroughCourseMaterials_L</th>\n",
       "      <th>goThroughCourseMaterials_M</th>\n",
       "      <th>parentsSatisfaction_No</th>\n",
       "      <th>parentsSatisfaction_Yes</th>\n",
       "      <th>parentsSatisfaction_Yes</th>\n",
       "      <th>educationStatusofParents_Above HSC</th>\n",
       "      <th>educationStatusofParents_HSC</th>\n",
       "      <th>educationStatusofParents_SSC</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>batch</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>0.092020</td>\n",
       "      <td>0.052573</td>\n",
       "      <td>-0.106342</td>\n",
       "      <td>0.013168</td>\n",
       "      <td>-0.144744</td>\n",
       "      <td>-0.023370</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.169137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048073</td>\n",
       "      <td>-0.006264</td>\n",
       "      <td>0.041619</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>-0.033395</td>\n",
       "      <td>-0.014521</td>\n",
       "      <td>-0.019456</td>\n",
       "      <td>-0.025609</td>\n",
       "      <td>0.056574</td>\n",
       "      <td>0.096536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lastSemesterGradePoint</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151437</td>\n",
       "      <td>0.072438</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>-0.031197</td>\n",
       "      <td>-0.017614</td>\n",
       "      <td>0.017614</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173663</td>\n",
       "      <td>-0.060540</td>\n",
       "      <td>-0.088292</td>\n",
       "      <td>-0.047669</td>\n",
       "      <td>0.044179</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.042449</td>\n",
       "      <td>-0.068720</td>\n",
       "      <td>0.021865</td>\n",
       "      <td>-0.025954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>questionsAskedInTheClassroom</td>\n",
       "      <td>0.092020</td>\n",
       "      <td>0.151437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256593</td>\n",
       "      <td>0.113385</td>\n",
       "      <td>0.133798</td>\n",
       "      <td>-0.019366</td>\n",
       "      <td>-0.118999</td>\n",
       "      <td>0.118999</td>\n",
       "      <td>0.071379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109463</td>\n",
       "      <td>-0.143077</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>-0.048155</td>\n",
       "      <td>0.033125</td>\n",
       "      <td>0.063243</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>-0.068904</td>\n",
       "      <td>0.034425</td>\n",
       "      <td>-0.047580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>goThroughCourseMaterial</td>\n",
       "      <td>0.052573</td>\n",
       "      <td>0.072438</td>\n",
       "      <td>0.256593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085755</td>\n",
       "      <td>0.497176</td>\n",
       "      <td>0.022326</td>\n",
       "      <td>-0.091188</td>\n",
       "      <td>0.091188</td>\n",
       "      <td>0.052621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198691</td>\n",
       "      <td>-0.149327</td>\n",
       "      <td>-0.041279</td>\n",
       "      <td>-0.143110</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>-0.041016</td>\n",
       "      <td>-0.021281</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>0.081551</td>\n",
       "      <td>-0.026018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meetWithAcademicAdviser</td>\n",
       "      <td>-0.106342</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.113385</td>\n",
       "      <td>0.085755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>0.044956</td>\n",
       "      <td>0.033776</td>\n",
       "      <td>-0.033776</td>\n",
       "      <td>-0.063530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>-0.077161</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>-0.080952</td>\n",
       "      <td>0.074763</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>-0.043028</td>\n",
       "      <td>0.045056</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>-0.017504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>parentsSatisfaction_Yes</td>\n",
       "      <td>-0.014521</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.063243</td>\n",
       "      <td>-0.041016</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>-0.057690</td>\n",
       "      <td>0.032785</td>\n",
       "      <td>-0.018347</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>-0.105306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025189</td>\n",
       "      <td>-0.034715</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>-0.054797</td>\n",
       "      <td>-0.173226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011718</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>-0.039667</td>\n",
       "      <td>0.007507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>educationStatusofParents_Above HSC</td>\n",
       "      <td>-0.019456</td>\n",
       "      <td>0.042449</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>-0.021281</td>\n",
       "      <td>-0.043028</td>\n",
       "      <td>-0.044659</td>\n",
       "      <td>0.035259</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>-0.013646</td>\n",
       "      <td>0.105010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038321</td>\n",
       "      <td>-0.044335</td>\n",
       "      <td>0.062530</td>\n",
       "      <td>0.018420</td>\n",
       "      <td>-0.015505</td>\n",
       "      <td>-0.011718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.701025</td>\n",
       "      <td>-0.555301</td>\n",
       "      <td>-0.106974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>educationStatusofParents_HSC</td>\n",
       "      <td>-0.025609</td>\n",
       "      <td>-0.068720</td>\n",
       "      <td>-0.068904</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>0.045056</td>\n",
       "      <td>-0.040046</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.062824</td>\n",
       "      <td>-0.062824</td>\n",
       "      <td>-0.092514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022527</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>-0.089600</td>\n",
       "      <td>0.045501</td>\n",
       "      <td>-0.055746</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>-0.701025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.203800</td>\n",
       "      <td>0.073519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>educationStatusofParents_SSC</td>\n",
       "      <td>0.056574</td>\n",
       "      <td>0.021865</td>\n",
       "      <td>0.034425</td>\n",
       "      <td>0.081551</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.108010</td>\n",
       "      <td>-0.051989</td>\n",
       "      <td>-0.091999</td>\n",
       "      <td>0.091999</td>\n",
       "      <td>-0.036273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026337</td>\n",
       "      <td>-0.052120</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>-0.078349</td>\n",
       "      <td>0.086296</td>\n",
       "      <td>-0.039667</td>\n",
       "      <td>-0.555301</td>\n",
       "      <td>-0.203800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Class</td>\n",
       "      <td>0.096536</td>\n",
       "      <td>-0.025954</td>\n",
       "      <td>-0.047580</td>\n",
       "      <td>-0.026018</td>\n",
       "      <td>-0.017504</td>\n",
       "      <td>-0.038787</td>\n",
       "      <td>-0.021161</td>\n",
       "      <td>0.054566</td>\n",
       "      <td>-0.054566</td>\n",
       "      <td>0.089803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037836</td>\n",
       "      <td>-0.060157</td>\n",
       "      <td>0.073963</td>\n",
       "      <td>0.049326</td>\n",
       "      <td>-0.050359</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>-0.106974</td>\n",
       "      <td>0.073519</td>\n",
       "      <td>0.061120</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       batch  lastSemesterGradePoint  \\\n",
       "batch                               1.000000                0.054141   \n",
       "lastSemesterGradePoint              0.054141                1.000000   \n",
       "questionsAskedInTheClassroom        0.092020                0.151437   \n",
       "goThroughCourseMaterial             0.052573                0.072438   \n",
       "meetWithAcademicAdviser            -0.106342                0.000417   \n",
       "...                                      ...                     ...   \n",
       "parentsSatisfaction_Yes            -0.014521                0.012495   \n",
       "educationStatusofParents_Above HSC -0.019456                0.042449   \n",
       "educationStatusofParents_HSC       -0.025609               -0.068720   \n",
       "educationStatusofParents_SSC        0.056574                0.021865   \n",
       "Class                               0.096536               -0.025954   \n",
       "\n",
       "                                    questionsAskedInTheClassroom   \\\n",
       "batch                                                    0.092020   \n",
       "lastSemesterGradePoint                                   0.151437   \n",
       "questionsAskedInTheClassroom                             1.000000   \n",
       "goThroughCourseMaterial                                  0.256593   \n",
       "meetWithAcademicAdviser                                  0.113385   \n",
       "...                                                           ...   \n",
       "parentsSatisfaction_Yes                                  0.063243   \n",
       "educationStatusofParents_Above HSC                       0.033457   \n",
       "educationStatusofParents_HSC                            -0.068904   \n",
       "educationStatusofParents_SSC                             0.034425   \n",
       "Class                                                   -0.047580   \n",
       "\n",
       "                                    goThroughCourseMaterial  \\\n",
       "batch                                              0.052573   \n",
       "lastSemesterGradePoint                             0.072438   \n",
       "questionsAskedInTheClassroom                       0.256593   \n",
       "goThroughCourseMaterial                            1.000000   \n",
       "meetWithAcademicAdviser                            0.085755   \n",
       "...                                                     ...   \n",
       "parentsSatisfaction_Yes                           -0.041016   \n",
       "educationStatusofParents_Above HSC                -0.021281   \n",
       "educationStatusofParents_HSC                      -0.044878   \n",
       "educationStatusofParents_SSC                       0.081551   \n",
       "Class                                             -0.026018   \n",
       "\n",
       "                                    meetWithAcademicAdviser  groupStudyHours  \\\n",
       "batch                                             -0.106342         0.013168   \n",
       "lastSemesterGradePoint                             0.000417         0.001058   \n",
       "questionsAskedInTheClassroom                       0.113385         0.133798   \n",
       "goThroughCourseMaterial                            0.085755         0.497176   \n",
       "meetWithAcademicAdviser                            1.000000         0.146560   \n",
       "...                                                     ...              ...   \n",
       "parentsSatisfaction_Yes                            0.022373        -0.057690   \n",
       "educationStatusofParents_Above HSC                -0.043028        -0.044659   \n",
       "educationStatusofParents_HSC                       0.045056        -0.040046   \n",
       "educationStatusofParents_SSC                       0.006527         0.108010   \n",
       "Class                                             -0.017504        -0.038787   \n",
       "\n",
       "                                    studentAbsenceDays  gender_F  gender_M  \\\n",
       "batch                                        -0.144744 -0.023370  0.023370   \n",
       "lastSemesterGradePoint                       -0.031197 -0.017614  0.017614   \n",
       "questionsAskedInTheClassroom                 -0.019366 -0.118999  0.118999   \n",
       "goThroughCourseMaterial                       0.022326 -0.091188  0.091188   \n",
       "meetWithAcademicAdviser                       0.044956  0.033776 -0.033776   \n",
       "...                                                ...       ...       ...   \n",
       "parentsSatisfaction_Yes                       0.032785 -0.018347  0.018347   \n",
       "educationStatusofParents_Above HSC            0.035259  0.013646 -0.013646   \n",
       "educationStatusofParents_HSC                  0.003073  0.062824 -0.062824   \n",
       "educationStatusofParents_SSC                 -0.051989 -0.091999  0.091999   \n",
       "Class                                        -0.021161  0.054566 -0.054566   \n",
       "\n",
       "                                    nationality_Bangladesh  ...  \\\n",
       "batch                                             0.169137  ...   \n",
       "lastSemesterGradePoint                           -0.001175  ...   \n",
       "questionsAskedInTheClassroom                      0.071379  ...   \n",
       "goThroughCourseMaterial                           0.052621  ...   \n",
       "meetWithAcademicAdviser                          -0.063530  ...   \n",
       "...                                                    ...  ...   \n",
       "parentsSatisfaction_Yes                          -0.105306  ...   \n",
       "educationStatusofParents_Above HSC                0.105010  ...   \n",
       "educationStatusofParents_HSC                     -0.092514  ...   \n",
       "educationStatusofParents_SSC                     -0.036273  ...   \n",
       "Class                                             0.089803  ...   \n",
       "\n",
       "                                    goThroughCourseMaterials_H  \\\n",
       "batch                                                -0.048073   \n",
       "lastSemesterGradePoint                                0.173663   \n",
       "questionsAskedInTheClassroom                          0.109463   \n",
       "goThroughCourseMaterial                               0.198691   \n",
       "meetWithAcademicAdviser                               0.063355   \n",
       "...                                                        ...   \n",
       "parentsSatisfaction_Yes                               0.025189   \n",
       "educationStatusofParents_Above HSC                   -0.038321   \n",
       "educationStatusofParents_HSC                          0.022527   \n",
       "educationStatusofParents_SSC                          0.026337   \n",
       "Class                                                -0.037836   \n",
       "\n",
       "                                    goThroughCourseMaterials_L  \\\n",
       "batch                                                -0.006264   \n",
       "lastSemesterGradePoint                               -0.060540   \n",
       "questionsAskedInTheClassroom                         -0.143077   \n",
       "goThroughCourseMaterial                              -0.149327   \n",
       "meetWithAcademicAdviser                              -0.077161   \n",
       "...                                                        ...   \n",
       "parentsSatisfaction_Yes                              -0.034715   \n",
       "educationStatusofParents_Above HSC                   -0.044335   \n",
       "educationStatusofParents_HSC                          0.096883   \n",
       "educationStatusofParents_SSC                         -0.052120   \n",
       "Class                                                -0.060157   \n",
       "\n",
       "                                    goThroughCourseMaterials_M  \\\n",
       "batch                                                 0.041619   \n",
       "lastSemesterGradePoint                               -0.088292   \n",
       "questionsAskedInTheClassroom                          0.022630   \n",
       "goThroughCourseMaterial                              -0.041279   \n",
       "meetWithAcademicAdviser                               0.008883   \n",
       "...                                                        ...   \n",
       "parentsSatisfaction_Yes                               0.006544   \n",
       "educationStatusofParents_Above HSC                    0.062530   \n",
       "educationStatusofParents_HSC                         -0.089600   \n",
       "educationStatusofParents_SSC                          0.018648   \n",
       "Class                                                 0.073963   \n",
       "\n",
       "                                    parentsSatisfaction_No  \\\n",
       "batch                                             0.037203   \n",
       "lastSemesterGradePoint                           -0.047669   \n",
       "questionsAskedInTheClassroom                     -0.048155   \n",
       "goThroughCourseMaterial                          -0.143110   \n",
       "meetWithAcademicAdviser                          -0.080952   \n",
       "...                                                    ...   \n",
       "parentsSatisfaction_Yes                          -0.054797   \n",
       "educationStatusofParents_Above HSC                0.018420   \n",
       "educationStatusofParents_HSC                      0.045501   \n",
       "educationStatusofParents_SSC                     -0.078349   \n",
       "Class                                             0.049326   \n",
       "\n",
       "                                    parentsSatisfaction_Yes  \\\n",
       "batch                                             -0.033395   \n",
       "lastSemesterGradePoint                             0.044179   \n",
       "questionsAskedInTheClassroom                       0.033125   \n",
       "goThroughCourseMaterial                            0.150481   \n",
       "meetWithAcademicAdviser                            0.074763   \n",
       "...                                                     ...   \n",
       "parentsSatisfaction_Yes                           -0.173226   \n",
       "educationStatusofParents_Above HSC                -0.015505   \n",
       "educationStatusofParents_HSC                      -0.055746   \n",
       "educationStatusofParents_SSC                       0.086296   \n",
       "Class                                             -0.050359   \n",
       "\n",
       "                                    parentsSatisfaction_Yes   \\\n",
       "batch                                              -0.014521   \n",
       "lastSemesterGradePoint                              0.012495   \n",
       "questionsAskedInTheClassroom                        0.063243   \n",
       "goThroughCourseMaterial                            -0.041016   \n",
       "meetWithAcademicAdviser                             0.022373   \n",
       "...                                                      ...   \n",
       "parentsSatisfaction_Yes                             1.000000   \n",
       "educationStatusofParents_Above HSC                 -0.011718   \n",
       "educationStatusofParents_HSC                        0.047809   \n",
       "educationStatusofParents_SSC                       -0.039667   \n",
       "Class                                               0.007507   \n",
       "\n",
       "                                    educationStatusofParents_Above HSC  \\\n",
       "batch                                                        -0.019456   \n",
       "lastSemesterGradePoint                                        0.042449   \n",
       "questionsAskedInTheClassroom                                  0.033457   \n",
       "goThroughCourseMaterial                                      -0.021281   \n",
       "meetWithAcademicAdviser                                      -0.043028   \n",
       "...                                                                ...   \n",
       "parentsSatisfaction_Yes                                      -0.011718   \n",
       "educationStatusofParents_Above HSC                            1.000000   \n",
       "educationStatusofParents_HSC                                 -0.701025   \n",
       "educationStatusofParents_SSC                                 -0.555301   \n",
       "Class                                                        -0.106974   \n",
       "\n",
       "                                    educationStatusofParents_HSC  \\\n",
       "batch                                                  -0.025609   \n",
       "lastSemesterGradePoint                                 -0.068720   \n",
       "questionsAskedInTheClassroom                           -0.068904   \n",
       "goThroughCourseMaterial                                -0.044878   \n",
       "meetWithAcademicAdviser                                 0.045056   \n",
       "...                                                          ...   \n",
       "parentsSatisfaction_Yes                                 0.047809   \n",
       "educationStatusofParents_Above HSC                     -0.701025   \n",
       "educationStatusofParents_HSC                            1.000000   \n",
       "educationStatusofParents_SSC                           -0.203800   \n",
       "Class                                                   0.073519   \n",
       "\n",
       "                                    educationStatusofParents_SSC     Class  \n",
       "batch                                                   0.056574  0.096536  \n",
       "lastSemesterGradePoint                                  0.021865 -0.025954  \n",
       "questionsAskedInTheClassroom                            0.034425 -0.047580  \n",
       "goThroughCourseMaterial                                 0.081551 -0.026018  \n",
       "meetWithAcademicAdviser                                 0.006527 -0.017504  \n",
       "...                                                          ...       ...  \n",
       "parentsSatisfaction_Yes                                -0.039667  0.007507  \n",
       "educationStatusofParents_Above HSC                     -0.555301 -0.106974  \n",
       "educationStatusofParents_HSC                           -0.203800  0.073519  \n",
       "educationStatusofParents_SSC                            1.000000  0.061120  \n",
       "Class                                                   0.061120  1.000000  \n",
       "\n",
       "[159 rows x 159 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_frame.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Chi2 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>goThroughCourseMaterial</td>\n",
       "      <td>72.046270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>studentAbsenceDays</td>\n",
       "      <td>46.797132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>batch</td>\n",
       "      <td>39.071508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>questionsAskedInTheClassroom</td>\n",
       "      <td>36.148678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>groupStudyHours</td>\n",
       "      <td>9.818743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>section_D</td>\n",
       "      <td>0.059082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>placeOfBirth_Cumilla</td>\n",
       "      <td>0.030538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>placeOfBirth_Madaripur</td>\n",
       "      <td>0.029912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>questionsAskInTheClassroom_L</td>\n",
       "      <td>0.013529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Class  Chi2 Weights\n",
       "3          goThroughCourseMaterial     72.046270\n",
       "6               studentAbsenceDays     46.797132\n",
       "0                            batch     39.071508\n",
       "2    questionsAskedInTheClassroom      36.148678\n",
       "5                  groupStudyHours      9.818743\n",
       "..                             ...           ...\n",
       "131                      section_D      0.059082\n",
       "31            placeOfBirth_Cumilla      0.030538\n",
       "69          placeOfBirth_Madaripur      0.029912\n",
       "147   questionsAskInTheClassroom_L      0.013529\n",
       "158                          Class           NaN\n",
       "\n",
       "[159 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(159, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = final_data_frame.iloc[:,:-1]\n",
    "y = final_data_frame.iloc[:,-1:]   \n",
    "\n",
    "dfcolumns =pd.DataFrame(final_data_frame.columns) \n",
    "#chi2\n",
    "bestfeatures = SelectKBest(score_func=sklearn_chi2, k='all')\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Class','Chi2 Weights']\n",
    "# print(featureScores.nlargest(len(data_frame.columns),'Score'))\n",
    "\n",
    "# featureScores.plot(kind='bar', subplots=True, figsize=(20,20))\n",
    "featureScores = featureScores.sort_values(by=['Chi2 Weights'], ascending=False)\n",
    "display(featureScores)\n",
    "display(featureScores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DCL\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Chi2 Weights</th>\n",
       "      <th>Random Forest Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>batch</td>\n",
       "      <td>39.071508</td>\n",
       "      <td>0.062652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>lastSemesterGradePoint</td>\n",
       "      <td>0.100282</td>\n",
       "      <td>0.132290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>questionsAskedInTheClassroom</td>\n",
       "      <td>36.148678</td>\n",
       "      <td>0.059807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>goThroughCourseMaterial</td>\n",
       "      <td>72.046270</td>\n",
       "      <td>0.080782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>meetWithAcademicAdviser</td>\n",
       "      <td>0.356554</td>\n",
       "      <td>0.042780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>parentsSatisfaction_Yes</td>\n",
       "      <td>0.219842</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>educationStatusofParents_Above HSC</td>\n",
       "      <td>2.037117</td>\n",
       "      <td>0.010416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>educationStatusofParents_HSC</td>\n",
       "      <td>2.252037</td>\n",
       "      <td>0.009069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>educationStatusofParents_SSC</td>\n",
       "      <td>1.715610</td>\n",
       "      <td>0.007964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Class  Chi2 Weights  \\\n",
       "0                                 batch     39.071508   \n",
       "1                lastSemesterGradePoint      0.100282   \n",
       "2         questionsAskedInTheClassroom      36.148678   \n",
       "3               goThroughCourseMaterial     72.046270   \n",
       "4               meetWithAcademicAdviser      0.356554   \n",
       "..                                  ...           ...   \n",
       "154            parentsSatisfaction_Yes       0.219842   \n",
       "155  educationStatusofParents_Above HSC      2.037117   \n",
       "156        educationStatusofParents_HSC      2.252037   \n",
       "157        educationStatusofParents_SSC      1.715610   \n",
       "158                               Class           NaN   \n",
       "\n",
       "     Random Forest Importance  \n",
       "0                    0.062652  \n",
       "1                    0.132290  \n",
       "2                    0.059807  \n",
       "3                    0.080782  \n",
       "4                    0.042780  \n",
       "..                        ...  \n",
       "154                  0.001052  \n",
       "155                  0.010416  \n",
       "156                  0.009069  \n",
       "157                  0.007964  \n",
       "158                       NaN  \n",
       "\n",
       "[159 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(159, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "#print(\"Features sorted by their score:\")\n",
    "#featureScores2 = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_)), reverse=True)\n",
    "\n",
    "\n",
    "dfscoresOfRF = pd.DataFrame(rf.feature_importances_)\n",
    "dfscoresOfRF.columns = ['Random Forest Importance']\n",
    "dfscoresOfRF = dfscoresOfRF.sort_values(by='Random Forest Importance', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([featureScores, dfscoresOfRF],axis=1)\n",
    "\n",
    "#featureScores = featureScores.sort_Values(by='Score', ascending = False)\n",
    "display(featureScores)\n",
    "display(featureScores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Test Data Preparing considering top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = ['goThroughCourseMaterial','studentAbsenceDays','questionsAskedInTheClassroom ','batch', 'groupStudyHours',\n",
    "                        'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria', 'placeOfBirth_Bosasosomalia', \n",
    "                        'questionsAskInTheClassroom_H']\n",
    "                        \n",
    "predicted_class_name = ['Class']\n",
    "\n",
    "# Getting feature variable values\n",
    "X = final_data_frame[feature_column_names].values\n",
    "y = final_data_frame[predicted_class_name].values\n",
    "\n",
    "# Saving 30% for testing\n",
    "split_test_size = 0.30\n",
    "\n",
    "# Splitting using scikit-learn train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "X_test = X_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93% in training set\n",
      "1.93% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(data_frame.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_test)/len(data_frame.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train.T,y_train.T)\n",
    "\n",
    "accu = clf.score(X_test.T,y_test.T)*100\n",
    "accuracies['Decision Tree'] = accu\n",
    "\n",
    "#Predict the response for test dataset\n",
    "x_pred = clf.predict(X_train.T)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988950276243094\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train.T, x_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3974358974358974\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test.T, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GaussianNBr model object and train it with the data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model= GaussianNB()\n",
    "nb_model.fit(X_train.T, y_train.T.ravel())  # ravel() return 1-D array\n",
    "\n",
    "accu = nb_model.score(X_test.T,y_test.T)*100\n",
    "accuracies['Naive Bayes'] = accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our GaussianNB model is : 0.5442\n"
     ]
    }
   ],
   "source": [
    "# performance metrics library\n",
    "from sklearn import metrics\n",
    "\n",
    "# get current accuracy of the model\n",
    "prediction_from_trained_data = nb_model.predict(X_train.T)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_train.T, prediction_from_trained_data)\n",
    "\n",
    "print (\"Accuracy of our GaussianNB model is : {0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our GaussianNB model is: 0.5321\n"
     ]
    }
   ],
   "source": [
    "# this returns array of predicted results from test_data\n",
    "prediction_from_test_data = nb_model.predict(X_test.T)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test.T, prediction_from_test_data)\n",
    "\n",
    "print (\"Accuracy of our GaussianNB model is: {0:0.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our GaussianNB model is: 0.5321 %\n",
      "Confusion Matrix\n",
      "[[4 1]\n",
      " [0 1]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.09      0.15        45\n",
      "           0       0.50      0.03      0.06        30\n",
      "\n",
      "   micro avg       0.56      0.07      0.12        75\n",
      "   macro avg       0.54      0.06      0.11        75\n",
      "weighted avg       0.54      0.07      0.12        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy of our GaussianNB model is: {0:0.4f} %\".format(accuracy))\n",
    "\n",
    "print (\"Confusion Matrix\")\n",
    "print (\"{0}\".format(metrics.confusion_matrix(y_test.T, prediction_from_test_data, labels=[1, 0])))\n",
    "print (\"Classification Report\")\n",
    "# labels for set 1=True to upper left and 0 = False to lower right\n",
    "print (\"{0}\".format(metrics.classification_report(y_test.T, prediction_from_test_data, labels=[1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "accu = rf_model.score(X_test.T,y_test.T)*100\n",
    "accuracies['Random Forest'] = accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "rf_predict_train = rf_model.predict(X_train.T)\n",
    "\n",
    "rf_accuracy = metrics.accuracy_score(y_train.T, rf_predict_train)\n",
    "print (\"Accuracy: {0:.4f}\".format(rf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4487\n"
     ]
    }
   ],
   "source": [
    "rf_predict_test = rf_model.predict(X_test.T)\n",
    "\n",
    "rf_accuracy_testdata = metrics.accuracy_score(y_test.T, rf_predict_test)\n",
    "print (\"Accuracy: {0:.4f}\".format(rf_accuracy_testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest\n",
      "[[18  4]\n",
      " [ 9  5]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.40      0.39        45\n",
      "           0       0.22      0.17      0.19        30\n",
      "\n",
      "   micro avg       0.33      0.31      0.32        75\n",
      "   macro avg       0.30      0.28      0.29        75\n",
      "weighted avg       0.32      0.31      0.31        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Confusion Matrix for Random Forest\")\n",
    "print (\"{0}\".format(metrics.confusion_matrix(y_test.T, rf_predict_test, labels=[1, 0])))\n",
    "print (\"\")\n",
    "print (\"Classification Report\\n\")\n",
    "print (\"{0}\".format(metrics.classification_report(y_test.T, rf_predict_test, labels=[1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate learning model (k = 5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "accu = knn.score(X_test.T,y_test.T)*100\n",
    "accuracies['KNN'] = accu\n",
    "\n",
    "# predict the train response\n",
    "x_pred = knn.predict(X_train.T)\n",
    "\n",
    "# predict the test response\n",
    "y_pred = knn.predict(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.638121546961326\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train.T, x_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test.T, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4167\n",
      "Confusion Matrix for KNN Classifier\n",
      "[[15  7]\n",
      " [ 5  5]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.33      0.34        45\n",
      "           0       0.20      0.17      0.18        30\n",
      "\n",
      "   micro avg       0.29      0.27      0.28        75\n",
      "   macro avg       0.27      0.25      0.26        75\n",
      "weighted avg       0.29      0.27      0.28        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_predict_test = knn.predict(X_test.T)\n",
    "knn_accuracy_testdata = metrics.accuracy_score(y_test.T, knn_predict_test)\n",
    "print (\"Accuracy: {0:.4f}\".format(knn_accuracy_testdata))\n",
    "print (\"Confusion Matrix for KNN Classifier\")\n",
    "\n",
    "# labels for set 1=True to upper left and 0 = False to lower right\n",
    "print (\"{0}\".format(metrics.confusion_matrix(y_test.T, knn_predict_test, labels=[1, 0])))\n",
    "print (\"\")\n",
    "print (\"Classification Report\\n\")\n",
    "print (\"{0}\".format(metrics.classification_report(y_test.T, knn_predict_test, labels=[1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Test Data Preparing considering top 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = ['goThroughCourseMaterial','studentAbsenceDays','questionsAskedInTheClassroom ','batch']\n",
    "                        \n",
    "predicted_class_name = ['Class']\n",
    "\n",
    "# Getting feature variable values\n",
    "X = final_data_frame[feature_column_names].values\n",
    "y = final_data_frame[predicted_class_name].values\n",
    "\n",
    "# Saving 30% for testing\n",
    "split_test_size = 0.30\n",
    "\n",
    "# Splitting using scikit-learn train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "X_test = X_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77% in training set\n",
      "0.77% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(data_frame.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_test)/len(data_frame.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train.T,y_train.T)\n",
    "\n",
    "accu = clf.score(X_test.T,y_test.T)*100\n",
    "accuracies['Decision Tree'] = accu\n",
    "\n",
    "#Predict the response for test dataset\n",
    "x_pred = clf.predict(X_train.T)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9779005524861878\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train.T, x_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41025641025641024\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test.T, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GaussianNBr model object and train it with the data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model= GaussianNB()\n",
    "nb_model.fit(X_train.T, y_train.T.ravel())  # ravel() return 1-D array\n",
    "\n",
    "accu = nb_model.score(X_test.T,y_test.T)*100\n",
    "accuracies['Naive Bayes'] = accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our GaussianNB model is : 0.5331\n"
     ]
    }
   ],
   "source": [
    "# performance metrics library\n",
    "from sklearn import metrics\n",
    "\n",
    "# get current accuracy of the model\n",
    "prediction_from_trained_data = nb_model.predict(X_train.T)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_train.T, prediction_from_trained_data)\n",
    "\n",
    "print (\"Accuracy of our GaussianNB model is : {0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our GaussianNB model is: 0.5321\n"
     ]
    }
   ],
   "source": [
    "# this returns array of predicted results from test_data\n",
    "prediction_from_test_data = nb_model.predict(X_test.T)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test.T, prediction_from_test_data)\n",
    "\n",
    "print (\"Accuracy of our GaussianNB model is: {0:0.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "accu = rf_model.score(X_test.T,y_test.T)*100\n",
    "accuracies['Random Forest'] = accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "rf_predict_train = rf_model.predict(X_train.T)\n",
    "\n",
    "rf_accuracy = metrics.accuracy_score(y_train.T, rf_predict_train)\n",
    "print (\"Accuracy: {0:.4f}\".format(rf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4487\n"
     ]
    }
   ],
   "source": [
    "rf_predict_test = rf_model.predict(X_test.T)\n",
    "\n",
    "rf_accuracy_testdata = metrics.accuracy_score(y_test.T, rf_predict_test)\n",
    "print (\"Accuracy: {0:.4f}\".format(rf_accuracy_testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate learning model (k = 5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train.T, y_train.T.ravel())\n",
    "\n",
    "accu = knn.score(X_test.T,y_test.T)*100\n",
    "accuracies['KNN'] = accu\n",
    "\n",
    "# predict the train response\n",
    "x_pred = knn.predict(X_train.T)\n",
    "\n",
    "# predict the test response\n",
    "y_pred = knn.predict(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6602209944751382\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train.T, x_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3782051282051282\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test.T, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = ['goThroughCourseMaterial','studentAbsenceDays','questionsAskedInTheClassroom ','batch', 'groupStudyHours','department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria', 'placeOfBirth_Bosasosomalia', 'questionsAskInTheClassroom_H']\n",
    "                        \n",
    "predicted_class_name = ['Class']\n",
    "\n",
    "# Getting feature variable values\n",
    "X = final_data_frame[feature_column_names].values\n",
    "y = final_data_frame[predicted_class_name].values\n",
    "\n",
    "# Saving 30% for testing\n",
    "split_test_size = 0.30\n",
    "\n",
    "# Splitting using scikit-learn train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.88% in training set\n",
      "30.12% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(data_frame.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_test)/len(data_frame.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria', 'placeOfBirth_Bosasosomalia', 'questionsAskInTheClassroom_H']\n"
     ]
    }
   ],
   "source": [
    "print(feature_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_column_names))\n",
    "test_columns = len(feature_column_names)\n",
    "print(test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria', 'placeOfBirth_Bosasosomalia', 'questionsAskInTheClassroom_H']\n",
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 4s 11ms/sample - loss: 1.0974 - accuracy: 0.5055\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 201us/sample - loss: 1.0891 - accuracy: 0.5249\n",
      "[0.47323608 0.48363477 0.52300316]\n",
      "[0.44921514 0.46926302 0.54291135]\n",
      "[0.47086793 0.48225513 0.52490276]\n",
      "[0.44224945 0.46501678 0.54875237]\n",
      "[0.44432765 0.4663357  0.54694754]\n",
      "[0.47179526 0.4828348  0.524121  ]\n",
      "[0.46097746 0.47630775 0.53315574]\n",
      "[0.43774375 0.4623318  0.5524378 ]\n",
      "[0.46400678 0.47816166 0.53059953]\n",
      "[0.45587808 0.47330436 0.5373218 ]\n",
      "[0.46373457 0.47798648 0.5308596 ]\n",
      "[0.46863508 0.48087487 0.5268162 ]\n",
      "[0.46920905 0.48123115 0.5263259 ]\n",
      "[0.4687515  0.48098472 0.52667665]\n",
      "[0.46681127 0.47981843 0.52829194]\n",
      "[0.4771921  0.4860415  0.51967466]\n",
      "[0.42981988 0.4574207  0.5592094 ]\n",
      "[0.451152   0.47039548 0.54133993]\n",
      "[0.4573422  0.47417176 0.536136  ]\n",
      "[0.4459123  0.46723616 0.5456853 ]\n",
      "[0.45222938 0.47109824 0.54037887]\n",
      "[0.42264712 0.45313758 0.56511074]\n",
      "[0.45566487 0.4731601  0.5375047 ]\n",
      "[0.45291436 0.47147062 0.53981954]\n",
      "[0.45353538 0.47188962 0.5392917 ]\n",
      "[0.47048512 0.48203734 0.5252305 ]\n",
      "[0.46726447 0.48010072 0.52792567]\n",
      "[0.46210715 0.47699833 0.5321958 ]\n",
      "[0.46627757 0.4795022  0.52874094]\n",
      "[0.48144472 0.48858073 0.5161439 ]\n",
      "[0.47470716 0.4845642  0.5217309 ]\n",
      "[0.46066368 0.47613025 0.5334281 ]\n",
      "[0.46848395 0.48082268 0.52690643]\n",
      "[0.468172   0.48063952 0.5271593 ]\n",
      "[0.45577028 0.47320348 0.53743726]\n",
      "[0.46911794 0.48121485 0.52637255]\n",
      "[0.44932815 0.46932113 0.542823  ]\n",
      "[0.450408   0.46999127 0.5418922 ]\n",
      "[0.47567114 0.48512423 0.5209314 ]\n",
      "[0.45786935 0.47449502 0.5356773 ]\n",
      "[0.4632664  0.47766307 0.53127897]\n",
      "[0.43054578 0.45784056 0.55863166]\n",
      "[0.4590448  0.47517204 0.5347186 ]\n",
      "[0.47139734 0.48258445 0.524473  ]\n",
      "[0.4518856  0.47090116 0.5406653 ]\n",
      "[0.4706044  0.48210528 0.52510214]\n",
      "[0.4621155  0.47698605 0.5322112 ]\n",
      "[0.44655505 0.46764863 0.54513466]\n",
      "[0.46510693 0.4788054  0.52969235]\n",
      "[0.46300867 0.47752166 0.53145766]\n",
      "[0.45892525 0.4750738  0.53485477]\n",
      "[0.45708552 0.47393942 0.53643024]\n",
      "[0.46660125 0.47969002 0.52846265]\n",
      "[0.4689916  0.4811199  0.52647996]\n",
      "[0.4674205 0.4801885 0.5277827]\n",
      "[0.45847696 0.47484204 0.5352061 ]\n",
      "[0.45472452 0.47254258 0.5383506 ]\n",
      "[0.4769673  0.48591405 0.51985544]\n",
      "[0.4590951  0.4751702  0.53470194]\n",
      "[0.4737118 0.4839762 0.5225303]\n",
      "[0.4638756  0.47805697 0.5307446 ]\n",
      "[0.44101244 0.46418706 0.54989856]\n",
      "[0.47131622 0.4825338  0.52453727]\n",
      "[0.43081298 0.45817593 0.55815434]\n",
      "[0.43277317 0.45920447 0.5567603 ]\n",
      "[0.46474093 0.4785984  0.52997607]\n",
      "[0.45798364 0.47456223 0.5355991 ]\n",
      "[0.4684046  0.48077434 0.526971  ]\n",
      "[0.44455928 0.46638384 0.5468679 ]\n",
      "[0.4636106 0.4778762 0.530993 ]\n",
      "[0.46993193 0.48168683 0.52570134]\n",
      "[0.4530495  0.47152385 0.5397803 ]\n",
      "[0.45286554 0.4714829  0.53984994]\n",
      "[0.45274645 0.47138292 0.5399882 ]\n",
      "[0.43035203 0.4577769  0.5587215 ]\n",
      "[0.45797396 0.47453532 0.5355919 ]\n",
      "[0.4618586  0.47685283 0.5323768 ]\n",
      "[0.44848388 0.46883506 0.5434859 ]\n",
      "[0.46810699 0.48058987 0.52721834]\n",
      "[0.45585757 0.47329104 0.5373498 ]\n",
      "[0.45892176 0.4750113  0.53493637]\n",
      "[0.4671289  0.48001686 0.52802396]\n",
      "[0.42688274 0.45565784 0.5616509 ]\n",
      "[0.4727484 0.4833794 0.523347 ]\n",
      "[0.4612478  0.47648245 0.5329157 ]\n",
      "[0.43117803 0.45827088 0.5580459 ]\n",
      "[0.4654956  0.47904745 0.52934194]\n",
      "[0.4623844  0.4771918  0.53194255]\n",
      "[0.46772486 0.48037946 0.5274991 ]\n",
      "[0.4594403  0.47543272 0.53439003]\n",
      "[0.4140516  0.44787887 0.5723256 ]\n",
      "[0.47954673 0.4874531  0.517717  ]\n",
      "[0.47085658 0.4822518  0.5249399 ]\n",
      "[0.46406338 0.47816974 0.53055483]\n",
      "[0.458663   0.47490215 0.53509825]\n",
      "[0.4535097 0.4717932 0.5393913]\n",
      "[0.45353436 0.4717836  0.53941554]\n",
      "[0.47088835 0.4822674  0.52490497]\n",
      "[0.45403886 0.47217035 0.53890276]\n",
      "[0.46927086 0.481309   0.5262412 ]\n",
      "[0.44834024 0.46874714 0.54364973]\n",
      "[0.4673572  0.48014852 0.527842  ]\n",
      "[0.44857872 0.46876758 0.5435706 ]\n",
      "[0.47280365 0.4834076  0.5233161 ]\n",
      "[0.46200138 0.47692513 0.53231776]\n",
      "[0.4570123  0.47393534 0.53645045]\n",
      "[0.43669748 0.4616841  0.55335456]\n",
      "[0.46219188 0.4770569  0.5321168 ]\n",
      "[0.4698646  0.48166853 0.5257451 ]\n",
      "[0.4635599  0.47787043 0.5310071 ]\n",
      "[0.46332848 0.4777341  0.53118724]\n",
      "[0.41462803 0.44817963 0.57192975]\n",
      "[0.4565789  0.47372305 0.536746  ]\n",
      "[0.4285075  0.45665616 0.560241  ]\n",
      "[0.43104318 0.45814297 0.55822724]\n",
      "[0.46059924 0.47606462 0.5334892 ]\n",
      "[0.47759727 0.48628268 0.5193384 ]\n",
      "[0.4257296  0.45496035 0.5625748 ]\n",
      "[0.47596547 0.48530507 0.5206846 ]\n",
      "[0.47463012 0.4845082  0.52179354]\n",
      "[0.42618364 0.45516646 0.5623178 ]\n",
      "[0.45494983 0.47268844 0.5381469 ]\n",
      "[0.44295114 0.46536762 0.54823303]\n",
      "[0.47179726 0.48282436 0.5241029 ]\n",
      "[0.46179926 0.4768473  0.5324234 ]\n",
      "[0.46091667 0.476273   0.5332041 ]\n",
      "[0.44846776 0.46875936 0.5435922 ]\n",
      "[0.4617914  0.47680393 0.53245753]\n",
      "[0.46395558 0.47812262 0.5306276 ]\n",
      "[0.46003136 0.47569898 0.53397954]\n",
      "[0.44457537 0.4664482  0.5467904 ]\n",
      "[0.47077397 0.48220176 0.52498406]\n",
      "[0.4767389  0.48575896 0.5200609 ]\n",
      "[0.41882598 0.45084044 0.56825906]\n",
      "[0.464888   0.47867975 0.5298918 ]\n",
      "[0.4498974  0.46965507 0.5423402 ]\n",
      "[0.4740982  0.48419896 0.5222352 ]\n",
      "[0.45373413 0.47188687 0.5392559 ]\n",
      "[0.46534732 0.4789295  0.52949816]\n",
      "[0.4591301  0.47523683 0.53464794]\n",
      "[0.47197643 0.48293898 0.5239834 ]\n",
      "[0.4661195 0.4793903 0.5288918]\n",
      "[0.45852995 0.47486112 0.5351341 ]\n",
      "[0.45937902 0.47535357 0.5344697 ]\n",
      "[0.46934336 0.48134005 0.5261883 ]\n",
      "[0.45872945 0.4749536  0.535004  ]\n",
      "[0.45078266 0.47022545 0.5415883 ]\n",
      "[0.45563072 0.47315526 0.5375422 ]\n",
      "[0.43294185 0.45935497 0.5565679 ]\n",
      "[0.4577598  0.47441316 0.53578746]\n",
      "[0.44889122 0.46906018 0.54319453]\n",
      "[0.4399001  0.46354568 0.5507908 ]\n",
      "[0.46108997 0.47641876 0.5330332 ]\n",
      "[0.45137966 0.4705033  0.541182  ]\n",
      "[0.46914196 0.48122    0.5263642 ]\n",
      "[0.45841143 0.4748104  0.5352442 ]\n",
      "Accuracy: 50.25726556777954%\n",
      "10\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria', 'placeOfBirth_Bosasosomalia', 'questionsAskInTheClassroom_H']\n",
      "9\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria', 'placeOfBirth_Bosasosomalia']\n",
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 0s 1ms/sample - loss: 1.0977 - accuracy: 0.4641\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0937 - accuracy: 0.5249\n",
      "[0.4883728  0.49849543 0.5146176 ]\n",
      "[0.48446095 0.4978468  0.5201358 ]\n",
      "[0.48858646 0.49855623 0.51427513]\n",
      "[0.48016873 0.4971647  0.52618116]\n",
      "[0.48315522 0.49767813 0.52194166]\n",
      "[0.4893756  0.49866402 0.5131703 ]\n",
      "[0.48624372 0.4981572  0.51763326]\n",
      "[0.47983572 0.49714592 0.526601  ]\n",
      "[0.48781252 0.49837434 0.5153824 ]\n",
      "[0.48657116 0.49819472 0.5171248 ]\n",
      "[0.48766282 0.49837294 0.51562405]\n",
      "[0.4871093 0.4983172 0.5163872]\n",
      "[0.48756933 0.49838364 0.5157477 ]\n",
      "[0.48831558 0.49850303 0.51467836]\n",
      "[0.48745522 0.49837857 0.5159006 ]\n",
      "[0.4902089  0.49876946 0.5120087 ]\n",
      "[0.47525683 0.49629298 0.53309435]\n",
      "[0.48375577 0.49774435 0.52113354]\n",
      "[0.4867099  0.49819246 0.51695657]\n",
      "[0.4826642 0.4975351 0.5226628]\n",
      "[0.4855877  0.49803182 0.51853526]\n",
      "[0.47507533 0.4962556  0.5333537 ]\n",
      "[0.48616567 0.49813214 0.5176925 ]\n",
      "[0.48449898 0.4978816  0.5200497 ]\n",
      "[0.4859963  0.4981021  0.51795554]\n",
      "[0.489118   0.49859717 0.51355   ]\n",
      "[0.48821783 0.49847972 0.51483154]\n",
      "[0.48669645 0.49824992 0.5169749 ]\n",
      "[0.48790044 0.4984147  0.51528114]\n",
      "[0.49057516 0.49886054 0.5114721 ]\n",
      "[0.48997438 0.4987198  0.5123423 ]\n",
      "[0.48660502 0.49822414 0.51710266]\n",
      "[0.48821476 0.49847713 0.5148339 ]\n",
      "[0.48828834 0.49848354 0.51472497]\n",
      "[0.48564997 0.49811623 0.5183778 ]\n",
      "[0.4888176  0.4985626  0.51397187]\n",
      "[0.48431668 0.4978107  0.5203345 ]\n",
      "[0.48498553 0.4979464  0.51936007]\n",
      "[0.48958996 0.49869132 0.51286787]\n",
      "[0.48659047 0.49825147 0.51709825]\n",
      "[0.48632675 0.49816173 0.51752764]\n",
      "[0.4751633  0.49625733 0.53324056]\n",
      "[0.4860457 0.4981627 0.5178783]\n",
      "[0.48932967 0.49864563 0.51324344]\n",
      "[0.48574346 0.49804583 0.51831514]\n",
      "[0.4887395  0.49858144 0.514034  ]\n",
      "[0.48638088 0.49817842 0.5174354 ]\n",
      "[0.48350605 0.4976799  0.5214776 ]\n",
      "[0.4876414  0.49839354 0.5156258 ]\n",
      "[0.4864822  0.49820155 0.5172744 ]\n",
      "[0.48555583 0.49806148 0.51859933]\n",
      "[0.48409837 0.49780777 0.520679  ]\n",
      "[0.4874993  0.49838546 0.5158321 ]\n",
      "[0.4881673  0.49848703 0.5148709 ]\n",
      "[0.48814166 0.49845657 0.5149309 ]\n",
      "[0.4867596  0.49820137 0.51689243]\n",
      "[0.48438922 0.4978644  0.52024204]\n",
      "[0.49032274 0.49879    0.5118489 ]\n",
      "[0.48554158 0.49806288 0.51859254]\n",
      "[0.4897346  0.49872246 0.51265186]\n",
      "[0.48730138 0.4983233  0.51612675]\n",
      "[0.4785368  0.49680853 0.52853346]\n",
      "[0.48906988 0.49861988 0.5136111 ]\n",
      "[0.48007306 0.49717274 0.52620214]\n",
      "[0.4762835  0.49642846 0.5316844 ]\n",
      "[0.48770687 0.49841046 0.5155195 ]\n",
      "[0.4869502  0.49823684 0.516614  ]\n",
      "[0.48818126 0.49847266 0.51487863]\n",
      "[0.48127115 0.4972939  0.52464765]\n",
      "[0.48658997 0.49820453 0.51716423]\n",
      "[0.488203   0.49849385 0.51484364]\n",
      "[0.48401272 0.4977756  0.5207839 ]\n",
      "[0.48581663 0.49807805 0.5182048 ]\n",
      "[0.48501986 0.49798372 0.5193106 ]\n",
      "[0.47670576 0.49650428 0.5310799 ]\n",
      "[0.4855214  0.49810836 0.51860154]\n",
      "[0.4865446 0.4982381 0.517157 ]\n",
      "[0.4832051  0.49771178 0.5218747 ]\n",
      "[0.48797962 0.49843556 0.5151563 ]\n",
      "[0.4865774  0.49819323 0.51712567]\n",
      "[0.48386478 0.49777436 0.52099335]\n",
      "[0.48802418 0.4984607  0.51509583]\n",
      "[0.4759995  0.49636614 0.5320677 ]\n",
      "[0.4890923  0.4986235  0.51356363]\n",
      "[0.48654443 0.49821576 0.517198  ]\n",
      "[0.47673398 0.49651554 0.5310359 ]\n",
      "[0.48788494 0.498446   0.5152429 ]\n",
      "[0.4874783  0.4983724  0.51585597]\n",
      "[0.48801398 0.4984803  0.51507664]\n",
      "[0.48709354 0.49825174 0.5164061 ]\n",
      "[0.47259507 0.495853   0.5367853 ]\n",
      "[0.49065143 0.4988486  0.51138   ]\n",
      "[0.48898822 0.4985849  0.5137476 ]\n",
      "[0.48718166 0.4983431  0.51624006]\n",
      "[0.48519728 0.49798998 0.51912564]\n",
      "[0.4836192  0.49771953 0.5213405 ]\n",
      "[0.48307323 0.49760902 0.5221349 ]\n",
      "[0.4889295  0.49858937 0.51381105]\n",
      "[0.48543715 0.49804637 0.5187539 ]\n",
      "[0.48885295 0.49856007 0.51392585]\n",
      "[0.48469394 0.4978778  0.5198106 ]\n",
      "[0.48804528 0.49844489 0.5150731 ]\n",
      "[0.48101088 0.4972379  0.525044  ]\n",
      "[0.48903757 0.49860138 0.51365906]\n",
      "[0.4865841 0.4982167 0.5171498]\n",
      "[0.4855263  0.49805516 0.5186408 ]\n",
      "[0.48039794 0.4971588  0.52585137]\n",
      "[0.48714516 0.49829304 0.51633066]\n",
      "[0.48905408 0.498589   0.5136406 ]\n",
      "[0.48724407 0.49833876 0.5161769 ]\n",
      "[0.4870668  0.4983081  0.51645106]\n",
      "[0.47160438 0.49559966 0.5382802 ]\n",
      "[0.486648   0.49819684 0.5170224 ]\n",
      "[0.47511703 0.49632722 0.533247  ]\n",
      "[0.47602236 0.49634722 0.5320738 ]\n",
      "[0.4853993  0.49803343 0.5188377 ]\n",
      "[0.49025595 0.49877894 0.5119409 ]\n",
      "[0.4749083  0.49623248 0.53355867]\n",
      "[0.48984283 0.49871957 0.51251113]\n",
      "[0.489646   0.49868688 0.5127944 ]\n",
      "[0.47390816 0.4959771  0.53505164]\n",
      "[0.48487714 0.49793467 0.51953715]\n",
      "[0.4791625  0.49695763 0.52758116]\n",
      "[0.48902938 0.49863228 0.5136189 ]\n",
      "[0.4874646  0.49831983 0.5158661 ]\n",
      "[0.4865019  0.4982311  0.51719886]\n",
      "[0.48237255 0.4974933  0.52310866]\n",
      "[0.4865574  0.49822888 0.51716477]\n",
      "[0.48735917 0.4983719  0.51600325]\n",
      "[0.48461482 0.49790812 0.51992875]\n",
      "[0.4828875  0.49756894 0.5223542 ]\n",
      "[0.48887968 0.49858603 0.51386803]\n",
      "[0.48979905 0.49871397 0.5125879 ]\n",
      "[0.47571817 0.4963679  0.5324009 ]\n",
      "[0.4879044  0.49842304 0.51526827]\n",
      "[0.48346013 0.49772686 0.52152663]\n",
      "[0.4897728  0.49871048 0.5126242 ]\n",
      "[0.48252106 0.49752355 0.5228955 ]\n",
      "[0.48695996 0.49830666 0.51657933]\n",
      "[0.48687527 0.498224   0.51671344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4895736  0.49866408 0.5129005 ]\n",
      "[0.48735717 0.49833214 0.516063  ]\n",
      "[0.4855812 0.4981143 0.5185152]\n",
      "[0.48562837 0.498086   0.51848894]\n",
      "[0.48855704 0.49853227 0.5143384 ]\n",
      "[0.48535594 0.49804386 0.51886123]\n",
      "[0.4853481  0.49799335 0.5188654 ]\n",
      "[0.4865548  0.49818492 0.51716083]\n",
      "[0.4770789  0.49659255 0.53056276]\n",
      "[0.48658407 0.49817395 0.51712596]\n",
      "[0.48393995 0.49779382 0.5208369 ]\n",
      "[0.47886366 0.49688056 0.5280635 ]\n",
      "[0.48736548 0.49828786 0.5160281 ]\n",
      "[0.48259583 0.4975455  0.52279174]\n",
      "[0.4885748  0.498513   0.51433045]\n",
      "[0.48683098 0.49821183 0.51677746]\n",
      "Accuracy: 50.08285641670227%\n",
      "9\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria', 'placeOfBirth_Bosasosomalia']\n",
      "8\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria']\n",
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 0s 1ms/sample - loss: 1.0976 - accuracy: 0.4972\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 1.0917 - accuracy: 0.5249\n",
      "[0.48108736 0.48429203 0.5205023 ]\n",
      "[0.4709247  0.47459826 0.5320984 ]\n",
      "[0.48050854 0.48374996 0.521152  ]\n",
      "[0.4656417  0.46952087 0.5381668 ]\n",
      "[0.46885493 0.47261634 0.53446853]\n",
      "[0.48236376 0.48551723 0.5190417 ]\n",
      "[0.47591338 0.47936603 0.5263972 ]\n",
      "[0.4641221  0.46808106 0.53988636]\n",
      "[0.47774696 0.48110074 0.524318  ]\n",
      "[0.47442678 0.47793627 0.5281056 ]\n",
      "[0.4783414 0.4816877 0.5236176]\n",
      "[0.47851446 0.48185164 0.5234168 ]\n",
      "[0.47925955 0.48255518 0.5225806 ]\n",
      "[0.4800763  0.48334527 0.52163523]\n",
      "[0.4789112  0.48221487 0.52299196]\n",
      "[0.4841899  0.48726338 0.51694864]\n",
      "[0.4565733  0.46084964 0.5485103 ]\n",
      "[0.4712483  0.47491765 0.5317109 ]\n",
      "[0.4750841 0.4785629 0.527354 ]\n",
      "[0.46754715 0.47136256 0.5359641 ]\n",
      "[0.4726616  0.4762522  0.53011954]\n",
      "[0.45645258 0.4607819  0.54859495]\n",
      "[0.473487  0.47704   0.5291753]\n",
      "[0.47096413 0.4746374  0.5320495 ]\n",
      "[0.47356316 0.4771172  0.5290855 ]\n",
      "[0.48125756 0.48446366 0.5202979 ]\n",
      "[0.48011017 0.48337683 0.5215968 ]\n",
      "[0.47690734 0.4803141  0.52526325]\n",
      "[0.47899482 0.48230866 0.52287763]\n",
      "[0.48581856 0.4888187  0.5150838 ]\n",
      "[0.4832606  0.4863747  0.51801044]\n",
      "[0.47674745 0.48017067 0.5254278 ]\n",
      "[0.48002136 0.48328942 0.5217046 ]\n",
      "[0.4798379 0.4831109 0.521918 ]\n",
      "[0.47309855 0.47668812 0.52959025]\n",
      "[0.4805777  0.48382378 0.52106273]\n",
      "[0.47015804 0.4738694  0.532967  ]\n",
      "[0.4708661  0.47455218 0.5321497 ]\n",
      "[0.4827131  0.48585883 0.5186281 ]\n",
      "[0.47598147 0.47942442 0.526331  ]\n",
      "[0.476401   0.47982436 0.52584803]\n",
      "[0.4567903  0.46104723 0.5482744 ]\n",
      "[0.4753446  0.47881502 0.5270582 ]\n",
      "[0.48189417 0.48507848 0.51956284]\n",
      "[0.47256064 0.47616115 0.53022593]\n",
      "[0.48008704 0.48335508 0.5216214 ]\n",
      "[0.47608158 0.47952804 0.5262021 ]\n",
      "[0.46898222 0.47274873 0.53430945]\n",
      "[0.47830436 0.48165068 0.5236648 ]\n",
      "[0.47601354 0.4794632  0.5262783 ]\n",
      "[0.4746617  0.47816694 0.52783066]\n",
      "[0.4733304  0.47688147 0.52936727]\n",
      "[0.47876748 0.48209316 0.52313304]\n",
      "[0.47942775 0.48272967 0.52236867]\n",
      "[0.47932804 0.48262364 0.52250004]\n",
      "[0.475322  0.4787955 0.5270752]\n",
      "[0.47226107 0.47587544 0.53056943]\n",
      "[0.48450172 0.48756352 0.51659083]\n",
      "[0.4738755 0.4774257 0.5287121]\n",
      "[0.48281014 0.48595116 0.51851916]\n",
      "[0.47768742 0.48106718 0.52435946]\n",
      "[0.46352902 0.46749675 0.5405794 ]\n",
      "[0.48186138 0.48504382 0.51960576]\n",
      "[0.4605652  0.4647184  0.54389644]\n",
      "[0.45896882 0.4631374  0.5457843 ]\n",
      "[0.4781622  0.4815104  0.52383316]\n",
      "[0.47558662 0.47904527 0.52677774]\n",
      "[0.47988406 0.48315874 0.5218606 ]\n",
      "[0.4673316  0.4711766  0.53618294]\n",
      "[0.47728008 0.48067102 0.5248354 ]\n",
      "[0.48044065 0.48368302 0.5212335 ]\n",
      "[0.47181842 0.4754643  0.5310577 ]\n",
      "[0.47308466 0.4766644  0.52962667]\n",
      "[0.47278994 0.4763924  0.52994424]\n",
      "[0.45953304 0.46371302 0.5450979 ]\n",
      "[0.47482222 0.47831392 0.52765524]\n",
      "[0.4758977  0.47934687 0.5264193 ]\n",
      "[0.46997195 0.47366327 0.533223  ]\n",
      "[0.47909895 0.48240256 0.5227635 ]\n",
      "[0.4746153  0.47811946 0.5278866 ]\n",
      "[0.47266093 0.47622678 0.5301475 ]\n",
      "[0.47977346 0.48305196 0.5219877 ]\n",
      "[0.45589095 0.46020803 0.54928297]\n",
      "[0.48141992 0.48462692 0.5201015 ]\n",
      "[0.47652417 0.4799483  0.5257017 ]\n",
      "[0.4586438  0.46284273 0.5461365 ]\n",
      "[0.47794476 0.48131183 0.52406603]\n",
      "[0.47797668 0.48133305 0.5240464 ]\n",
      "[0.47926673 0.48256546 0.5225694 ]\n",
      "[0.4760718  0.47950128 0.5262319 ]\n",
      "[0.4487702  0.45341718 0.55737555]\n",
      "[0.4854741  0.48849046 0.5154814 ]\n",
      "[0.48164    0.48483425 0.5198567 ]\n",
      "[0.47664917 0.4800788  0.5255385 ]\n",
      "[0.4742669  0.47778657 0.52828515]\n",
      "[0.4712336  0.47488347 0.5317558 ]\n",
      "[0.471067   0.47471336 0.5319605 ]\n",
      "[0.4811679  0.48438883 0.5203865 ]\n",
      "[0.4739503  0.47749317 0.5286348 ]\n",
      "[0.4806944 0.4839294 0.5209375]\n",
      "[0.47080702 0.4744955  0.5322139 ]\n",
      "[0.47944966 0.4827445  0.5223568 ]\n",
      "[0.46793842 0.4717291  0.53552276]\n",
      "[0.481496   0.4846974  0.52001834]\n",
      "[0.47716644 0.4805685  0.5249552 ]\n",
      "[0.47478324 0.47829074 0.52767956]\n",
      "[0.46339738 0.46739683 0.5407062 ]\n",
      "[0.4765764  0.47999907 0.5256382 ]\n",
      "[0.4810721 0.4842895 0.5205065]\n",
      "[0.47759163 0.48097733 0.52446216]\n",
      "[0.47780687 0.48117712 0.52422816]\n",
      "[0.45022333 0.454815   0.55570734]\n",
      "[0.4747773  0.47826642 0.52771044]\n",
      "[0.4562208  0.46053344 0.54888123]\n",
      "[0.4579842  0.46220562 0.54689574]\n",
      "[0.47535166 0.47881958 0.52704966]\n",
      "[0.4842766 0.4873469 0.5168485]\n",
      "[0.45443654 0.45883766 0.5509089 ]\n",
      "[0.48294282 0.4860723  0.51837206]\n",
      "[0.482607   0.48574957 0.51875883]\n",
      "[0.45528272 0.45962694 0.54996854]\n",
      "[0.47215065 0.47576928 0.53069574]\n",
      "[0.46307132 0.467074   0.54107803]\n",
      "[0.48076114 0.4839974  0.52085334]\n",
      "[0.4770398  0.48042148 0.5251328 ]\n",
      "[0.47507185 0.47857475 0.52733284]\n",
      "[0.4693538 0.4730976 0.5338889]\n",
      "[0.47644168 0.47987378 0.5257876 ]\n",
      "[0.47763798 0.48101196 0.52442795]\n",
      "[0.473809   0.47733596 0.52882224]\n",
      "[0.4678588 0.4716738 0.5355946]\n",
      "[0.48083884 0.48407128 0.52076787]\n",
      "[0.4835193  0.48662302 0.5177147 ]\n",
      "[0.45356554 0.45804924 0.55185187]\n",
      "[0.47880015 0.4821267  0.5230918 ]\n",
      "[0.47032085 0.47402108 0.53278726]\n",
      "[0.4832268 0.4863492 0.5180442]\n",
      "[0.4702211 0.4739045 0.5329229]\n",
      "[0.4773296 0.4807209 0.5247723]\n",
      "[0.47551426 0.47896978 0.52686715]\n",
      "[0.48217002 0.48533198 0.5192592 ]\n",
      "[0.47846493 0.48180446 0.52347964]\n",
      "[0.47467452 0.47817656 0.5278186 ]\n",
      "[0.47525623 0.47873598 0.52715003]\n",
      "[0.48033828 0.48359692 0.52133423]\n",
      "[0.4740423  0.47757858 0.5285318 ]\n",
      "[0.47159556 0.4752464  0.53131884]\n",
      "[0.4745012  0.47801176 0.5280146 ]\n",
      "[0.46063966 0.464735   0.5438823 ]\n",
      "[0.4747396 0.4782312 0.5277496]\n",
      "[0.4710034  0.47468352 0.53198916]\n",
      "[0.463836   0.46779308 0.5402287 ]\n",
      "[0.47684968 0.48024252 0.52534527]\n",
      "[0.470228   0.47391304 0.5329168 ]\n",
      "[0.48043594 0.4836794  0.52123654]\n",
      "[0.47531638 0.47878203 0.5270913 ]\n",
      "Accuracy: 50.012266635894775%\n",
      "8\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni', 'nationality_Nigeria']\n",
      "7\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni']\n",
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 0s 935us/sample - loss: 1.0977 - accuracy: 0.4751\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0925 - accuracy: 0.5249\n",
      "[0.48680937 0.48631197 0.5193677 ]\n",
      "[0.48023158 0.47779405 0.5303593 ]\n",
      "[0.4864833  0.48595974 0.51981544]\n",
      "[0.47688636 0.47314024 0.5363953 ]\n",
      "[0.4789914  0.47618085 0.53243846]\n",
      "[0.48799843 0.48796555 0.51720184]\n",
      "[0.48297337 0.48131463 0.5258235 ]\n",
      "[0.4759297  0.47200122 0.5378568 ]\n",
      "[0.48515582 0.4843019  0.521942  ]\n",
      "[0.4828904  0.48138022 0.52570844]\n",
      "[0.4842785  0.48312515 0.5234689 ]\n",
      "[0.48387593 0.48244226 0.52437466]\n",
      "[0.48524925 0.4842655  0.5220165 ]\n",
      "[0.48555997 0.4847719  0.52134883]\n",
      "[0.48567438 0.48484537 0.521263  ]\n",
      "[0.48887542 0.489093   0.5157499 ]\n",
      "[0.4704519 0.4645244 0.5475279]\n",
      "[0.4788033  0.47585914 0.53287375]\n",
      "[0.48304465 0.48157686 0.52545375]\n",
      "[0.4783007  0.47516596 0.5337718 ]\n",
      "[0.48162568 0.47969887 0.5278849 ]\n",
      "[0.4693548  0.46321923 0.54919285]\n",
      "[0.48236904 0.4806627  0.5266485 ]\n",
      "[0.4803441  0.47791162 0.53022   ]\n",
      "[0.48195556 0.48015025 0.52729666]\n",
      "[0.48701808 0.48670462 0.51883644]\n",
      "[0.48527458 0.48441887 0.52180016]\n",
      "[0.4837714  0.48239022 0.5244289 ]\n",
      "[0.4852562  0.48435974 0.5218811 ]\n",
      "[0.48963168 0.49006194 0.51449776]\n",
      "[0.4882598  0.488319   0.51674193]\n",
      "[0.4823045  0.48054576 0.52680874]\n",
      "[0.4858031 0.4850604 0.5209783]\n",
      "[0.48600587 0.48534268 0.52061003]\n",
      "[0.48016205 0.47782344 0.5303284 ]\n",
      "[0.48598436 0.48536864 0.5205689 ]\n",
      "[0.4795907  0.47696298 0.53143686]\n",
      "[0.4798545  0.47739542 0.5308653 ]\n",
      "[0.48770484 0.48755357 0.51774764]\n",
      "[0.4837661  0.48247263 0.52430594]\n",
      "[0.48347464 0.48192894 0.5250379 ]\n",
      "[0.47020537 0.46416548 0.54799443]\n",
      "[0.48325127 0.48171154 0.5253057 ]\n",
      "[0.487066   0.486771   0.51874954]\n",
      "[0.4809865  0.47891808 0.5288807 ]\n",
      "[0.48585054 0.48520288 0.5207893 ]\n",
      "[0.48300275 0.48135105 0.5257788 ]\n",
      "[0.4786308  0.47566763 0.53311324]\n",
      "[0.48485518 0.48384893 0.5225409 ]\n",
      "[0.48314053 0.48154408 0.5255308 ]\n",
      "[0.48224366 0.4803353  0.52709156]\n",
      "[0.4811378  0.47876844 0.52912426]\n",
      "[0.4846832  0.4835903  0.52288085]\n",
      "[0.48475194 0.48372442 0.52270967]\n",
      "[0.48569196 0.48493996 0.52113116]\n",
      "[0.48295024 0.48143232 0.5256467 ]\n",
      "[0.4804832  0.47800934 0.53009826]\n",
      "[0.4890259  0.48929986 0.5154786 ]\n",
      "[0.4812836  0.47912225 0.5286604 ]\n",
      "[0.487895   0.4878505  0.51735187]\n",
      "[0.4836855  0.48231706 0.524521  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47413713 0.46938077 0.5412628 ]\n",
      "[0.48719275 0.4869012  0.5185851 ]\n",
      "[0.47370553 0.4693159  0.5413027 ]\n",
      "[0.47108442 0.46535176 0.54646134]\n",
      "[0.48513383 0.48422945 0.52204776]\n",
      "[0.48322773 0.48182923 0.52512413]\n",
      "[0.4857004  0.4849277  0.52115005]\n",
      "[0.47561854 0.47152963 0.5384676 ]\n",
      "[0.48348525 0.48195094 0.5250019 ]\n",
      "[0.48624694 0.48560962 0.5202708 ]\n",
      "[0.47902015 0.47610548 0.5325569 ]\n",
      "[0.48149118 0.4795432  0.5280824 ]\n",
      "[0.479576   0.47702962 0.5313468 ]\n",
      "[0.47072387 0.46496254 0.5469481 ]\n",
      "[0.48278925 0.4811225  0.5260662 ]\n",
      "[0.4835688 0.4821389 0.5247578]\n",
      "[0.48078766 0.4783877  0.52960426]\n",
      "[0.48560178 0.4847986  0.52131927]\n",
      "[0.48274636 0.48120177 0.5259357 ]\n",
      "[0.48125404 0.47888848 0.5289814 ]\n",
      "[0.48552382 0.48471713 0.5214174 ]\n",
      "[0.47025114 0.4643653  0.5477353 ]\n",
      "[0.48673484 0.4863089  0.5193602 ]\n",
      "[0.48355824 0.48210448 0.5247986 ]\n",
      "[0.471149   0.46552044 0.5462376 ]\n",
      "[0.48430237 0.48321128 0.5233577 ]\n",
      "[0.48486164 0.4838868  0.5224824 ]\n",
      "[0.4856339  0.484865   0.52123016]\n",
      "[0.48392206 0.48271772 0.52397954]\n",
      "[0.46744102 0.46065673 0.5525195 ]\n",
      "[0.48963493 0.49008903 0.5144624 ]\n",
      "[0.48687676 0.4864792  0.5191339 ]\n",
      "[0.48289832 0.48133627 0.52579576]\n",
      "[0.4818671  0.47980338 0.52778304]\n",
      "[0.47993386 0.47722876 0.53111386]\n",
      "[0.47982624 0.47701648 0.5313943 ]\n",
      "[0.48623088 0.48566484 0.52019113]\n",
      "[0.4813772  0.47933102 0.52837133]\n",
      "[0.4864967 0.4860243 0.5197192]\n",
      "[0.47888485 0.47614172 0.5324779 ]\n",
      "[0.4854789  0.48464447 0.52151453]\n",
      "[0.47666636 0.47276747 0.53688437]\n",
      "[0.48688316 0.48647973 0.5191394 ]\n",
      "[0.48291314 0.48127714 0.5258689 ]\n",
      "[0.48156276 0.47951642 0.52814233]\n",
      "[0.47543663 0.47136638 0.53867936]\n",
      "[0.48384273 0.4825465  0.5242231 ]\n",
      "[0.48673147 0.48634028 0.51930624]\n",
      "[0.48295912 0.4814194  0.52568245]\n",
      "[0.4838434  0.48252165 0.52425766]\n",
      "[0.4650927  0.45740858 0.55669177]\n",
      "[0.48326966 0.48186582 0.52508104]\n",
      "[0.4705408  0.46468514 0.547314  ]\n",
      "[0.47001287 0.46393156 0.5482925 ]\n",
      "[0.48250064 0.48061365 0.5267354 ]\n",
      "[0.48889685 0.48911935 0.51571673]\n",
      "[0.46879557 0.4624279  0.5502279 ]\n",
      "[0.4880947  0.4880704  0.51707613]\n",
      "[0.48798352 0.48792687 0.51726097]\n",
      "[0.46757168 0.46061978 0.5525612 ]\n",
      "[0.48100862 0.47876614 0.5291168 ]\n",
      "[0.47379827 0.46902248 0.541725  ]\n",
      "[0.48631576 0.48580253 0.5200116 ]\n",
      "[0.48495218 0.48404506 0.5222692 ]\n",
      "[0.4810826  0.4789682  0.52885705]\n",
      "[0.47790435 0.47454128 0.5345815 ]\n",
      "[0.48312992 0.4815647  0.52549684]\n",
      "[0.4845279  0.48343784 0.52307075]\n",
      "[0.48175395 0.47959402 0.52806264]\n",
      "[0.47792223 0.47471306 0.53434885]\n",
      "[0.48652375 0.48604438 0.51969993]\n",
      "[0.48837003 0.48839968 0.5166511 ]\n",
      "[0.46828622 0.46197453 0.55078727]\n",
      "[0.48453927 0.483481   0.5230092 ]\n",
      "[0.47937402 0.47658968 0.5319269 ]\n",
      "[0.48806822 0.4880467  0.5170985 ]\n",
      "[0.47892505 0.47580713 0.53295964]\n",
      "[0.48370293 0.48229894 0.5245542 ]\n",
      "[0.48367217 0.48236525 0.52444375]\n",
      "[0.4877187  0.48762777 0.5176342 ]\n",
      "[0.48441952 0.4832123  0.52337086]\n",
      "[0.48254618 0.48080117 0.5264847 ]\n",
      "[0.48248228 0.48066062 0.52666754]\n",
      "[0.48571572 0.48498604 0.5210713 ]\n",
      "[0.4816776 0.4796086 0.528031 ]\n",
      "[0.48008168 0.47772077 0.53043354]\n",
      "[0.48250192 0.48089167 0.52633375]\n",
      "[0.47287536 0.46775675 0.54335093]\n",
      "[0.4830723 0.4815864 0.52545  ]\n",
      "[0.47851726 0.47560048 0.5331949 ]\n",
      "[0.47472265 0.47019958 0.5402001 ]\n",
      "[0.48439637 0.48333076 0.52318794]\n",
      "[0.47924325 0.47625768 0.5323699 ]\n",
      "[0.48638678 0.4858469  0.5199542 ]\n",
      "[0.4833916  0.48201793 0.52488756]\n",
      "Accuracy: 49.94976818561554%\n",
      "7\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM', 'placeOfBirth_Feni']\n",
      "6\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM']\n",
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 1s 2ms/sample - loss: 1.0974 - accuracy: 0.4945\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 1.0911 - accuracy: 0.5249\n",
      "[0.4779829 0.4858178 0.5215389]\n",
      "[0.4683114  0.4796225  0.53126067]\n",
      "[0.4784461  0.48615363 0.5210613 ]\n",
      "[0.4634414  0.47633365 0.53618366]\n",
      "[0.46757838 0.47914505 0.5320016 ]\n",
      "[0.4803466 0.4873777 0.519162 ]\n",
      "[0.47380742 0.48316056 0.5257395 ]\n",
      "[0.463386   0.47635186 0.5362191 ]\n",
      "[0.47421476 0.48346183 0.52530146]\n",
      "[0.47158694 0.48178422 0.5279387 ]\n",
      "[0.47716215 0.48538536 0.52235514]\n",
      "[0.47693563 0.48515794 0.5225927 ]\n",
      "[0.47705722 0.48523727 0.5224705 ]\n",
      "[0.47897044 0.4865112  0.5205396 ]\n",
      "[0.4766988  0.48501968 0.52283156]\n",
      "[0.4819801  0.48840445 0.5175201 ]\n",
      "[0.45240116 0.46901804 0.5473025 ]\n",
      "[0.4709881 0.4813642 0.5285733]\n",
      "[0.47213984 0.48214447 0.5273907 ]\n",
      "[0.46353245 0.4764412  0.5360762 ]\n",
      "[0.46989414 0.4806769  0.52965367]\n",
      "[0.45634243 0.47174084 0.54332954]\n",
      "[0.47013262 0.48081404 0.52940214]\n",
      "[0.46801752 0.47938472 0.53155106]\n",
      "[0.47136566 0.4816453  0.52817285]\n",
      "[0.47891194 0.4864769  0.5205936 ]\n",
      "[0.47947392 0.48685142 0.52003694]\n",
      "[0.47543052 0.484228   0.5241034 ]\n",
      "[0.47679624 0.48512092 0.522726  ]\n",
      "[0.48459297 0.4900509  0.5148978 ]\n",
      "[0.48090574 0.48774156 0.51859266]\n",
      "[0.4763591  0.48488048 0.52316684]\n",
      "[0.47822642 0.48602432 0.5212932 ]\n",
      "[0.47752887 0.48558095 0.5219895 ]\n",
      "[0.47354695 0.4830668  0.5259676 ]\n",
      "[0.4791928  0.48666963 0.52031183]\n",
      "[0.46715397 0.47886533 0.5324181 ]\n",
      "[0.4687356  0.47993165 0.5308085 ]\n",
      "[0.480718   0.48759782 0.51878077]\n",
      "[0.47480544 0.48385417 0.5247239 ]\n",
      "[0.47350395 0.48292893 0.5260499 ]\n",
      "[0.45184654 0.4686352  0.5478652 ]\n",
      "[0.47365454 0.4830654  0.52588916]\n",
      "[0.48044878 0.48746154 0.51905334]\n",
      "[0.47011715 0.48084968 0.52942085]\n",
      "[0.47836614 0.4861331  0.5211198 ]\n",
      "[0.47389463 0.4832094  0.52564996]\n",
      "[0.46637887 0.4783539  0.53320646]\n",
      "[0.47642034 0.484879   0.5230998 ]\n",
      "[0.47358367 0.48299804 0.5259575 ]\n",
      "[0.4726214  0.48237702 0.52693427]\n",
      "[0.47103888 0.4813039  0.5285395 ]\n",
      "[0.47782698 0.485771   0.5216912 ]\n",
      "[0.47861665 0.486288   0.520886  ]\n",
      "[0.47688583 0.485174   0.5226323 ]\n",
      "[0.47260967 0.48244327 0.5269214 ]\n",
      "[0.47032163 0.48087576 0.5292486 ]\n",
      "[0.48265848 0.4888434  0.5168418 ]\n",
      "[0.47213906 0.48207206 0.5274044 ]\n",
      "[0.48127165 0.48797685 0.5182213 ]\n",
      "[0.47665665 0.48505244 0.5228629 ]\n",
      "[0.4590839 0.4734128 0.540586 ]\n",
      "[0.48049346 0.4874748  0.51901484]\n",
      "[0.4590931  0.4736161  0.54051137]\n",
      "[0.45464316 0.47050864 0.545052  ]\n",
      "[0.47591513 0.48454878 0.52360356]\n",
      "[0.47298428 0.48270053 0.52654064]\n",
      "[0.47808853 0.48593664 0.52143043]\n",
      "[0.4670108  0.4787346  0.53259164]\n",
      "[0.47550812 0.48426446 0.5240336 ]\n",
      "[0.4787102  0.48631445 0.5208099 ]\n",
      "[0.4712917  0.48155254 0.5282712 ]\n",
      "[0.47108632 0.4814653  0.5284524 ]\n",
      "[0.47277704 0.4825765  0.5267597 ]\n",
      "[0.45882815 0.4733459  0.5408316 ]\n",
      "[0.47407863 0.4833467  0.5254534 ]\n",
      "[0.47366574 0.48306102 0.52586925]\n",
      "[0.4676721  0.47913978 0.5319144 ]\n",
      "[0.47637615 0.48482212 0.5231456 ]\n",
      "[0.47219256 0.4821854  0.5273345 ]\n",
      "[0.4687618 0.4797561 0.5308276]\n",
      "[0.4787396  0.48636353 0.52077705]\n",
      "[0.4501837  0.4676155  0.54953337]\n",
      "[0.47970694 0.48696887 0.5197925 ]\n",
      "[0.47474992 0.4837863  0.5247895 ]\n",
      "[0.45525128 0.47095415 0.5444345 ]\n",
      "[0.47660932 0.48502955 0.52287924]\n",
      "[0.47638804 0.48487753 0.5231337 ]\n",
      "[0.477656   0.48566094 0.5218539 ]\n",
      "[0.47270015 0.4825007  0.5268251 ]\n",
      "[0.44306082 0.46291715 0.5566925 ]\n",
      "[0.48374087 0.48951977 0.51575655]\n",
      "[0.4800038  0.48716503 0.5195094 ]\n",
      "[0.47600806 0.48462546 0.52349555]\n",
      "[0.47185335 0.48186123 0.5277127 ]\n",
      "[0.46847335 0.47963995 0.53111607]\n",
      "[0.46739736 0.4789025  0.5322086 ]\n",
      "[0.48010015 0.4872364  0.51940316]\n",
      "[0.47344062 0.48298636 0.5260973 ]\n",
      "[0.47857878 0.48626834 0.5209296 ]\n",
      "[0.46923673 0.4802896  0.5303102 ]\n",
      "[0.47744438 0.48552966 0.5220765 ]\n",
      "[0.46514875 0.47742346 0.53447634]\n",
      "[0.4793615  0.48673728 0.5201474 ]\n",
      "[0.4767557  0.48511556 0.52277213]\n",
      "[0.47442943 0.48361105 0.5251086 ]\n",
      "[0.45995533 0.47411284 0.5396847 ]\n",
      "[0.47404078 0.4833391  0.52548695]\n",
      "[0.4790387  0.4865656  0.52046627]\n",
      "[0.47730982 0.48548195 0.5222055 ]\n",
      "[0.4773     0.48545802 0.52222085]\n",
      "[0.44668958 0.46532124 0.553068  ]\n",
      "[0.4715237  0.4817374  0.52800477]\n",
      "[0.45375228 0.46993282 0.54592276]\n",
      "[0.45374697 0.46993664 0.5459604 ]\n",
      "[0.47340477 0.4828677  0.5261527 ]\n",
      "[0.48212048 0.48849216 0.51737875]\n",
      "[0.45078897 0.46800184 0.54891455]\n",
      "[0.480435   0.4874212  0.51905996]\n",
      "[0.48001105 0.487153   0.5194894 ]\n",
      "[0.45138884 0.46835992 0.5483409 ]\n",
      "[0.46901947 0.4800312  0.53055054]\n",
      "[0.45925024 0.47353122 0.54039514]\n",
      "[0.47920486 0.48666695 0.5202733 ]\n",
      "[0.4732736  0.48285568 0.52624583]\n",
      "[0.47488612 0.48391595 0.5246315 ]\n",
      "[0.46801123 0.47937208 0.53158295]\n",
      "[0.47533503 0.48417073 0.5241948 ]\n",
      "[0.47616857 0.48471525 0.5233476 ]\n",
      "[0.47079092 0.4811149  0.5287816 ]\n",
      "[0.46499383 0.47744015 0.5346042 ]\n",
      "[0.47893095 0.48648053 0.5205731 ]\n",
      "[0.4812397  0.48792002 0.5182646 ]\n",
      "[0.45160338 0.46866953 0.5480834 ]\n",
      "[0.47787884 0.48584455 0.52163213]\n",
      "[0.4692663 0.4802065 0.5303067]\n",
      "[0.4816001  0.48817867 0.51790404]\n",
      "[0.466453   0.47826147 0.5331566 ]\n",
      "[0.47617382 0.48469368 0.5233465 ]\n",
      "[0.4720026  0.48202994 0.527528  ]\n",
      "[0.47975844 0.48702    0.51974076]\n",
      "[0.47667456 0.4850273  0.52285457]\n",
      "[0.47379816 0.4831586  0.52573466]\n",
      "[0.47419405 0.4834135  0.5253507 ]\n",
      "[0.4790905  0.48659274 0.52041686]\n",
      "[0.47246182 0.48226917 0.5270891 ]\n",
      "[0.46962202 0.48052666 0.5299171 ]\n",
      "[0.47214434 0.4821596  0.527382  ]\n",
      "[0.4577439  0.4725832  0.54193205]\n",
      "[0.47116834 0.48149058 0.5283658 ]\n",
      "[0.4713636  0.48164985 0.5281863 ]\n",
      "[0.4601048  0.47411564 0.5395559 ]\n",
      "[0.47348067 0.48300716 0.52604234]\n",
      "[0.46745184 0.47895408 0.53215134]\n",
      "[0.477963   0.48586234 0.52155256]\n",
      "[0.47188887 0.48196828 0.5276404 ]\n",
      "Accuracy: 50.09092092514038%\n",
      "6\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours', 'department_ESDM']\n",
      "5\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 0s 1ms/sample - loss: 1.0971 - accuracy: 0.5138\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 1.0861 - accuracy: 0.5249\n",
      "[0.46719375 0.4827636  0.53617984]\n",
      "[0.44512552 0.470484   0.5608598 ]\n",
      "[0.46745083 0.4829032  0.53589785]\n",
      "[0.4360687 0.4654209 0.5709722]\n",
      "[0.44211265 0.46879748 0.56422514]\n",
      "[0.4713543  0.4850709  0.53151476]\n",
      "[0.45504004 0.47600865 0.54978967]\n",
      "[0.43382794 0.46415663 0.57347256]\n",
      "[0.4612272 0.4794521 0.5428462]\n",
      "[0.45393953 0.47539908 0.55099624]\n",
      "[0.45834154 0.47784027 0.5461012 ]\n",
      "[0.45959294 0.47853756 0.5447151 ]\n",
      "[0.46311325 0.48049682 0.5407607 ]\n",
      "[0.46380576 0.48087364 0.5399893 ]\n",
      "[0.46422598 0.48112097 0.53949946]\n",
      "[0.47428823 0.48669225 0.5282417 ]\n",
      "[0.41555846 0.45386553 0.5938327 ]\n",
      "[0.44206294 0.4687615  0.56431824]\n",
      "[0.45346203 0.47513247 0.5515374 ]\n",
      "[0.4400588  0.46764913 0.56651455]\n",
      "[0.4493684  0.47285444 0.5561119 ]\n",
      "[0.41289258 0.45233774 0.5968303 ]\n",
      "[0.45286685 0.47480282 0.55219764]\n",
      "[0.44754577 0.47183797 0.5581587 ]\n",
      "[0.45021796 0.4733244  0.5551666 ]\n",
      "[0.4675682  0.48296735 0.5357619 ]\n",
      "[0.46225038 0.48000813 0.54173446]\n",
      "[0.45778108 0.47753304 0.5467224 ]\n",
      "[0.46202093 0.47988802 0.5419757 ]\n",
      "[0.47761428 0.48853323 0.52452785]\n",
      "[0.4715761  0.48518926 0.53127635]\n",
      "[0.4529352  0.47482473 0.55216885]\n",
      "[0.4641806  0.48108628 0.53956187]\n",
      "[0.4647165  0.48138535 0.5389563 ]\n",
      "[0.4475391  0.47181502 0.5582056 ]\n",
      "[0.46423218 0.48111176 0.5395063 ]\n",
      "[0.4434095  0.46952277 0.5627814 ]\n",
      "[0.44427106 0.47000265 0.5618202 ]\n",
      "[0.47126624 0.48501503 0.53163403]\n",
      "[0.4573604  0.47730017 0.54717934]\n",
      "[0.456579   0.47686705 0.54806364]\n",
      "[0.4143934  0.45320657 0.59512573]\n",
      "[0.45625576 0.47668967 0.5484189 ]\n",
      "[0.4678962  0.4831452  0.53540254]\n",
      "[0.44665343 0.47133556 0.5591544 ]\n",
      "[0.46570194 0.4819261  0.5378631 ]\n",
      "[0.4555183  0.4762736  0.54925805]\n",
      "[0.4404443  0.46786168 0.56609523]\n",
      "[0.46132997 0.4795037  0.5427484 ]\n",
      "[0.4564886  0.47681457 0.5481715 ]\n",
      "[0.4530836  0.47492272 0.5519769 ]\n",
      "[0.4497005  0.47304595 0.555758  ]\n",
      "[0.46131778 0.47949407 0.54277456]\n",
      "[0.46185315 0.47978622 0.54218465]\n",
      "[0.46374607 0.48084646 0.5400425 ]\n",
      "[0.4533233  0.47505322 0.5516991 ]\n",
      "[0.44765043 0.47189522 0.5580543 ]\n",
      "[0.4745463  0.4868347  0.52795345]\n",
      "[0.45101702 0.47376615 0.5542982 ]\n",
      "[0.47139558 0.48508608 0.5314822 ]\n",
      "[0.45713595 0.47716817 0.547456  ]\n",
      "[0.42634052 0.4599494  0.5818274 ]\n",
      "[0.4687321 0.4836115 0.5344644]\n",
      "[0.42692104 0.46026206 0.58118045]\n",
      "[0.41743657 0.45492247 0.59175164]\n",
      "[0.46242693 0.48011518 0.5415135 ]\n",
      "[0.4540942 0.4754825 0.5508329]\n",
      "[0.46397218 0.4809703  0.5397959 ]\n",
      "[0.43245548 0.4633721  0.5750533 ]\n",
      "[0.45648116 0.47680834 0.5481851 ]\n",
      "[0.46609658 0.48215297 0.53741646]\n",
      "[0.4427744  0.46916038 0.56352663]\n",
      "[0.44891024 0.4725941  0.5566316 ]\n",
      "[0.44455624 0.4701519  0.5615394 ]\n",
      "[0.41757601 0.454988   0.591629  ]\n",
      "[0.45545796 0.47624457 0.54931283]\n",
      "[0.45799768 0.47765702 0.54647243]\n",
      "[0.44868225 0.47248796 0.5568526 ]\n",
      "[0.4639882 0.4809821 0.5397717]\n",
      "[0.45303196 0.47489166 0.552017  ]\n",
      "[0.44933474 0.4728469  0.5561519 ]\n",
      "[0.46336254 0.4806302  0.5404806 ]\n",
      "[0.4141815  0.45307782 0.59535694]\n",
      "[0.46815342 0.48328817 0.5351184 ]\n",
      "[0.45680186 0.47698966 0.5478153 ]\n",
      "[0.4185292  0.45553523 0.5905434 ]\n",
      "[0.46015948 0.478846   0.544068  ]\n",
      "[0.46070915 0.47915938 0.5434377 ]\n",
      "[0.46459615 0.4813182  0.53909343]\n",
      "[0.45646712 0.47680628 0.54817134]\n",
      "[0.40553552 0.44818437 0.6049416 ]\n",
      "[0.47703668 0.48821512 0.52516615]\n",
      "[0.46713433 0.48272488 0.5362552 ]\n",
      "[0.4562095  0.47664806 0.54850084]\n",
      "[0.45171696 0.47416306 0.5535053 ]\n",
      "[0.44580567 0.47086647 0.56011057]\n",
      "[0.44455338 0.47016984 0.56149834]\n",
      "[0.46571   0.4819299 0.5378583]\n",
      "[0.44958764 0.47296664 0.55589265]\n",
      "[0.46582437 0.4819986  0.5377169 ]\n",
      "[0.44024816 0.46774748 0.5663285 ]\n",
      "[0.46301058 0.48043707 0.5408699 ]\n",
      "[0.4354841  0.46508336 0.5716478 ]\n",
      "[0.4683186  0.4833815  0.53493184]\n",
      "[0.4549494  0.47594872 0.5499119 ]\n",
      "[0.45063436 0.47354856 0.55473155]\n",
      "[0.4308091  0.46245694 0.5768403 ]\n",
      "[0.45764682 0.47745743 0.54686725]\n",
      "[0.46651962 0.48238415 0.5369385 ]\n",
      "[0.45555446 0.47628206 0.54923874]\n",
      "[0.4581262 0.4777176 0.5463485]\n",
      "[0.39891446 0.44439712 0.61233914]\n",
      "[0.45492452 0.47594935 0.54989254]\n",
      "[0.41718334 0.45478812 0.59202504]\n",
      "[0.41392833 0.45293123 0.59566444]\n",
      "[0.4540523  0.47546428 0.5508959 ]\n",
      "[0.47453174 0.48682663 0.52797073]\n",
      "[0.41200027 0.4518383  0.5978112 ]\n",
      "[0.47238725 0.48563784 0.5303725 ]\n",
      "[0.4716831  0.4852494  0.53115624]\n",
      "[0.40656203 0.448753   0.6038571 ]\n",
      "[0.44935152 0.472846   0.5561409 ]\n",
      "[0.42782938 0.46077758 0.58019197]\n",
      "[0.4673713  0.48285162 0.5359966 ]\n",
      "[0.46064478 0.47913125 0.54348856]\n",
      "[0.45026237 0.47333616 0.5551589 ]\n",
      "[0.43910402 0.46710894 0.56761223]\n",
      "[0.45614627 0.47661963 0.54855937]\n",
      "[0.4607944  0.47920585 0.5433477 ]\n",
      "[0.4517969  0.47421426 0.5534126 ]\n",
      "[0.43814117 0.46657118 0.5686657 ]\n",
      "[0.46704572 0.4826746  0.53635335]\n",
      "[0.4728375  0.4858882  0.52986926]\n",
      "[0.40925306 0.45027122 0.60086477]\n",
      "[0.45954022 0.47850424 0.54476213]\n",
      "[0.4442187  0.46997464 0.5618885 ]\n",
      "[0.47131512 0.48504278 0.5315735 ]\n",
      "[0.44246182 0.4689974  0.563845  ]\n",
      "[0.45883965 0.4781182  0.5455487 ]\n",
      "[0.45617244 0.4766432  0.5485009 ]\n",
      "[0.4698153 0.4842143 0.5332431]\n",
      "[0.45975575 0.47862762 0.5445205 ]\n",
      "[0.45491844 0.47594327 0.5499213 ]\n",
      "[0.45396376 0.47541028 0.55099773]\n",
      "[0.46406364 0.481017   0.53969985]\n",
      "[0.45199084 0.47431287 0.553204  ]\n",
      "[0.44428372 0.47000933 0.5618087 ]\n",
      "[0.45199957 0.47431555 0.55317456]\n",
      "[0.42288527 0.4580041  0.5856774 ]\n",
      "[0.45418325 0.4755362  0.5507268 ]\n",
      "[0.44134763 0.46835738 0.56512195]\n",
      "[0.42842418 0.46112245 0.5795048 ]\n",
      "[0.45783496 0.47756678 0.5466418 ]\n",
      "[0.44349635 0.46957785 0.56268656]\n",
      "[0.46546054 0.48179823 0.53812337]\n",
      "[0.45496178 0.47596872 0.5498565 ]\n",
      "Accuracy: 50.26234984397888%\n",
      "5\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch', 'groupStudyHours']\n",
      "4\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch']\n",
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 1s 2ms/sample - loss: 1.0974 - accuracy: 0.4945\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0887 - accuracy: 0.5249\n",
      "[0.47482613 0.4966384  0.5249125 ]\n",
      "[0.4596763  0.49517488 0.53986526]\n",
      "[0.47469667 0.4966237  0.52503306]\n",
      "[0.45776877 0.49496716 0.5417761 ]\n",
      "[0.46034658 0.49522224 0.53921396]\n",
      "[0.4784768  0.49698967 0.5213033 ]\n",
      "[0.46711567 0.4958786  0.53252935]\n",
      "[0.45721292 0.49489945 0.54232967]\n",
      "[0.46872795 0.4960714  0.53091973]\n",
      "[0.46475527 0.49568152 0.5348379 ]\n",
      "[0.47008264 0.4961558  0.5295921 ]\n",
      "[0.47042963 0.4961811  0.5292647 ]\n",
      "[0.47261035 0.49641153 0.5271031 ]\n",
      "[0.47336155 0.4964753  0.5263573 ]\n",
      "[0.47391337 0.49654517 0.52581626]\n",
      "[0.47938073 0.49707597 0.5204095 ]\n",
      "[0.44312927 0.49355432 0.55623126]\n",
      "[0.46025705 0.49517378 0.5393185 ]\n",
      "[0.46456292 0.49565968 0.5350284 ]\n",
      "[0.45495418 0.4947283  0.5445341 ]\n",
      "[0.46195766 0.4954051  0.5376035 ]\n",
      "[0.444535   0.4936263  0.55488175]\n",
      "[0.46298176 0.49551642 0.5365884 ]\n",
      "[0.4599364  0.49520633 0.539606  ]\n",
      "[0.46337226 0.49553314 0.53620553]\n",
      "[0.47465503 0.49662393 0.5250716 ]\n",
      "[0.47337636 0.49646366 0.5263486 ]\n",
      "[0.4697689  0.49613205 0.52990925]\n",
      "[0.4712977  0.49629158 0.52839214]\n",
      "[0.48327735 0.4974342  0.5165678 ]\n",
      "[0.47733572 0.49688238 0.5224254 ]\n",
      "[0.46752298 0.4958745  0.53214526]\n",
      "[0.47333848 0.49648184 0.52638054]\n",
      "[0.47296768 0.49645653 0.5267425 ]\n",
      "[0.4634679  0.49548632 0.53614455]\n",
      "[0.47332427 0.49647844 0.5263868 ]\n",
      "[0.45722538 0.49494225 0.54228115]\n",
      "[0.45840093 0.4950494  0.5411121 ]\n",
      "[0.47700667 0.4968435  0.52275187]\n",
      "[0.47035474 0.49619386 0.5293251 ]\n",
      "[0.4676648  0.4959399  0.53198737]\n",
      "[0.4420201  0.49344647 0.5573277 ]\n",
      "[0.46878937 0.49604616 0.5308738 ]\n",
      "[0.4759413  0.49673358 0.5238039 ]\n",
      "[0.46076253 0.49528155 0.5387757 ]\n",
      "[0.47297475 0.49645415 0.5267259 ]\n",
      "[0.46695432 0.49586383 0.53268707]\n",
      "[0.45627934 0.4948398  0.5432229 ]\n",
      "[0.47101688 0.49626312 0.5286684 ]\n",
      "[0.466799   0.49585614 0.53283536]\n",
      "[0.46615893 0.49578542 0.5334761 ]\n",
      "[0.46527824 0.49569    0.5343599 ]\n",
      "[0.47223285 0.49636188 0.52747774]\n",
      "[0.47166714 0.49630353 0.5280306 ]\n",
      "[0.4719334  0.49635923 0.527762  ]\n",
      "[0.464562   0.49565467 0.5350289 ]\n",
      "[0.46257737 0.49543428 0.5370159 ]\n",
      "[0.48017624 0.4971478  0.5196255 ]\n",
      "[0.46348473 0.49552235 0.53611106]\n",
      "[0.47807142 0.49694428 0.5216993 ]\n",
      "[0.46884185 0.4960332  0.5308202 ]\n",
      "[0.44997168 0.4942075  0.54948294]\n",
      "[0.4770273  0.4968371  0.52273715]\n",
      "[0.44799677 0.49403328 0.5513982 ]\n",
      "[0.4440872  0.49363184 0.55529785]\n",
      "[0.4713732  0.49630725 0.5283129 ]\n",
      "[0.46551067 0.49574643 0.5340908 ]\n",
      "[0.47307774 0.4964569  0.5266374 ]\n",
      "[0.454663   0.4946121  0.54485905]\n",
      "[0.4686807  0.49601814 0.5309909 ]\n",
      "[0.47514397 0.49665573 0.5246002 ]\n",
      "[0.46020958 0.49516883 0.53936595]\n",
      "[0.46256545 0.49545094 0.53700244]\n",
      "[0.46215335 0.49534866 0.5374518 ]\n",
      "[0.4460883  0.49377638 0.5533469 ]\n",
      "[0.46988782 0.49613646 0.5297962 ]\n",
      "[0.46827152 0.49600527 0.53137773]\n",
      "[0.4649726  0.49568963 0.5346495 ]\n",
      "[0.47168395 0.496338   0.5280087 ]\n",
      "[0.46486622 0.4956846  0.5347268 ]\n",
      "[0.46405932 0.49559703 0.5355493 ]\n",
      "[0.4738177  0.49651864 0.5259099 ]\n",
      "[0.43935183 0.4932025  0.5599646 ]\n",
      "[0.47508848 0.49665442 0.5246458 ]\n",
      "[0.46886003 0.49604717 0.53080636]\n",
      "[0.44438422 0.49365655 0.5550073 ]\n",
      "[0.46984723 0.49614504 0.5298148 ]\n",
      "[0.47165146 0.49632296 0.52804255]\n",
      "[0.47353226 0.49650508 0.5261846 ]\n",
      "[0.46611223 0.49581575 0.5335014 ]\n",
      "[0.43517816 0.49281597 0.56408167]\n",
      "[0.48198476 0.4973205  0.51784116]\n",
      "[0.47554758 0.49669448 0.5241977 ]\n",
      "[0.46765167 0.49591407 0.53199345]\n",
      "[0.46521354 0.49569336 0.5344132 ]\n",
      "[0.46142823 0.49532834 0.5381539 ]\n",
      "[0.46105188 0.49529493 0.5385305 ]\n",
      "[0.47451398 0.49658662 0.52521676]\n",
      "[0.4654455 0.4956946 0.5341807]\n",
      "[0.4737398  0.49653152 0.5259755 ]\n",
      "[0.45769492 0.49495453 0.5418215 ]\n",
      "[0.47219104 0.49637452 0.5275114 ]\n",
      "[0.45591402 0.49476692 0.5436204 ]\n",
      "[0.47499657 0.49664977 0.5247378 ]\n",
      "[0.46880916 0.49600813 0.53086925]\n",
      "[0.46600825 0.4957419  0.53363127]\n",
      "[0.45056686 0.49428958 0.5488757 ]\n",
      "[0.4672892  0.49591386 0.53234273]\n",
      "[0.4743008  0.49658567 0.5254203 ]\n",
      "[0.46875125 0.4959982  0.530929  ]\n",
      "[0.47068924 0.49620417 0.5290023 ]\n",
      "[0.43305278 0.49253017 0.5662186 ]\n",
      "[0.46506602 0.49571598 0.5345335 ]\n",
      "[0.44551915 0.49377823 0.5538694 ]\n",
      "[0.44123054 0.4933417  0.5581298 ]\n",
      "[0.467747   0.49592996 0.531917  ]\n",
      "[0.47949886 0.49708658 0.52029276]\n",
      "[0.4394748  0.49318805 0.5598464 ]\n",
      "[0.4771233  0.4968635  0.52263486]\n",
      "[0.4768849  0.49684212 0.5228713 ]\n",
      "[0.43740618 0.49295014 0.56191796]\n",
      "[0.46138626 0.49534443 0.5381774 ]\n",
      "[0.44894433 0.49411014 0.55048794]\n",
      "[0.4743809  0.49658778 0.52533805]\n",
      "[0.46824136 0.4960287  0.53140163]\n",
      "[0.46429074 0.49556383 0.5353341 ]\n",
      "[0.45837638 0.49500218 0.54118276]\n",
      "[0.46842712 0.4959961  0.53123367]\n",
      "[0.47109598 0.49626786 0.5285903 ]\n",
      "[0.4655521  0.49573225 0.5340775 ]\n",
      "[0.4547343  0.49469063 0.5447516 ]\n",
      "[0.4743564  0.49658805 0.52536744]\n",
      "[0.4784623  0.49698555 0.5213182 ]\n",
      "[0.43722963 0.49296218 0.56206065]\n",
      "[0.4710106  0.4962428  0.52867746]\n",
      "[0.46140903 0.49531382 0.53817266]\n",
      "[0.47823957 0.49695766 0.52153754]\n",
      "[0.45957083 0.49514815 0.5399908 ]\n",
      "[0.46977735 0.49612677 0.52989954]\n",
      "[0.46547353 0.4957558  0.5341325 ]\n",
      "[0.4761405  0.49676982 0.52360475]\n",
      "[0.47043425 0.4961939  0.52925336]\n",
      "[0.46874315 0.49602747 0.530924  ]\n",
      "[0.46795347 0.49594575 0.5317099 ]\n",
      "[0.47318313 0.49646038 0.5265307 ]\n",
      "[0.46523386 0.49569124 0.5343885 ]\n",
      "[0.4591893  0.49512103 0.54033166]\n",
      "[0.46434397 0.49563146 0.53524095]\n",
      "[0.4493338  0.49413761 0.5501187 ]\n",
      "[0.463992   0.49561307 0.53559375]\n",
      "[0.4605514  0.4951916  0.53903466]\n",
      "[0.45181292 0.49438614 0.54766524]\n",
      "[0.46709827 0.49591067 0.53252864]\n",
      "[0.4611067 0.4952909 0.5384797]\n",
      "[0.47328714 0.4964888  0.5264265 ]\n",
      "[0.4648476  0.49569395 0.534749  ]\n",
      "Accuracy: 50.35524368286133%\n",
      "4\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ', 'batch']\n",
      "3\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 1s 2ms/sample - loss: 1.0972 - accuracy: 0.5249\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 1.0887 - accuracy: 0.5249\n",
      "[0.47140878 0.49049973 0.5239971 ]\n",
      "[0.4603594  0.48706087 0.5331083 ]\n",
      "[0.4737461  0.49124658 0.5220568 ]\n",
      "[0.4388064  0.48027477 0.550962  ]\n",
      "[0.45452306 0.48524147 0.53792703]\n",
      "[0.47983268 0.4931266  0.51706344]\n",
      "[0.46177033 0.48750317 0.53194094]\n",
      "[0.43868947 0.48026198 0.55103374]\n",
      "[0.47900468 0.492876   0.51774   ]\n",
      "[0.47376868 0.4912601  0.52203375]\n",
      "[0.46710038 0.4891885  0.5275264 ]\n",
      "[0.45927006 0.48674238 0.53398895]\n",
      "[0.46622312 0.48889196 0.52826416]\n",
      "[0.46923178 0.48985308 0.525764  ]\n",
      "[0.4695579  0.48992014 0.52552414]\n",
      "[0.4802798  0.49327144 0.5166936 ]\n",
      "[0.4156316  0.47292492 0.570213  ]\n",
      "[0.445261   0.48237047 0.5455661 ]\n",
      "[0.4736592  0.49122238 0.5221252 ]\n",
      "[0.45269608 0.4846483  0.53945553]\n",
      "[0.4681605  0.48950458 0.52665895]\n",
      "[0.41184473 0.47174367 0.5733323 ]\n",
      "[0.47155374 0.4905662  0.52385604]\n",
      "[0.45923492 0.4867181  0.53402734]\n",
      "[0.46827215 0.4895504  0.5265598 ]\n",
      "[0.47815076 0.49261233 0.51843864]\n",
      "[0.46738255 0.4892793  0.5272916 ]\n",
      "[0.4643401  0.48831084 0.52981454]\n",
      "[0.4707576  0.49030757 0.52451974]\n",
      "[0.478167   0.49262396 0.51842266]\n",
      "[0.48141348 0.4936276  0.51575804]\n",
      "[0.4558975  0.48571774 0.5367668 ]\n",
      "[0.47054166 0.49024257 0.52469623]\n",
      "[0.47311464 0.49103794 0.5225802 ]\n",
      "[0.4524544  0.48467302 0.539583  ]\n",
      "[0.472952   0.49101385 0.5227025 ]\n",
      "[0.4592834  0.48673615 0.53398824]\n",
      "[0.46158886 0.48748755 0.53206164]\n",
      "[0.47602847 0.49196118 0.5201785 ]\n",
      "[0.46837616 0.48956951 0.5264827 ]\n",
      "[0.46226078 0.48764375 0.5315468 ]\n",
      "[0.41350073 0.47224113 0.57199067]\n",
      "[0.46441817 0.48832646 0.5297558 ]\n",
      "[0.4758912  0.49192226 0.5202894 ]\n",
      "[0.46771577 0.48939085 0.52701133]\n",
      "[0.47359842 0.4912337  0.5221628 ]\n",
      "[0.46163827 0.48746747 0.53204554]\n",
      "[0.45430833 0.48517656 0.53810275]\n",
      "[0.4698767  0.49004164 0.52523947]\n",
      "[0.46309978 0.48792753 0.53083354]\n",
      "[0.45901722 0.48664072 0.53421646]\n",
      "[0.45088524 0.48407832 0.5409543 ]\n",
      "[0.46517175 0.48858422 0.5291167 ]\n",
      "[0.46540207 0.48867884 0.52891135]\n",
      "[0.47290388 0.49097446 0.5227525 ]\n",
      "[0.47126472 0.49048045 0.5240917 ]\n",
      "[0.45318887 0.48482308 0.5390294 ]\n",
      "[0.48046803 0.49332944 0.516537  ]\n",
      "[0.45679894 0.48598218 0.53602207]\n",
      "[0.478682   0.49279195 0.51799583]\n",
      "[0.46379185 0.48816255 0.5302522 ]\n",
      "[0.4251762  0.47595528 0.56227934]\n",
      "[0.4749401  0.49161512 0.5210756 ]\n",
      "[0.44379735 0.48191732 0.54676676]\n",
      "[0.4163409 0.4731492 0.5696185]\n",
      "[0.47275463 0.49093306 0.5228727 ]\n",
      "[0.473667   0.49123073 0.522117  ]\n",
      "[0.4703242  0.49017707 0.52487385]\n",
      "[0.43086922 0.47782415 0.55749744]\n",
      "[0.4603594  0.48706087 0.5331083 ]\n",
      "[0.47037292 0.4901844  0.5248391 ]\n",
      "[0.4449621  0.48227388 0.5458154 ]\n",
      "[0.46618164 0.48890567 0.5282808 ]\n",
      "[0.4491572 0.483626  0.5423268]\n",
      "[0.41405886 0.47245526 0.57148606]\n",
      "[0.4609695  0.4872647  0.53259236]\n",
      "[0.466498   0.48898596 0.5280291 ]\n",
      "[0.4579823  0.48629454 0.53509986]\n",
      "[0.47184008 0.49064282 0.5236296 ]\n",
      "[0.4721092 0.4907474 0.5233964]\n",
      "[0.4515976  0.48430055 0.5403764 ]\n",
      "[0.4690674  0.48979166 0.52590686]\n",
      "[0.4216339  0.47482908 0.5652274 ]\n",
      "[0.4738762  0.49130067 0.52194273]\n",
      "[0.46420336 0.48826247 0.52993184]\n",
      "[0.4195574  0.47418478 0.5669313 ]\n",
      "[0.4697335  0.49003777 0.5253369 ]\n",
      "[0.4710681  0.49040684 0.52426183]\n",
      "[0.47131228 0.4904931  0.5240535 ]\n",
      "[0.4773348  0.49235857 0.5191088 ]\n",
      "[0.41582555 0.47297755 0.57007456]\n",
      "[0.48087323 0.49345684 0.5162053 ]\n",
      "[0.474024   0.4913265  0.52182937]\n",
      "[0.46122068 0.4873916  0.53235155]\n",
      "[0.45654398 0.48585868 0.53626734]\n",
      "[0.4503031  0.48390153 0.5414305 ]\n",
      "[0.4477527  0.48308432 0.5435595 ]\n",
      "[0.47139418 0.49053046 0.523982  ]\n",
      "[0.4579897 0.4863491 0.5350476]\n",
      "[0.47607085 0.49196956 0.52014506]\n",
      "[0.45568702 0.48565376 0.53693914]\n",
      "[0.47054166 0.49024257 0.52469623]\n",
      "[0.43302685 0.47845596 0.55574536]\n",
      "[0.47416922 0.49137694 0.52170855]\n",
      "[0.45775545 0.4862779  0.5352397 ]\n",
      "[0.4553722  0.48553112 0.5372095 ]\n",
      "[0.44265234 0.4814905  0.5477696 ]\n",
      "[0.46965298 0.48997393 0.5254223 ]\n",
      "[0.4771906  0.49232057 0.51922387]\n",
      "[0.4583699  0.48649722 0.5347162 ]\n",
      "[0.46295223 0.48789695 0.5309481 ]\n",
      "[0.39674804 0.4668507  0.5859631 ]\n",
      "[0.47575247 0.49186778 0.5204083 ]\n",
      "[0.41675666 0.4733037  0.5692564 ]\n",
      "[0.4124173  0.47189552 0.57288307]\n",
      "[0.45654398 0.48585868 0.53626734]\n",
      "[0.48006463 0.4932061  0.5168693 ]\n",
      "[0.41379485 0.47236145 0.5717155 ]\n",
      "[0.47915506 0.4929296  0.5176141 ]\n",
      "[0.47933498 0.49298    0.51746976]\n",
      "[0.39996064 0.4678933  0.58327323]\n",
      "[0.4601106  0.48698473 0.5333108 ]\n",
      "[0.42746252 0.4767188  0.5603444 ]\n",
      "[0.4743437  0.49146762 0.52154964]\n",
      "[0.4807983  0.49343008 0.5162707 ]\n",
      "[0.4526737  0.48473543 0.5394075 ]\n",
      "[0.44115815 0.48104256 0.5489888 ]\n",
      "[0.46195593 0.4875835  0.5317707 ]\n",
      "[0.46897328 0.48976824 0.5259781 ]\n",
      "[0.45419377 0.48512176 0.53821564]\n",
      "[0.4516996 0.4843518 0.5402653]\n",
      "[0.47461733 0.4915247  0.521336  ]\n",
      "[0.47747654 0.49239928 0.51899767]\n",
      "[0.41975677 0.4742858  0.56673396]\n",
      "[0.46744266 0.4893028  0.52723855]\n",
      "[0.4504097 0.4839613 0.5413212]\n",
      "[0.47790602 0.49253765 0.51863885]\n",
      "[0.4435974  0.48178884 0.54698884]\n",
      "[0.46241915 0.48773518 0.53138113]\n",
      "[0.47506663 0.49164852 0.52097505]\n",
      "[0.48141345 0.4936276  0.51575804]\n",
      "[0.46460813 0.48839465 0.52959335]\n",
      "[0.46030003 0.48706165 0.5331398 ]\n",
      "[0.45814955 0.48637947 0.53492665]\n",
      "[0.4703116  0.49019122 0.52487236]\n",
      "[0.45701203 0.4860323  0.5358579 ]\n",
      "[0.46305177 0.48794731 0.53085387]\n",
      "[0.47156876 0.49058405 0.52383924]\n",
      "[0.4232189  0.47533298 0.5639046 ]\n",
      "[0.47382292 0.49126533 0.5219949 ]\n",
      "[0.44584665 0.482578   0.5450699 ]\n",
      "[0.42903042 0.4771763  0.55907947]\n",
      "[0.4788558  0.4928274  0.51786095]\n",
      "[0.4456217  0.4824211  0.54531497]\n",
      "[0.4746873  0.49152562 0.5212884 ]\n",
      "[0.4752343  0.4917076  0.52083343]\n",
      "Accuracy: 50.199294090270996%\n",
      "3\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ']\n",
      "2\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays']\n",
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 0s 785us/sample - loss: 1.0978 - accuracy: 0.4834\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 1.0951 - accuracy: 0.5249\n",
      "[0.490636   0.49598584 0.5094484 ]\n",
      "[0.4908853  0.4960385  0.50920457]\n",
      "[0.4913131  0.49612904 0.50878483]\n",
      "[0.4867545  0.49516034 0.5132968 ]\n",
      "[0.49029073 0.4959121  0.5097893 ]\n",
      "[0.4923249  0.49634203 0.50779486]\n",
      "[0.4907361 0.496007  0.5093503]\n",
      "[0.48743632 0.49530512 0.5126154 ]\n",
      "[0.49212047 0.49629954 0.5079941 ]\n",
      "[0.49216765 0.49630925 0.5079483 ]\n",
      "[0.49257454 0.49639386 0.50755185]\n",
      "[0.4902774  0.49590972 0.50980026]\n",
      "[0.49048388 0.49595362 0.5095978 ]\n",
      "[0.49191704 0.49625704 0.50819266]\n",
      "[0.4907361 0.496007  0.5093503]\n",
      "[0.49227196 0.496331   0.5078466 ]\n",
      "[0.48274553 0.49431282 0.5172852 ]\n",
      "[0.49048826 0.4959545  0.50959337]\n",
      "[0.49247405 0.496373   0.50764954]\n",
      "[0.488662   0.49556458 0.5113982 ]\n",
      "[0.49177712 0.49622732 0.5083299 ]\n",
      "[0.4854841  0.49489138 0.51456285]\n",
      "[0.4913661  0.49614027 0.5087328 ]\n",
      "[0.489634   0.49577284 0.51043373]\n",
      "[0.49227473 0.49633163 0.5078436 ]\n",
      "[0.49242315 0.49636242 0.50769925]\n",
      "[0.49262413 0.49640414 0.50750345]\n",
      "[0.4910823  0.49608034 0.50901073]\n",
      "[0.49177712 0.49622732 0.5083299 ]\n",
      "[0.49200764 0.49627587 0.5081045 ]\n",
      "[0.4927215 0.4964243 0.5074088]\n",
      "[0.4925737  0.49639365 0.50755256]\n",
      "[0.49172682 0.4962168  0.50837904]\n",
      "[0.49172682 0.4962168  0.50837904]\n",
      "[0.4917009  0.49621022 0.5084101 ]\n",
      "[0.49261653 0.4964024  0.50751114]\n",
      "[0.490636   0.49598584 0.5094484 ]\n",
      "[0.4914557  0.49615923 0.5086451 ]\n",
      "[0.49170467 0.49621198 0.50840104]\n",
      "[0.49182716 0.49623778 0.5082812 ]\n",
      "[0.49014202 0.49588042 0.5099356 ]\n",
      "[0.48240376 0.4942404  0.51762605]\n",
      "[0.490636   0.49598584 0.5094484 ]\n",
      "[0.49266937 0.49641344 0.5074596 ]\n",
      "[0.49266937 0.49641344 0.5074596 ]\n",
      "[0.49175546 0.49622208 0.5083561 ]\n",
      "[0.49058554 0.49597517 0.50949794]\n",
      "[0.490241   0.49590158 0.5098379 ]\n",
      "[0.49157402 0.49618444 0.5085289 ]\n",
      "[0.49032903 0.49592072 0.50974965]\n",
      "[0.49014136 0.4958805  0.50993544]\n",
      "[0.48880976 0.49559578 0.5112531 ]\n",
      "[0.49127337 0.49612072 0.50882363]\n",
      "[0.4916398  0.49619815 0.5084654 ]\n",
      "[0.49167618 0.49620613 0.5084287 ]\n",
      "[0.4923235  0.49634174 0.5077963 ]\n",
      "[0.48954606 0.49575356 0.5105225 ]\n",
      "[0.4925737  0.49639365 0.50755256]\n",
      "[0.49006748 0.49586517 0.5100063 ]\n",
      "[0.49245435 0.49636865 0.5076695 ]\n",
      "[0.4919221  0.49625808 0.50818783]\n",
      "[0.4848976  0.4947673  0.51514685]\n",
      "[0.49222386 0.49632105 0.50789326]\n",
      "[0.488633  0.4955597 0.5114222]\n",
      "[0.48372397 0.49451932 0.51631373]\n",
      "[0.4915224  0.49617347 0.5085795 ]\n",
      "[0.492773   0.49643502 0.50735855]\n",
      "[0.49167618 0.49620613 0.5084287 ]\n",
      "[0.488859   0.49560618 0.5112047 ]\n",
      "[0.4908853  0.4960385  0.50920457]\n",
      "[0.49122983 0.4961116  0.50886625]\n",
      "[0.490439   0.49594387 0.5096425 ]\n",
      "[0.4921726  0.49631038 0.50794333]\n",
      "[0.49231213 0.49633917 0.5078078 ]\n",
      "[0.4858751  0.4949741  0.51417345]\n",
      "[0.49043226 0.49594265 0.5096484 ]\n",
      "[0.4904746  0.49595147 0.50960684]\n",
      "[0.488859   0.49560618 0.5112047 ]\n",
      "[0.4911276 0.4960899 0.5089665]\n",
      "[0.49247065 0.49637222 0.5076531 ]\n",
      "[0.4875358  0.49532598 0.5125168 ]\n",
      "[0.49192542 0.49625865 0.5081846 ]\n",
      "[0.48387077 0.4945503  0.516168  ]\n",
      "[0.491748   0.49622113 0.5083587 ]\n",
      "[0.49108303 0.49608046 0.50901026]\n",
      "[0.48465222 0.49471584 0.51538885]\n",
      "[0.49190727 0.496254   0.5082074 ]\n",
      "[0.49202597 0.49627972 0.5080865 ]\n",
      "[0.4913131  0.49612904 0.50878483]\n",
      "[0.49247405 0.496373   0.50764954]\n",
      "[0.48157346 0.49406457 0.51845336]\n",
      "[0.49237132 0.4963516  0.50774986]\n",
      "[0.49237505 0.49635246 0.50774616]\n",
      "[0.49131355 0.49612874 0.50878793]\n",
      "[0.48974603 0.49579588 0.5103265 ]\n",
      "[0.488662   0.49556458 0.5113982 ]\n",
      "[0.48792854 0.4954083  0.5121295 ]\n",
      "[0.49231213 0.49633917 0.5078078 ]\n",
      "[0.49187723 0.49624828 0.5082324 ]\n",
      "[0.49242315 0.49636242 0.50769925]\n",
      "[0.49252278 0.49638307 0.5076023 ]\n",
      "[0.49172682 0.4962168  0.50837904]\n",
      "[0.48685268 0.4951809  0.5131999 ]\n",
      "[0.49166793 0.49620426 0.50843686]\n",
      "[0.49182716 0.49623778 0.5082812 ]\n",
      "[0.49138027 0.4961434  0.50871885]\n",
      "[0.48783037 0.49538773 0.51222634]\n",
      "[0.4915224  0.49617347 0.5085795 ]\n",
      "[0.49262214 0.4964037  0.50750554]\n",
      "[0.49245435 0.49636865 0.5076695 ]\n",
      "[0.4917753 0.4962271 0.5083316]\n",
      "[0.48206404 0.49416745 0.51796955]\n",
      "[0.4921726  0.49631038 0.50794333]\n",
      "[0.48303258 0.4943743  0.5169972 ]\n",
      "[0.48392025 0.49456048 0.51612014]\n",
      "[0.48974603 0.49579588 0.5103265 ]\n",
      "[0.49221984 0.49632013 0.5078974 ]\n",
      "[0.48308235 0.49438474 0.51694787]\n",
      "[0.491856   0.49624404 0.5082527 ]\n",
      "[0.49191704 0.49625704 0.50819266]\n",
      "[0.48260123 0.49428126 0.5174341 ]\n",
      "[0.48984048 0.49581665 0.51023144]\n",
      "[0.4849846  0.49478734 0.5150539 ]\n",
      "[0.491798   0.49623036 0.5083153 ]\n",
      "[0.49222386 0.49632105 0.50789326]\n",
      "[0.49176794 0.49622506 0.50834227]\n",
      "[0.488859   0.49560618 0.5112047 ]\n",
      "[0.491076   0.49607894 0.5090171 ]\n",
      "[0.4913661  0.49614027 0.5087328 ]\n",
      "[0.48846346 0.49552262 0.5115938 ]\n",
      "[0.48979574 0.49580637 0.5102779 ]\n",
      "[0.49190947 0.49625537 0.5082002 ]\n",
      "[0.49177143 0.49622625 0.5083354 ]\n",
      "[0.48587176 0.49497432 0.5141725 ]\n",
      "[0.49262214 0.4964037  0.50750554]\n",
      "[0.48949564 0.4957429  0.510572  ]\n",
      "[0.4925737  0.49639365 0.50755256]\n",
      "[0.48719382 0.49525353 0.51285785]\n",
      "[0.49061075 0.49598017 0.50947344]\n",
      "[0.4918746 0.496248  0.5082344]\n",
      "[0.4927215 0.4964243 0.5074088]\n",
      "[0.49123144 0.49611193 0.5088646 ]\n",
      "[0.4902774  0.49590972 0.50980026]\n",
      "[0.49043807 0.49594387 0.50964266]\n",
      "[0.49211463 0.49629822 0.508     ]\n",
      "[0.48988283 0.4958259  0.51018846]\n",
      "[0.49225825 0.49632797 0.50786036]\n",
      "[0.49266937 0.49641344 0.5074596 ]\n",
      "[0.48499578 0.49478787 0.51505005]\n",
      "[0.4918231  0.49623722 0.50828475]\n",
      "[0.49162567 0.49619544 0.5084783 ]\n",
      "[0.48558226 0.49491197 0.51446605]\n",
      "[0.4926743  0.49641454 0.5074547 ]\n",
      "[0.48792812 0.49540842 0.51212895]\n",
      "[0.49202597 0.49627972 0.5080865 ]\n",
      "[0.49217263 0.49631035 0.50794333]\n",
      "Accuracy: 49.995020031929016%\n",
      "2\n",
      "['goThroughCourseMaterial', 'studentAbsenceDays']\n",
      "1\n",
      "['goThroughCourseMaterial']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 362 samples\n",
      "Epoch 1/2\n",
      "362/362 [==============================] - 0s 831us/sample - loss: 1.0977 - accuracy: 0.4917\n",
      "Epoch 2/2\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 1.0952 - accuracy: 0.5249\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49026456 0.4910872  0.5115836 ]\n",
      "[0.49216405 0.49393782 0.5087227 ]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49080727 0.4919016  0.51076627]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.49333665 0.49559623 0.5069926 ]\n",
      "[0.4933945  0.49567172 0.5069098 ]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.4932205 0.4954451 0.5071582]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49333665 0.49559623 0.5069926 ]\n",
      "[0.48825684 0.4880743  0.5146072 ]\n",
      "[0.4923269  0.49418217 0.50847745]\n",
      "[0.4933945  0.49567172 0.5069098 ]\n",
      "[0.49134997 0.49271604 0.5099489 ]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.48950484 0.48994708 0.5127278 ]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49210978 0.49385637 0.50880444]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.4933945  0.49567172 0.5069098 ]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49265254 0.4946709  0.50798696]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49333665 0.49559623 0.5069926 ]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49350938 0.49582234 0.50674427]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.4932205 0.4954451 0.5071582]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49210978 0.49385637 0.50880444]\n",
      "[0.48803982 0.48774862 0.514934  ]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.49350938 0.49582234 0.50674427]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49216405 0.49393782 0.5087227 ]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49216405 0.49393782 0.5087227 ]\n",
      "[0.49134997 0.49271604 0.5099489 ]\n",
      "[0.492875   0.49498752 0.50765574]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49333665 0.49559623 0.5069926 ]\n",
      "[0.4918927  0.49353054 0.50913143]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.49316245 0.49536952 0.5072411 ]\n",
      "[0.48917928 0.4894585  0.5132181 ]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.49178416 0.49336764 0.5092949 ]\n",
      "[0.48863667 0.48864424 0.5140352 ]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49134997 0.49271604 0.5099489 ]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.49276257 0.49483106 0.5078221 ]\n",
      "[0.49227262 0.49410072 0.5085592 ]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.4897219  0.49027282 0.51240087]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.492544   0.494508   0.50815046]\n",
      "[0.49134997 0.49271604 0.5099489 ]\n",
      "[0.49276257 0.49483106 0.5078221 ]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49080727 0.4919016  0.51076627]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.4886909  0.48872566 0.5139535 ]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.49259827 0.49458945 0.5080687 ]\n",
      "[0.48917928 0.4894585  0.5132181 ]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.4933945  0.49567172 0.5069098 ]\n",
      "[0.4875515 0.4870159 0.5156693]\n",
      "[0.4933945  0.49567172 0.5069098 ]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.4918927  0.49353054 0.50913143]\n",
      "[0.49134997 0.49271604 0.5099489 ]\n",
      "[0.49080727 0.4919016  0.51076627]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.4933945  0.49567172 0.5069098 ]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49026456 0.4910872  0.5115836 ]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49276257 0.49483106 0.5078221 ]\n",
      "[0.49080727 0.4919016  0.51076627]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49350938 0.49582234 0.50674427]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.4930463 0.4952184 0.5074067]\n",
      "[0.4875515 0.4870159 0.5156693]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.48863667 0.48864424 0.5140352 ]\n",
      "[0.48863667 0.48864424 0.5140352 ]\n",
      "[0.4918927  0.49353054 0.50913143]\n",
      "[0.49333665 0.49559623 0.5069926 ]\n",
      "[0.48863667 0.48864424 0.5140352 ]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.4932205 0.4954451 0.5071582]\n",
      "[0.48787704 0.4875044  0.5151791 ]\n",
      "[0.49210978 0.49385637 0.50880444]\n",
      "[0.4897219  0.49027282 0.51240087]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49134997 0.49271604 0.5099489 ]\n",
      "[0.49276257 0.49483106 0.5078221 ]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.49134997 0.49271604 0.5099489 ]\n",
      "[0.4918927  0.49353054 0.50913143]\n",
      "[0.4932786  0.49552065 0.5070754 ]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.48999324 0.49067998 0.5119923 ]\n",
      "[0.49350938 0.49582234 0.50674427]\n",
      "[0.4918927  0.49353054 0.50913143]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49059018 0.49157584 0.5110932 ]\n",
      "[0.4927068  0.49475235 0.5079052 ]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.4927068  0.49475235 0.5079052 ]\n",
      "[0.49243543 0.49434507 0.50831395]\n",
      "[0.4923269  0.49418217 0.50847745]\n",
      "[0.49333665 0.49559623 0.5069926 ]\n",
      "[0.49221835 0.49401927 0.50864094]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49356666 0.49589756 0.50666153]\n",
      "[0.48917928 0.4894585  0.5132181 ]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.49298826 0.49514285 0.5074895 ]\n",
      "[0.48950484 0.48994708 0.5127278 ]\n",
      "[0.4934521  0.49574712 0.50682706]\n",
      "[0.49086154 0.49198303 0.51068455]\n",
      "[0.4931044  0.49529397 0.50732386]\n",
      "[0.49327853 0.49552068 0.50707537]\n",
      "Accuracy: 50.0%\n",
      "1\n",
      "['goThroughCourseMaterial']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "acc =0\n",
    "j= 0\n",
    "test_columns = len(feature_column_names)\n",
    "featureNo = 10\n",
    "\n",
    "while j < test_columns:\n",
    "    # Initialising the ANN\n",
    "    # Initialising the ANN\n",
    "  print(feature_column_names)\n",
    "  classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "  classifier.add(Dense(units = 70, kernel_initializer = 'uniform', activation = 'relu', input_dim = featureNo))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "  classifier.add(Dense(units = 66, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "  classifier.add(Dense(units = 60, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the fourth hidden layer\n",
    "  classifier.add(Dense(units = 56, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the fifth hidden layer\n",
    "  classifier.add(Dense(units = 48, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "  classifier.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "  classifier.compile(Adam(lr=.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "  classifier.fit(X_train, y_train, batch_size =42 , epochs = 2)\n",
    "  \n",
    "  \n",
    "\n",
    "  # Predicting the Test set results\n",
    "  predictions = classifier.predict(X_test)\n",
    "  \n",
    "  for p in predictions:\n",
    "    print(p)\n",
    "\n",
    "  accuracy = (predictions[0][0]+predictions[1][1])/(predictions[0][0]+predictions[0][1]+predictions[1][0]+predictions[1][1])\n",
    "  acc = str(accuracy*100)\n",
    "  print(\"Accuracy: \"+ acc+\"%\")\n",
    "    \n",
    "  \n",
    "  \n",
    "    \n",
    "  print(featureNo)\n",
    "  print(feature_column_names)\n",
    "  feature_column_names.pop()\n",
    "  featureNo -= 1\n",
    "  print(featureNo)\n",
    "  X = final_data_frame[feature_column_names].values\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "  j += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = ['goThroughCourseMaterial','studentAbsenceDays','questionsAskedInTheClassroom ']\n",
    "                        \n",
    "predicted_class_name = ['Class']\n",
    "\n",
    "# Getting feature variable values\n",
    "X = final_data_frame[feature_column_names].values\n",
    "y = final_data_frame[predicted_class_name].values\n",
    "\n",
    "# Saving 30% for testing\n",
    "split_test_size = 0.30\n",
    "\n",
    "# Splitting using scikit-learn train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.88% in training set\n",
      "30.12% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(data_frame.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_test)/len(data_frame.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goThroughCourseMaterial', 'studentAbsenceDays', 'questionsAskedInTheClassroom ']\n",
      "Train on 362 samples\n",
      "Epoch 1/600\n",
      "362/362 [==============================] - 0s 891us/sample - loss: 1.0977 - accuracy: 0.4890\n",
      "Epoch 2/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0929 - accuracy: 0.5249\n",
      "Epoch 3/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0704 - accuracy: 0.5249\n",
      "Epoch 4/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0377 - accuracy: 0.5249\n",
      "Epoch 5/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0308 - accuracy: 0.5249\n",
      "Epoch 6/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0302 - accuracy: 0.5249\n",
      "Epoch 7/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 1.0307 - accuracy: 0.5249\n",
      "Epoch 8/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 1.0257 - accuracy: 0.5249\n",
      "Epoch 9/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0237 - accuracy: 0.5249\n",
      "Epoch 10/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0227 - accuracy: 0.5249\n",
      "Epoch 11/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 1.0220 - accuracy: 0.5249\n",
      "Epoch 12/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0195 - accuracy: 0.5249\n",
      "Epoch 13/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0184 - accuracy: 0.5249\n",
      "Epoch 14/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 1.0173 - accuracy: 0.5249\n",
      "Epoch 15/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0161 - accuracy: 0.5249\n",
      "Epoch 16/600\n",
      "362/362 [==============================] - 0s 173us/sample - loss: 1.0146 - accuracy: 0.5249\n",
      "Epoch 17/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0152 - accuracy: 0.5249\n",
      "Epoch 18/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 1.0131 - accuracy: 0.5249\n",
      "Epoch 19/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0099 - accuracy: 0.5249\n",
      "Epoch 20/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 1.0089 - accuracy: 0.5249\n",
      "Epoch 21/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0070 - accuracy: 0.5249\n",
      "Epoch 22/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 1.0060 - accuracy: 0.5249\n",
      "Epoch 23/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 1.0026 - accuracy: 0.5249\n",
      "Epoch 24/600\n",
      "362/362 [==============================] - 0s 173us/sample - loss: 1.0029 - accuracy: 0.5249\n",
      "Epoch 25/600\n",
      "362/362 [==============================] - 0s 173us/sample - loss: 1.0003 - accuracy: 0.5249\n",
      "Epoch 26/600\n",
      "362/362 [==============================] - 0s 191us/sample - loss: 0.9984 - accuracy: 0.5249\n",
      "Epoch 27/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9977 - accuracy: 0.5249\n",
      "Epoch 28/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9966 - accuracy: 0.5249\n",
      "Epoch 29/600\n",
      "362/362 [==============================] - 0s 191us/sample - loss: 0.9985 - accuracy: 0.5249\n",
      "Epoch 30/600\n",
      "362/362 [==============================] - 0s 173us/sample - loss: 0.9940 - accuracy: 0.5249\n",
      "Epoch 31/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9958 - accuracy: 0.5249\n",
      "Epoch 32/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9933 - accuracy: 0.5249\n",
      "Epoch 33/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9930 - accuracy: 0.5249\n",
      "Epoch 34/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 0.9931 - accuracy: 0.5249\n",
      "Epoch 35/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 0.9932 - accuracy: 0.5249\n",
      "Epoch 36/600\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 0.9926 - accuracy: 0.5249\n",
      "Epoch 37/600\n",
      "362/362 [==============================] - 0s 173us/sample - loss: 0.9929 - accuracy: 0.5249\n",
      "Epoch 38/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9924 - accuracy: 0.5249\n",
      "Epoch 39/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9913 - accuracy: 0.5249\n",
      "Epoch 40/600\n",
      "362/362 [==============================] - 0s 173us/sample - loss: 0.9928 - accuracy: 0.5249\n",
      "Epoch 41/600\n",
      "362/362 [==============================] - 0s 191us/sample - loss: 0.9899 - accuracy: 0.5249\n",
      "Epoch 42/600\n",
      "362/362 [==============================] - 0s 191us/sample - loss: 0.9920 - accuracy: 0.5249\n",
      "Epoch 43/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 0.9905 - accuracy: 0.5249\n",
      "Epoch 44/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9912 - accuracy: 0.5249\n",
      "Epoch 45/600\n",
      "362/362 [==============================] - 0s 191us/sample - loss: 0.9908 - accuracy: 0.5249\n",
      "Epoch 46/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9904 - accuracy: 0.5249\n",
      "Epoch 47/600\n",
      "362/362 [==============================] - 0s 173us/sample - loss: 0.9899 - accuracy: 0.5249\n",
      "Epoch 48/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 0.9909 - accuracy: 0.5249\n",
      "Epoch 49/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9915 - accuracy: 0.5249\n",
      "Epoch 50/600\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 0.9914 - accuracy: 0.5249\n",
      "Epoch 51/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9895 - accuracy: 0.5249\n",
      "Epoch 52/600\n",
      "362/362 [==============================] - 0s 191us/sample - loss: 0.9898 - accuracy: 0.5249\n",
      "Epoch 53/600\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 0.9894 - accuracy: 0.5249\n",
      "Epoch 54/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9903 - accuracy: 0.5249\n",
      "Epoch 55/600\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 0.9898 - accuracy: 0.5249\n",
      "Epoch 56/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9895 - accuracy: 0.5249\n",
      "Epoch 57/600\n",
      "362/362 [==============================] - 0s 191us/sample - loss: 0.9911 - accuracy: 0.5249\n",
      "Epoch 58/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9897 - accuracy: 0.5249\n",
      "Epoch 59/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9899 - accuracy: 0.5249\n",
      "Epoch 60/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9888 - accuracy: 0.5249\n",
      "Epoch 61/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9903 - accuracy: 0.5249\n",
      "Epoch 62/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9886 - accuracy: 0.5249\n",
      "Epoch 63/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9889 - accuracy: 0.5249\n",
      "Epoch 64/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9883 - accuracy: 0.5249\n",
      "Epoch 65/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9904 - accuracy: 0.5249\n",
      "Epoch 66/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9889 - accuracy: 0.5249\n",
      "Epoch 67/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9887 - accuracy: 0.5249\n",
      "Epoch 68/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9888 - accuracy: 0.5249\n",
      "Epoch 69/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9916 - accuracy: 0.5249\n",
      "Epoch 70/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9877 - accuracy: 0.5249\n",
      "Epoch 71/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9884 - accuracy: 0.5249\n",
      "Epoch 72/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9887 - accuracy: 0.5249\n",
      "Epoch 73/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9875 - accuracy: 0.5249\n",
      "Epoch 74/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9875 - accuracy: 0.5249\n",
      "Epoch 75/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9879 - accuracy: 0.5249\n",
      "Epoch 76/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9879 - accuracy: 0.5249\n",
      "Epoch 77/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9880 - accuracy: 0.5249\n",
      "Epoch 78/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9858 - accuracy: 0.5249\n",
      "Epoch 79/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9871 - accuracy: 0.5249\n",
      "Epoch 80/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9881 - accuracy: 0.5249\n",
      "Epoch 81/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9878 - accuracy: 0.5249\n",
      "Epoch 82/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9893 - accuracy: 0.5249\n",
      "Epoch 83/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9856 - accuracy: 0.5249\n",
      "Epoch 84/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9868 - accuracy: 0.5249\n",
      "Epoch 85/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9875 - accuracy: 0.5249\n",
      "Epoch 86/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9844 - accuracy: 0.5249\n",
      "Epoch 87/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9885 - accuracy: 0.5249\n",
      "Epoch 88/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9869 - accuracy: 0.5249\n",
      "Epoch 89/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9850 - accuracy: 0.5249\n",
      "Epoch 90/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9885 - accuracy: 0.5249\n",
      "Epoch 91/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9856 - accuracy: 0.5249\n",
      "Epoch 92/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9848 - accuracy: 0.5249\n",
      "Epoch 93/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9844 - accuracy: 0.5249\n",
      "Epoch 94/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9890 - accuracy: 0.5249\n",
      "Epoch 95/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9848 - accuracy: 0.5249\n",
      "Epoch 96/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9838 - accuracy: 0.5249\n",
      "Epoch 97/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9834 - accuracy: 0.5249\n",
      "Epoch 98/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9829 - accuracy: 0.5249\n",
      "Epoch 99/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9816 - accuracy: 0.5249\n",
      "Epoch 100/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9817 - accuracy: 0.5249\n",
      "Epoch 101/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9822 - accuracy: 0.5249\n",
      "Epoch 102/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9812 - accuracy: 0.5249\n",
      "Epoch 103/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9814 - accuracy: 0.5249\n",
      "Epoch 104/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9844 - accuracy: 0.5249\n",
      "Epoch 105/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9774 - accuracy: 0.5249\n",
      "Epoch 106/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9850 - accuracy: 0.5249\n",
      "Epoch 107/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9830 - accuracy: 0.5249\n",
      "Epoch 108/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9857 - accuracy: 0.5249\n",
      "Epoch 109/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9789 - accuracy: 0.5249\n",
      "Epoch 110/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9841 - accuracy: 0.5249\n",
      "Epoch 111/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9808 - accuracy: 0.5249\n",
      "Epoch 112/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9853 - accuracy: 0.5249\n",
      "Epoch 113/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9798 - accuracy: 0.5249\n",
      "Epoch 114/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9808 - accuracy: 0.5276\n",
      "Epoch 115/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9808 - accuracy: 0.5304\n",
      "Epoch 116/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9785 - accuracy: 0.5331\n",
      "Epoch 117/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9774 - accuracy: 0.5249\n",
      "Epoch 118/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9776 - accuracy: 0.5331\n",
      "Epoch 119/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9764 - accuracy: 0.5470\n",
      "Epoch 120/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9892 - accuracy: 0.5249\n",
      "Epoch 121/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9881 - accuracy: 0.5249\n",
      "Epoch 122/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9775 - accuracy: 0.5331\n",
      "Epoch 123/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9820 - accuracy: 0.5304\n",
      "Epoch 124/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9763 - accuracy: 0.5331\n",
      "Epoch 125/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9760 - accuracy: 0.5387\n",
      "Epoch 126/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9800 - accuracy: 0.5304\n",
      "Epoch 127/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9734 - accuracy: 0.5359\n",
      "Epoch 128/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9800 - accuracy: 0.5304\n",
      "Epoch 129/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9754 - accuracy: 0.5304\n",
      "Epoch 130/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9746 - accuracy: 0.5387\n",
      "Epoch 131/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9743 - accuracy: 0.5387\n",
      "Epoch 132/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9766 - accuracy: 0.5331\n",
      "Epoch 133/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9734 - accuracy: 0.5387\n",
      "Epoch 134/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9721 - accuracy: 0.5359\n",
      "Epoch 135/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9795 - accuracy: 0.5249\n",
      "Epoch 136/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9748 - accuracy: 0.5331\n",
      "Epoch 137/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9739 - accuracy: 0.5414\n",
      "Epoch 138/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9795 - accuracy: 0.5304\n",
      "Epoch 139/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9723 - accuracy: 0.5442\n",
      "Epoch 140/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9732 - accuracy: 0.5276\n",
      "Epoch 141/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9763 - accuracy: 0.5331\n",
      "Epoch 142/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9707 - accuracy: 0.5359\n",
      "Epoch 143/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9756 - accuracy: 0.5276\n",
      "Epoch 144/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9770 - accuracy: 0.5304\n",
      "Epoch 145/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9751 - accuracy: 0.5387\n",
      "Epoch 146/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9715 - accuracy: 0.5442\n",
      "Epoch 147/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9783 - accuracy: 0.5276\n",
      "Epoch 148/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9774 - accuracy: 0.5414\n",
      "Epoch 149/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9725 - accuracy: 0.5414\n",
      "Epoch 150/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9728 - accuracy: 0.5525\n",
      "Epoch 151/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9723 - accuracy: 0.5525\n",
      "Epoch 152/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9693 - accuracy: 0.5387\n",
      "Epoch 153/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9696 - accuracy: 0.5442\n",
      "Epoch 154/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9703 - accuracy: 0.5414\n",
      "Epoch 155/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9650 - accuracy: 0.5470\n",
      "Epoch 156/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9646 - accuracy: 0.5442\n",
      "Epoch 157/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9649 - accuracy: 0.5497\n",
      "Epoch 158/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9633 - accuracy: 0.5414\n",
      "Epoch 159/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9792 - accuracy: 0.5249\n",
      "Epoch 160/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9755 - accuracy: 0.5331\n",
      "Epoch 161/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9706 - accuracy: 0.5387\n",
      "Epoch 162/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9734 - accuracy: 0.5331\n",
      "Epoch 163/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9714 - accuracy: 0.5442\n",
      "Epoch 164/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9671 - accuracy: 0.5552\n",
      "Epoch 165/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9687 - accuracy: 0.5580\n",
      "Epoch 166/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9659 - accuracy: 0.5525\n",
      "Epoch 167/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9689 - accuracy: 0.5331\n",
      "Epoch 168/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9686 - accuracy: 0.5193\n",
      "Epoch 169/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9639 - accuracy: 0.5635\n",
      "Epoch 170/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9640 - accuracy: 0.5525\n",
      "Epoch 171/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9653 - accuracy: 0.5442\n",
      "Epoch 172/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9657 - accuracy: 0.5359\n",
      "Epoch 173/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9700 - accuracy: 0.5414\n",
      "Epoch 174/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9645 - accuracy: 0.5525\n",
      "Epoch 175/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9697 - accuracy: 0.5414\n",
      "Epoch 176/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9595 - accuracy: 0.5470\n",
      "Epoch 177/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9636 - accuracy: 0.5442\n",
      "Epoch 178/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9611 - accuracy: 0.5414\n",
      "Epoch 179/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9633 - accuracy: 0.5442\n",
      "Epoch 180/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9591 - accuracy: 0.5442\n",
      "Epoch 181/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9612 - accuracy: 0.5497\n",
      "Epoch 182/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9588 - accuracy: 0.5359\n",
      "Epoch 183/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9588 - accuracy: 0.5304\n",
      "Epoch 184/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9601 - accuracy: 0.5470\n",
      "Epoch 185/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9554 - accuracy: 0.5414\n",
      "Epoch 186/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9591 - accuracy: 0.5387\n",
      "Epoch 187/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9578 - accuracy: 0.5276\n",
      "Epoch 188/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9573 - accuracy: 0.5387\n",
      "Epoch 189/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9576 - accuracy: 0.5359\n",
      "Epoch 190/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9554 - accuracy: 0.5359\n",
      "Epoch 191/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9565 - accuracy: 0.5331\n",
      "Epoch 192/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9527 - accuracy: 0.5497\n",
      "Epoch 193/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9514 - accuracy: 0.5497\n",
      "Epoch 194/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9527 - accuracy: 0.5497\n",
      "Epoch 195/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9524 - accuracy: 0.5414\n",
      "Epoch 196/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9516 - accuracy: 0.5525\n",
      "Epoch 197/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9538 - accuracy: 0.5635\n",
      "Epoch 198/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9489 - accuracy: 0.5608\n",
      "Epoch 199/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9513 - accuracy: 0.5580\n",
      "Epoch 200/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9500 - accuracy: 0.5497\n",
      "Epoch 201/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9462 - accuracy: 0.5635\n",
      "Epoch 202/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9550 - accuracy: 0.5470\n",
      "Epoch 203/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9454 - accuracy: 0.5663\n",
      "Epoch 204/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9456 - accuracy: 0.5663\n",
      "Epoch 205/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9489 - accuracy: 0.5608\n",
      "Epoch 206/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9485 - accuracy: 0.5663\n",
      "Epoch 207/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9506 - accuracy: 0.5663\n",
      "Epoch 208/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9492 - accuracy: 0.5718\n",
      "Epoch 209/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9454 - accuracy: 0.5580\n",
      "Epoch 210/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9430 - accuracy: 0.5608\n",
      "Epoch 211/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9548 - accuracy: 0.5552\n",
      "Epoch 212/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9484 - accuracy: 0.5635\n",
      "Epoch 213/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9504 - accuracy: 0.5525\n",
      "Epoch 214/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9472 - accuracy: 0.5608\n",
      "Epoch 215/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9436 - accuracy: 0.5663\n",
      "Epoch 216/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9458 - accuracy: 0.5580\n",
      "Epoch 217/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9469 - accuracy: 0.5608\n",
      "Epoch 218/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9449 - accuracy: 0.5608\n",
      "Epoch 219/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9472 - accuracy: 0.5635\n",
      "Epoch 220/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9435 - accuracy: 0.5635\n",
      "Epoch 221/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9393 - accuracy: 0.5635\n",
      "Epoch 222/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9385 - accuracy: 0.5608\n",
      "Epoch 223/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9340 - accuracy: 0.5663\n",
      "Epoch 224/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9368 - accuracy: 0.5608\n",
      "Epoch 225/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9322 - accuracy: 0.5663\n",
      "Epoch 226/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9332 - accuracy: 0.5691\n",
      "Epoch 227/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9470 - accuracy: 0.5552\n",
      "Epoch 228/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9415 - accuracy: 0.5718\n",
      "Epoch 229/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9367 - accuracy: 0.5663\n",
      "Epoch 230/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9336 - accuracy: 0.5580\n",
      "Epoch 231/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9376 - accuracy: 0.5608\n",
      "Epoch 232/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9318 - accuracy: 0.5635\n",
      "Epoch 233/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9306 - accuracy: 0.5635\n",
      "Epoch 234/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9375 - accuracy: 0.5608\n",
      "Epoch 235/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9408 - accuracy: 0.5525\n",
      "Epoch 236/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9384 - accuracy: 0.5635\n",
      "Epoch 237/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9368 - accuracy: 0.5663\n",
      "Epoch 238/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9357 - accuracy: 0.5691\n",
      "Epoch 239/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9422 - accuracy: 0.5663\n",
      "Epoch 240/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9456 - accuracy: 0.5525\n",
      "Epoch 241/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9405 - accuracy: 0.5635\n",
      "Epoch 242/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9321 - accuracy: 0.5663\n",
      "Epoch 243/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9285 - accuracy: 0.5608\n",
      "Epoch 244/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9263 - accuracy: 0.5663\n",
      "Epoch 245/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9288 - accuracy: 0.5663\n",
      "Epoch 246/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9249 - accuracy: 0.5691\n",
      "Epoch 247/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9227 - accuracy: 0.5718\n",
      "Epoch 248/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9316 - accuracy: 0.5552\n",
      "Epoch 249/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9388 - accuracy: 0.5525\n",
      "Epoch 250/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9222 - accuracy: 0.5691\n",
      "Epoch 251/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9253 - accuracy: 0.5691\n",
      "Epoch 252/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9224 - accuracy: 0.5663\n",
      "Epoch 253/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9229 - accuracy: 0.5691\n",
      "Epoch 254/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9320 - accuracy: 0.5635\n",
      "Epoch 255/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9230 - accuracy: 0.5663\n",
      "Epoch 256/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9309 - accuracy: 0.5580\n",
      "Epoch 257/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9186 - accuracy: 0.5635\n",
      "Epoch 258/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9210 - accuracy: 0.5691\n",
      "Epoch 259/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9197 - accuracy: 0.5580\n",
      "Epoch 260/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9160 - accuracy: 0.5663\n",
      "Epoch 261/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9124 - accuracy: 0.5718\n",
      "Epoch 262/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9100 - accuracy: 0.5691\n",
      "Epoch 263/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9098 - accuracy: 0.5691\n",
      "Epoch 264/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9121 - accuracy: 0.5773\n",
      "Epoch 265/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9156 - accuracy: 0.5608\n",
      "Epoch 266/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9045 - accuracy: 0.5718\n",
      "Epoch 267/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9073 - accuracy: 0.5663\n",
      "Epoch 268/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9102 - accuracy: 0.5608\n",
      "Epoch 269/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9078 - accuracy: 0.5773\n",
      "Epoch 270/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9109 - accuracy: 0.5691\n",
      "Epoch 271/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9000 - accuracy: 0.5773\n",
      "Epoch 272/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9081 - accuracy: 0.5691\n",
      "Epoch 273/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9644 - accuracy: 0.5304\n",
      "Epoch 274/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9589 - accuracy: 0.5304\n",
      "Epoch 275/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9351 - accuracy: 0.5525\n",
      "Epoch 276/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9182 - accuracy: 0.5691\n",
      "Epoch 277/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9104 - accuracy: 0.5635\n",
      "Epoch 278/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9022 - accuracy: 0.5691\n",
      "Epoch 279/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8981 - accuracy: 0.5718\n",
      "Epoch 280/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.9060 - accuracy: 0.5663\n",
      "Epoch 281/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9146 - accuracy: 0.5580\n",
      "Epoch 282/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8967 - accuracy: 0.5718\n",
      "Epoch 283/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9044 - accuracy: 0.5663\n",
      "Epoch 284/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9015 - accuracy: 0.5635\n",
      "Epoch 285/600\n",
      "362/362 [==============================] - ETA: 0s - loss: 1.0391 - accuracy: 0.57 - 0s 43us/sample - loss: 0.9049 - accuracy: 0.5691\n",
      "Epoch 286/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9054 - accuracy: 0.5718\n",
      "Epoch 287/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.9102 - accuracy: 0.5635\n",
      "Epoch 288/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9107 - accuracy: 0.5552\n",
      "Epoch 289/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9205 - accuracy: 0.5608\n",
      "Epoch 290/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9034 - accuracy: 0.5691\n",
      "Epoch 291/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.8915 - accuracy: 0.5773\n",
      "Epoch 292/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.9002 - accuracy: 0.5691\n",
      "Epoch 293/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8951 - accuracy: 0.5691\n",
      "Epoch 294/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8918 - accuracy: 0.5773\n",
      "Epoch 295/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8941 - accuracy: 0.5801\n",
      "Epoch 296/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.9004 - accuracy: 0.5691\n",
      "Epoch 297/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.8848 - accuracy: 0.5718\n",
      "Epoch 298/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9001 - accuracy: 0.5746\n",
      "Epoch 299/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 0.8914 - accuracy: 0.5663\n",
      "Epoch 300/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 0.8867 - accuracy: 0.5773\n",
      "Epoch 301/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.8885 - accuracy: 0.5801\n",
      "Epoch 302/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 0.9003 - accuracy: 0.5801\n",
      "Epoch 303/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8880 - accuracy: 0.5829\n",
      "Epoch 304/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8809 - accuracy: 0.5691\n",
      "Epoch 305/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.8804 - accuracy: 0.5773\n",
      "Epoch 306/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8787 - accuracy: 0.5691\n",
      "Epoch 307/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8767 - accuracy: 0.5829\n",
      "Epoch 308/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8772 - accuracy: 0.5773\n",
      "Epoch 309/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.8740 - accuracy: 0.5829\n",
      "Epoch 310/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8705 - accuracy: 0.5773\n",
      "Epoch 311/600\n",
      "362/362 [==============================] - 0s 196us/sample - loss: 0.8775 - accuracy: 0.5746\n",
      "Epoch 312/600\n",
      "362/362 [==============================] - 0s 112us/sample - loss: 0.8747 - accuracy: 0.5801\n",
      "Epoch 313/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8950 - accuracy: 0.5663\n",
      "Epoch 314/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8786 - accuracy: 0.5746\n",
      "Epoch 315/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8873 - accuracy: 0.5635\n",
      "Epoch 316/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.9274 - accuracy: 0.5635\n",
      "Epoch 317/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8954 - accuracy: 0.5746\n",
      "Epoch 318/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8830 - accuracy: 0.5801\n",
      "Epoch 319/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8759 - accuracy: 0.5829\n",
      "Epoch 320/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8757 - accuracy: 0.5801\n",
      "Epoch 321/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8691 - accuracy: 0.5773\n",
      "Epoch 322/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8703 - accuracy: 0.5912\n",
      "Epoch 323/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8665 - accuracy: 0.5801\n",
      "Epoch 324/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8685 - accuracy: 0.5718\n",
      "Epoch 325/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8598 - accuracy: 0.5884\n",
      "Epoch 326/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8639 - accuracy: 0.5773\n",
      "Epoch 327/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8617 - accuracy: 0.5912\n",
      "Epoch 328/600\n",
      "362/362 [==============================] - ETA: 0s - loss: 0.8159 - accuracy: 0.59 - 0s 43us/sample - loss: 0.8576 - accuracy: 0.5912\n",
      "Epoch 329/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8543 - accuracy: 0.5912\n",
      "Epoch 330/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8621 - accuracy: 0.5746\n",
      "Epoch 331/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8662 - accuracy: 0.5829\n",
      "Epoch 332/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8740 - accuracy: 0.5829\n",
      "Epoch 333/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8779 - accuracy: 0.5856\n",
      "Epoch 334/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8617 - accuracy: 0.5773\n",
      "Epoch 335/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8621 - accuracy: 0.5884\n",
      "Epoch 336/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8541 - accuracy: 0.5829\n",
      "Epoch 337/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8487 - accuracy: 0.5856\n",
      "Epoch 338/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8512 - accuracy: 0.5912\n",
      "Epoch 339/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 0.8442 - accuracy: 0.5912\n",
      "Epoch 340/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8667 - accuracy: 0.5856\n",
      "Epoch 341/600\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 0.8759 - accuracy: 0.5746\n",
      "Epoch 342/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8702 - accuracy: 0.5746\n",
      "Epoch 343/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8513 - accuracy: 0.5746\n",
      "Epoch 344/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8564 - accuracy: 0.5773\n",
      "Epoch 345/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8550 - accuracy: 0.5884\n",
      "Epoch 346/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8514 - accuracy: 0.5884\n",
      "Epoch 347/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8491 - accuracy: 0.5994\n",
      "Epoch 348/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8490 - accuracy: 0.5939\n",
      "Epoch 349/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8480 - accuracy: 0.5994\n",
      "Epoch 350/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8516 - accuracy: 0.5856\n",
      "Epoch 351/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8443 - accuracy: 0.5884\n",
      "Epoch 352/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8467 - accuracy: 0.5801\n",
      "Epoch 353/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8665 - accuracy: 0.5801\n",
      "Epoch 354/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8630 - accuracy: 0.5801\n",
      "Epoch 355/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8517 - accuracy: 0.5856\n",
      "Epoch 356/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8449 - accuracy: 0.5801\n",
      "Epoch 357/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8440 - accuracy: 0.5773\n",
      "Epoch 358/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.8380 - accuracy: 0.5856\n",
      "Epoch 359/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8317 - accuracy: 0.5967\n",
      "Epoch 360/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8281 - accuracy: 0.6050\n",
      "Epoch 361/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8345 - accuracy: 0.5912\n",
      "Epoch 362/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.8202 - accuracy: 0.5994\n",
      "Epoch 363/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8338 - accuracy: 0.5912\n",
      "Epoch 364/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8419 - accuracy: 0.5967\n",
      "Epoch 365/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8401 - accuracy: 0.5912\n",
      "Epoch 366/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8384 - accuracy: 0.5773\n",
      "Epoch 367/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8347 - accuracy: 0.5939\n",
      "Epoch 368/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8249 - accuracy: 0.5994\n",
      "Epoch 369/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8175 - accuracy: 0.5939\n",
      "Epoch 370/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8159 - accuracy: 0.6105\n",
      "Epoch 371/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8263 - accuracy: 0.6050\n",
      "Epoch 372/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8458 - accuracy: 0.5884\n",
      "Epoch 373/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8197 - accuracy: 0.5939\n",
      "Epoch 374/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8135 - accuracy: 0.5967\n",
      "Epoch 375/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8173 - accuracy: 0.6050\n",
      "Epoch 376/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7942 - accuracy: 0.6077\n",
      "Epoch 377/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8047 - accuracy: 0.6105\n",
      "Epoch 378/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8009 - accuracy: 0.6022\n",
      "Epoch 379/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7966 - accuracy: 0.6077\n",
      "Epoch 380/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7855 - accuracy: 0.6077\n",
      "Epoch 381/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7932 - accuracy: 0.6188\n",
      "Epoch 382/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 0.8356 - accuracy: 0.5912\n",
      "Epoch 383/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8792 - accuracy: 0.5663\n",
      "Epoch 384/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8602 - accuracy: 0.5801\n",
      "Epoch 385/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8596 - accuracy: 0.5856\n",
      "Epoch 386/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8561 - accuracy: 0.5856\n",
      "Epoch 387/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8367 - accuracy: 0.5884\n",
      "Epoch 388/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8023 - accuracy: 0.6050\n",
      "Epoch 389/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8105 - accuracy: 0.6105\n",
      "Epoch 390/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8147 - accuracy: 0.6105\n",
      "Epoch 391/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.8076 - accuracy: 0.6022\n",
      "Epoch 392/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8018 - accuracy: 0.6050\n",
      "Epoch 393/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8045 - accuracy: 0.6160\n",
      "Epoch 394/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7919 - accuracy: 0.6188\n",
      "Epoch 395/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7908 - accuracy: 0.6077\n",
      "Epoch 396/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7865 - accuracy: 0.6105\n",
      "Epoch 397/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7900 - accuracy: 0.6160\n",
      "Epoch 398/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8293 - accuracy: 0.5994\n",
      "Epoch 399/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8137 - accuracy: 0.6215\n",
      "Epoch 400/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8185 - accuracy: 0.6077\n",
      "Epoch 401/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8092 - accuracy: 0.6077\n",
      "Epoch 402/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8018 - accuracy: 0.6022\n",
      "Epoch 403/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8084 - accuracy: 0.6022\n",
      "Epoch 404/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8051 - accuracy: 0.6022\n",
      "Epoch 405/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8041 - accuracy: 0.6105\n",
      "Epoch 406/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8117 - accuracy: 0.6050\n",
      "Epoch 407/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8236 - accuracy: 0.5967\n",
      "Epoch 408/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.8177 - accuracy: 0.5939\n",
      "Epoch 409/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8469 - accuracy: 0.5912\n",
      "Epoch 410/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8160 - accuracy: 0.6077\n",
      "Epoch 411/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.8137 - accuracy: 0.6105\n",
      "Epoch 412/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7979 - accuracy: 0.6050\n",
      "Epoch 413/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7754 - accuracy: 0.6160\n",
      "Epoch 414/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7626 - accuracy: 0.6215\n",
      "Epoch 415/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7675 - accuracy: 0.6160\n",
      "Epoch 416/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7770 - accuracy: 0.6188\n",
      "Epoch 417/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7792 - accuracy: 0.6215\n",
      "Epoch 418/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7795 - accuracy: 0.5967\n",
      "Epoch 419/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7812 - accuracy: 0.6188\n",
      "Epoch 420/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7758 - accuracy: 0.6105\n",
      "Epoch 421/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7645 - accuracy: 0.6105\n",
      "Epoch 422/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7995 - accuracy: 0.6050\n",
      "Epoch 423/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7722 - accuracy: 0.6133\n",
      "Epoch 424/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.8045 - accuracy: 0.5884\n",
      "Epoch 425/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7757 - accuracy: 0.6160\n",
      "Epoch 426/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7696 - accuracy: 0.6271\n",
      "Epoch 427/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7691 - accuracy: 0.6243\n",
      "Epoch 428/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7649 - accuracy: 0.6271\n",
      "Epoch 429/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7723 - accuracy: 0.6160\n",
      "Epoch 430/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7534 - accuracy: 0.6243\n",
      "Epoch 431/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7443 - accuracy: 0.6326\n",
      "Epoch 432/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7527 - accuracy: 0.6188\n",
      "Epoch 433/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7350 - accuracy: 0.6381\n",
      "Epoch 434/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7522 - accuracy: 0.6133\n",
      "Epoch 435/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7701 - accuracy: 0.6133\n",
      "Epoch 436/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7754 - accuracy: 0.6215\n",
      "Epoch 437/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7672 - accuracy: 0.6160\n",
      "Epoch 438/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7797 - accuracy: 0.6105\n",
      "Epoch 439/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7520 - accuracy: 0.6326\n",
      "Epoch 440/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7679 - accuracy: 0.6243\n",
      "Epoch 441/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7442 - accuracy: 0.6464\n",
      "Epoch 442/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7375 - accuracy: 0.6354\n",
      "Epoch 443/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7532 - accuracy: 0.6326\n",
      "Epoch 444/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7561 - accuracy: 0.6354\n",
      "Epoch 445/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7555 - accuracy: 0.6188\n",
      "Epoch 446/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7774 - accuracy: 0.6243\n",
      "Epoch 447/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7478 - accuracy: 0.6298\n",
      "Epoch 448/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7555 - accuracy: 0.6243\n",
      "Epoch 449/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7807 - accuracy: 0.6105\n",
      "Epoch 450/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7414 - accuracy: 0.6492\n",
      "Epoch 451/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7341 - accuracy: 0.6409\n",
      "Epoch 452/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7237 - accuracy: 0.6354\n",
      "Epoch 453/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7542 - accuracy: 0.6215\n",
      "Epoch 454/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7163 - accuracy: 0.6354\n",
      "Epoch 455/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7261 - accuracy: 0.6464\n",
      "Epoch 456/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7310 - accuracy: 0.6326\n",
      "Epoch 457/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7168 - accuracy: 0.6326\n",
      "Epoch 458/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7192 - accuracy: 0.6492\n",
      "Epoch 459/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7182 - accuracy: 0.6464\n",
      "Epoch 460/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7116 - accuracy: 0.6602\n",
      "Epoch 461/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7293 - accuracy: 0.6436\n",
      "Epoch 462/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7125 - accuracy: 0.6464\n",
      "Epoch 463/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7292 - accuracy: 0.6436\n",
      "Epoch 464/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7333 - accuracy: 0.6547\n",
      "Epoch 465/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7222 - accuracy: 0.6409\n",
      "Epoch 466/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7510 - accuracy: 0.6464\n",
      "Epoch 467/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7428 - accuracy: 0.6381\n",
      "Epoch 468/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7475 - accuracy: 0.6381\n",
      "Epoch 469/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7545 - accuracy: 0.6436\n",
      "Epoch 470/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.7526 - accuracy: 0.6436\n",
      "Epoch 471/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7352 - accuracy: 0.6519\n",
      "Epoch 472/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7339 - accuracy: 0.6519\n",
      "Epoch 473/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7411 - accuracy: 0.6519\n",
      "Epoch 474/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7241 - accuracy: 0.6602\n",
      "Epoch 475/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7204 - accuracy: 0.6547\n",
      "Epoch 476/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7464 - accuracy: 0.6492\n",
      "Epoch 477/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7347 - accuracy: 0.6492\n",
      "Epoch 478/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7300 - accuracy: 0.6602\n",
      "Epoch 479/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7408 - accuracy: 0.6409\n",
      "Epoch 480/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7007 - accuracy: 0.6685\n",
      "Epoch 481/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6922 - accuracy: 0.6713\n",
      "Epoch 482/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7033 - accuracy: 0.6547\n",
      "Epoch 483/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6834 - accuracy: 0.6685\n",
      "Epoch 484/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6816 - accuracy: 0.6796\n",
      "Epoch 485/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7199 - accuracy: 0.6381\n",
      "Epoch 486/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6900 - accuracy: 0.6547\n",
      "Epoch 487/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6921 - accuracy: 0.6492\n",
      "Epoch 488/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6803 - accuracy: 0.6630\n",
      "Epoch 489/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6890 - accuracy: 0.6547\n",
      "Epoch 490/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6874 - accuracy: 0.6575\n",
      "Epoch 491/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6834 - accuracy: 0.6575\n",
      "Epoch 492/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7104 - accuracy: 0.6547\n",
      "Epoch 493/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6937 - accuracy: 0.6464\n",
      "Epoch 494/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6806 - accuracy: 0.6602\n",
      "Epoch 495/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6833 - accuracy: 0.6740\n",
      "Epoch 496/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6804 - accuracy: 0.6575\n",
      "Epoch 497/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6650 - accuracy: 0.6796\n",
      "Epoch 498/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6692 - accuracy: 0.6685\n",
      "Epoch 499/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6771 - accuracy: 0.6657\n",
      "Epoch 500/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7292 - accuracy: 0.6409\n",
      "Epoch 501/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.7618 - accuracy: 0.6105\n",
      "Epoch 502/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7039 - accuracy: 0.6602\n",
      "Epoch 503/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.7371 - accuracy: 0.6464\n",
      "Epoch 504/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7314 - accuracy: 0.6464\n",
      "Epoch 505/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7263 - accuracy: 0.6381\n",
      "Epoch 506/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6978 - accuracy: 0.6464\n",
      "Epoch 507/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.6718 - accuracy: 0.6685\n",
      "Epoch 508/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 0.6563 - accuracy: 0.6685\n",
      "Epoch 509/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6525 - accuracy: 0.6657\n",
      "Epoch 510/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6646 - accuracy: 0.6630\n",
      "Epoch 511/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6826 - accuracy: 0.6823\n",
      "Epoch 512/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.7238 - accuracy: 0.6602\n",
      "Epoch 513/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7284 - accuracy: 0.6547\n",
      "Epoch 514/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.6880 - accuracy: 0.6796\n",
      "Epoch 515/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 0.6976 - accuracy: 0.6602\n",
      "Epoch 516/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.6700 - accuracy: 0.6823\n",
      "Epoch 517/600\n",
      "362/362 [==============================] - 0s 147us/sample - loss: 0.6725 - accuracy: 0.6602\n",
      "Epoch 518/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6559 - accuracy: 0.6740\n",
      "Epoch 519/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.6449 - accuracy: 0.6961\n",
      "Epoch 520/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.6862 - accuracy: 0.6713\n",
      "Epoch 521/600\n",
      "362/362 [==============================] - 0s 105us/sample - loss: 0.7450 - accuracy: 0.6436\n",
      "Epoch 522/600\n",
      "362/362 [==============================] - 0s 130us/sample - loss: 0.6836 - accuracy: 0.6630\n",
      "Epoch 523/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.6557 - accuracy: 0.6823\n",
      "Epoch 524/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.6585 - accuracy: 0.6713\n",
      "Epoch 525/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6883 - accuracy: 0.6575\n",
      "Epoch 526/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.7019 - accuracy: 0.6602\n",
      "Epoch 527/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6857 - accuracy: 0.6657\n",
      "Epoch 528/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.6935 - accuracy: 0.6519\n",
      "Epoch 529/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.6688 - accuracy: 0.6575\n",
      "Epoch 530/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.6654 - accuracy: 0.6768\n",
      "Epoch 531/600\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 0.6399 - accuracy: 0.6685\n",
      "Epoch 532/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6285 - accuracy: 0.6851\n",
      "Epoch 533/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.6485 - accuracy: 0.6796\n",
      "Epoch 534/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6726 - accuracy: 0.6602\n",
      "Epoch 535/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6771 - accuracy: 0.6630\n",
      "Epoch 536/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.6793 - accuracy: 0.6409\n",
      "Epoch 537/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6753 - accuracy: 0.6547\n",
      "Epoch 538/600\n",
      "362/362 [==============================] - 0s 148us/sample - loss: 0.6839 - accuracy: 0.6547\n",
      "Epoch 539/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6696 - accuracy: 0.6713\n",
      "Epoch 540/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6995 - accuracy: 0.6381\n",
      "Epoch 541/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6511 - accuracy: 0.6575\n",
      "Epoch 542/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6461 - accuracy: 0.6602\n",
      "Epoch 543/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6587 - accuracy: 0.6713\n",
      "Epoch 544/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6544 - accuracy: 0.6713\n",
      "Epoch 545/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6527 - accuracy: 0.6602\n",
      "Epoch 546/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6576 - accuracy: 0.6851\n",
      "Epoch 547/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6676 - accuracy: 0.6575\n",
      "Epoch 548/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6658 - accuracy: 0.6575\n",
      "Epoch 549/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6289 - accuracy: 0.6823\n",
      "Epoch 550/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6221 - accuracy: 0.6657\n",
      "Epoch 551/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6459 - accuracy: 0.6657\n",
      "Epoch 552/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6733 - accuracy: 0.6575\n",
      "Epoch 553/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6508 - accuracy: 0.6547\n",
      "Epoch 554/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6555 - accuracy: 0.6602\n",
      "Epoch 555/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6833 - accuracy: 0.6685\n",
      "Epoch 556/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7061 - accuracy: 0.6602\n",
      "Epoch 557/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6939 - accuracy: 0.6547\n",
      "Epoch 558/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6521 - accuracy: 0.6823\n",
      "Epoch 559/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6425 - accuracy: 0.6796\n",
      "Epoch 560/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.6393 - accuracy: 0.6713\n",
      "Epoch 561/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6148 - accuracy: 0.6796\n",
      "Epoch 562/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6046 - accuracy: 0.6796\n",
      "Epoch 563/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6088 - accuracy: 0.6796\n",
      "Epoch 564/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5998 - accuracy: 0.6851\n",
      "Epoch 565/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6257 - accuracy: 0.6685\n",
      "Epoch 566/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6333 - accuracy: 0.6768\n",
      "Epoch 567/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6204 - accuracy: 0.6878\n",
      "Epoch 568/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6265 - accuracy: 0.6961\n",
      "Epoch 569/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6170 - accuracy: 0.6906\n",
      "Epoch 570/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5835 - accuracy: 0.7017\n",
      "Epoch 571/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.5947 - accuracy: 0.6740\n",
      "Epoch 572/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6130 - accuracy: 0.6823\n",
      "Epoch 573/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6893 - accuracy: 0.6657\n",
      "Epoch 574/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.7036 - accuracy: 0.6630\n",
      "Epoch 575/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6546 - accuracy: 0.6685\n",
      "Epoch 576/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6814 - accuracy: 0.6657\n",
      "Epoch 577/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6630 - accuracy: 0.6685\n",
      "Epoch 578/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6595 - accuracy: 0.6878\n",
      "Epoch 579/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6467 - accuracy: 0.6878\n",
      "Epoch 580/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6346 - accuracy: 0.6878\n",
      "Epoch 581/600\n",
      "362/362 [==============================] - 0s 129us/sample - loss: 0.5995 - accuracy: 0.6878\n",
      "Epoch 582/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.6298 - accuracy: 0.6878\n",
      "Epoch 583/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.6386 - accuracy: 0.6906\n",
      "Epoch 584/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6379 - accuracy: 0.6961\n",
      "Epoch 585/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5978 - accuracy: 0.7127\n",
      "Epoch 586/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5911 - accuracy: 0.7017\n",
      "Epoch 587/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.5997 - accuracy: 0.6961\n",
      "Epoch 588/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5960 - accuracy: 0.6961\n",
      "Epoch 589/600\n",
      "362/362 [==============================] - 0s 43us/sample - loss: 0.5962 - accuracy: 0.6934\n",
      "Epoch 590/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.5957 - accuracy: 0.6934\n",
      "Epoch 591/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6440 - accuracy: 0.6630\n",
      "Epoch 592/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5886 - accuracy: 0.6906\n",
      "Epoch 593/600\n",
      "362/362 [==============================] - 0s 61us/sample - loss: 0.5736 - accuracy: 0.6934\n",
      "Epoch 594/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5864 - accuracy: 0.6851\n",
      "Epoch 595/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5712 - accuracy: 0.7017\n",
      "Epoch 596/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.5877 - accuracy: 0.6906\n",
      "Epoch 597/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6253 - accuracy: 0.6906\n",
      "Epoch 598/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.5696 - accuracy: 0.7044\n",
      "Epoch 599/600\n",
      "362/362 [==============================] - 0s 104us/sample - loss: 0.5810 - accuracy: 0.6934\n",
      "Epoch 600/600\n",
      "362/362 [==============================] - 0s 86us/sample - loss: 0.6194 - accuracy: 0.6768\n",
      "[4.938245e-05 0.000000e+00 9.529933e-02]\n",
      "[0.00247148 0.02953327 0.96193945]\n",
      "[2.1851063e-04 0.0000000e+00 8.6712551e-01]\n",
      "[0.02531436 0.00083199 0.16441688]\n",
      "[0.00237125 0.00099063 0.00136012]\n",
      "[9.0917945e-04 1.6391277e-06 1.4781952e-05]\n",
      "[0.02974138 0.02660966 0.11435318]\n",
      "[0.19455633 1.         1.        ]\n",
      "[7.0708990e-03 4.4703484e-07 2.4067968e-02]\n",
      "[2.2757053e-04 9.1165853e-01 1.0000000e+00]\n",
      "[0.01124081 0.04688135 0.96762466]\n",
      "[4.1526556e-04 1.0000000e+00 1.0000000e+00]\n",
      "[0.10832477 1.         1.        ]\n",
      "[5.0842762e-05 3.7856519e-02 1.0000000e+00]\n",
      "[0.28165138 0.9998475  1.        ]\n",
      "[1.7146885e-02 8.1062317e-06 3.2282084e-02]\n",
      "[0.09279314 1.         1.        ]\n",
      "[0.01948953 0.08351594 0.9495425 ]\n",
      "[0.01053998 0.03294161 0.8033905 ]\n",
      "[0.24901804 0.9999891  1.        ]\n",
      "[9.5579028e-03 1.6902179e-01 1.4317036e-04]\n",
      "[0.00306711 0.02721295 0.97981   ]\n",
      "[0.19450742 1.         1.        ]\n",
      "[0.06368348 1.         1.        ]\n",
      "[0.03584009 0.06119356 0.09125236]\n",
      "[0.2586387 0.999972  1.       ]\n",
      "[0.01572913 0.03915298 0.9527378 ]\n",
      "[0.00701776 0.01902455 0.90930784]\n",
      "[0.04809594 0.09860805 0.00044289]\n",
      "[9.8645687e-05 0.0000000e+00 1.9388095e-01]\n",
      "[0.30273214 0.9970531  0.9999983 ]\n",
      "[0.36956894 0.90663815 0.9999949 ]\n",
      "[0.00370982 0.18410924 0.9998035 ]\n",
      "[0.2498956  0.99998593 1.        ]\n",
      "[1.3610721e-04 3.2541752e-01 1.0000000e+00]\n",
      "[0.06415927 0.9133061  0.9999982 ]\n",
      "[0.05085117 0.04227629 0.00015828]\n",
      "[3.2603741e-04 7.7353626e-01 1.0000000e+00]\n",
      "[1.4278293e-04 1.1920929e-07 9.9991924e-01]\n",
      "[0.00627154 0.07794788 0.00073433]\n",
      "[0.13157272 0.99884284 1.        ]\n",
      "[0.18124345 1.         1.        ]\n",
      "[0.22718859 0.99999917 1.        ]\n",
      "[0.00159085 0.56570816 0.99999905]\n",
      "[0.26724875 0.21478835 0.96591306]\n",
      "[1.9669533e-06 9.9955505e-01 1.0000000e+00]\n",
      "[0.02040985 0.99973726 1.        ]\n",
      "[0.00390315 0.00135931 0.07355908]\n",
      "[0.01062948 0.9998225  1.        ]\n",
      "[0.07308221 1.         1.        ]\n",
      "[0.10363838 0.9999401  1.        ]\n",
      "[0.06004196 0.20034686 0.81568694]\n",
      "[7.0095062e-05 8.7667185e-01 1.0000000e+00]\n",
      "[4.324317e-05 9.777766e-01 1.000000e+00]\n",
      "[0.21308768 0.99999976 1.        ]\n",
      "[0.01276362 0.04426661 0.95006454]\n",
      "[0.05578801 0.99996537 1.        ]\n",
      "[0.3468111 0.9894669 0.9999682]\n",
      "[1.15692616e-04 1.00000000e+00 1.00000000e+00]\n",
      "[0.0029121 0.9729682 1.       ]\n",
      "[0.03902778 0.02105114 0.80061877]\n",
      "[0.01776448 0.0157336  0.00135118]\n",
      "[0.00432765 0.487872   0.999982  ]\n",
      "[5.662441e-07 1.000000e+00 1.000000e+00]\n",
      "[0.01803038 0.0002172  0.1349712 ]\n",
      "[0.14294404 1.         1.        ]\n",
      "[0.07834134 0.05536607 0.01282051]\n",
      "[0.00138885 0.92057467 0.9999999 ]\n",
      "[0.0129182  0.03783497 0.0003964 ]\n",
      "[0.00247148 0.02953327 0.96193945]\n",
      "[0.17081925 1.         1.        ]\n",
      "[0.02112901 0.09479895 0.8316852 ]\n",
      "[0.04318091 0.01759982 0.27971682]\n",
      "[0.03092518 0.01812384 0.99988145]\n",
      "[0.002323   0.00026533 0.00172219]\n",
      "[0.01767826 0.99999994 1.        ]\n",
      "[0.1946446 1.        1.       ]\n",
      "[1.1920929e-07 0.0000000e+00 8.1888115e-01]\n",
      "[0.24702641 0.9999248  1.        ]\n",
      "[0.01005596 0.23893765 0.9993268 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14446259 0.9960662  1.        ]\n",
      "[0.02637711 0.0227842  0.00243205]\n",
      "[1.43341124e-02 1.40964985e-05 8.66930783e-02]\n",
      "[0.08192927 0.99999756 1.        ]\n",
      "[0.03130549 0.02293143 0.00384226]\n",
      "[7.6882839e-03 2.1138787e-04 2.4452117e-01]\n",
      "[0.         0.00828496 1.        ]\n",
      "[0.01024356 0.17479128 0.00025901]\n",
      "[0.26720873 1.         1.        ]\n",
      "[0.01681015 0.20118648 0.99750197]\n",
      "[2.3841858e-07 6.5565109e-07 1.0000000e+00]\n",
      "[7.6681674e-03 2.2053719e-06 3.2815903e-02]\n",
      "[0.00649321 0.03542703 0.75337845]\n",
      "[1.2516975e-06 9.4976878e-01 1.0000000e+00]\n",
      "[0.05676734 0.96731    0.9999968 ]\n",
      "[0.17962205 0.9996146  1.        ]\n",
      "[0.0172832  0.02333874 0.00106269]\n",
      "[0.00131375 0.556609   1.        ]\n",
      "[0.0067268  0.15444994 0.9987973 ]\n",
      "[1.6101357e-01 6.8796498e-01 6.3180923e-06]\n",
      "[0.51875854 0.9335184  0.9999958 ]\n",
      "[0.00370982 0.18410924 0.9998035 ]\n",
      "[0.06219071 0.20795187 0.72449666]\n",
      "[0.05697674 0.9996128  1.        ]\n",
      "[0.00855604 0.14420575 0.99813837]\n",
      "[0.01458874 0.11643454 0.98066807]\n",
      "[0.09555379 0.17059082 0.04942015]\n",
      "[0.00638175 0.99999225 1.        ]\n",
      "[0.1392279  0.05488548 0.00419128]\n",
      "[0.03715619 0.01869071 0.99987996]\n",
      "[0.04131919 0.02890116 0.3192981 ]\n",
      "[0.00378293 0.00022098 0.00267565]\n",
      "[0.25223053 0.9999919  1.        ]\n",
      "[0.01005155 1.         1.        ]\n",
      "[0.00513119 0.00326714 0.00040212]\n",
      "[0.05676728 0.96731    0.9999969 ]\n",
      "[1.2108684e-03 8.9406967e-08 2.6239812e-02]\n",
      "[0.02361396 1.         1.        ]\n",
      "[7.4505806e-07 0.0000000e+00 1.4460295e-02]\n",
      "[3.0249357e-05 0.0000000e+00 1.6882420e-02]\n",
      "[0.0050177  0.00125781 0.00301987]\n",
      "[0.09608197 1.         1.        ]\n",
      "[0.01320505 1.         1.        ]\n",
      "[5.9604645e-08 9.3605816e-01 1.0000000e+00]\n",
      "[3.0010939e-05 0.0000000e+00 2.9243690e-01]\n",
      "[0.0031603  0.24142542 1.        ]\n",
      "[0.00328743 0.00327376 0.00012669]\n",
      "[4.0687430e-01 6.3498914e-03 3.5405159e-04]\n",
      "[0.00485089 1.         1.        ]\n",
      "[0.07047144 1.         1.        ]\n",
      "[0.00309128 0.02767503 0.97453856]\n",
      "[0.14569789 0.9999984  1.        ]\n",
      "[0.00163013 0.         0.01089689]\n",
      "[3.3447146e-04 9.6544790e-01 1.0000000e+00]\n",
      "[0.08808801 0.09896964 0.94276774]\n",
      "[7.8618526e-04 9.3747163e-01 1.0000000e+00]\n",
      "[1.0597068e-01 4.3617201e-01 7.0452690e-05]\n",
      "[0.18620792 0.99999994 1.        ]\n",
      "[0.08711329 1.         1.        ]\n",
      "[0.20260197 0.9999999  1.        ]\n",
      "[0.30273217 0.9970532  0.99999833]\n",
      "[0.01573494 0.11829555 0.00016615]\n",
      "[0.0024837 1.        1.       ]\n",
      "[0.01753852 0.0093137  0.04264042]\n",
      "[7.8231096e-05 5.7234287e-02 1.0000000e+00]\n",
      "[0.00509191 1.         1.        ]\n",
      "[0.72729456 0.98450494 0.9999997 ]\n",
      "[0.12404567 0.327151   0.9923444 ]\n",
      "[0.01084808 0.00070769 0.00147951]\n",
      "[0.19340047 1.         1.        ]\n",
      "[0.11933446 0.89749885 0.9999994 ]\n",
      "[0.01222974 0.00077054 0.00251147]\n",
      "[0.10774729 0.09412125 0.00234571]\n",
      "[1.4949590e-02 5.6181085e-01 1.0460615e-04]\n",
      "[0.04833826 0.9384298  0.99999213]\n",
      "[0.17386353 0.9999324  1.        ]\n",
      "Accuracy: 92.28967428207397%\n"
     ]
    }
   ],
   "source": [
    "  print(feature_column_names)\n",
    "  classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "  classifier.add(Dense(units = 76, kernel_initializer = 'uniform', activation = 'relu', input_dim = 3))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "  classifier.add(Dense(units = 62, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "  classifier.add(Dense(units = 56, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the fourth hidden layer\n",
    "  classifier.add(Dense(units = 52, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the fifth hidden layer\n",
    "  classifier.add(Dense(units = 46, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "  classifier.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "  classifier.compile(Adam(lr=.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "  classifier.fit(X_train, y_train, batch_size =42 , epochs = 600)\n",
    "  \n",
    "\n",
    "  # Predicting the Test set results\n",
    "  predictions = classifier.predict(X_test)\n",
    "  \n",
    "  for p in predictions:\n",
    "    print(p)\n",
    "\n",
    "  accuracy = (predictions[0][0]+predictions[1][1])/(predictions[0][0]+predictions[0][1]+predictions[1][0]+predictions[1][1])\n",
    "  acc = str(accuracy*100)\n",
    "  print(\"Accuracy: \"+ acc+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "#serialize classifier to JSON\n",
    "model_json = classifier.to_json()\n",
    "with open(\"student_prediction_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "classifier.save('student_prediction_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del classifier  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('student_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN using kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('E:\\\\xAPI-Edu-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender NationalITy PlaceofBirth     StageID GradeID SectionID Topic  \\\n",
       "0      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "1      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "\n",
       "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "\n",
       "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "\n",
       "  StudentAbsenceDays Class  \n",
       "0            Under-7     M  \n",
       "1            Under-7     M  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender NationalITy PlaceofBirth     StageID GradeID SectionID Topic  \\\n",
       "0      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "1      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "\n",
       "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "\n",
       "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "\n",
       "  StudentAbsenceDays  \n",
       "0            Under-7  \n",
       "1            Under-7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X and y\n",
    "Without_class_data_frame = data_frame.drop(columns=['Class'])\n",
    "Without_class_data_frame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Egypt</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>...</th>\n",
       "      <th>Semester_F</th>\n",
       "      <th>Semester_S</th>\n",
       "      <th>Relation_Father</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_No</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Bad</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Above-7</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_F  \\\n",
       "0           15                16                  2          20         0   \n",
       "1           20                20                  3          25         0   \n",
       "2           10                 7                  0          30         0   \n",
       "\n",
       "   gender_M  NationalITy_Egypt  NationalITy_Iran  NationalITy_Iraq  \\\n",
       "0         1                  0                 0                 0   \n",
       "1         1                  0                 0                 0   \n",
       "2         1                  0                 0                 0   \n",
       "\n",
       "   NationalITy_Jordan  ...  Semester_F  Semester_S  Relation_Father  \\\n",
       "0                   0  ...           1           0                1   \n",
       "1                   0  ...           1           0                1   \n",
       "2                   0  ...           1           0                1   \n",
       "\n",
       "   Relation_Mum  ParentAnsweringSurvey_No  ParentAnsweringSurvey_Yes  \\\n",
       "0             0                         0                          1   \n",
       "1             0                         0                          1   \n",
       "2             0                         1                          0   \n",
       "\n",
       "   ParentschoolSatisfaction_Bad  ParentschoolSatisfaction_Good  \\\n",
       "0                             0                              1   \n",
       "1                             0                              1   \n",
       "2                             1                              0   \n",
       "\n",
       "   StudentAbsenceDays_Above-7  StudentAbsenceDays_Under-7  \n",
       "0                           0                           1  \n",
       "1                           0                           1  \n",
       "2                           1                           0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummies\n",
    "Without_class_data_frame = pd.get_dummies(Without_class_data_frame)\n",
    "\n",
    "# data_frame head\n",
    "Without_class_data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class\n",
       "0     M\n",
       "1     M"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_data_frame = data_frame.drop(columns=['gender','NationalITy', 'PlaceofBirth','StageID','GradeID','SectionID','Topic','Semester','Relation','raisedhands','VisITedResources','AnnouncementsView','Discussion','ParentAnsweringSurvey','ParentschoolSatisfaction','StudentAbsenceDays'])\n",
    "Class_data_frame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'L', 'H'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_data_frame['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "\n",
    "# Encode labels in column 'species'. \n",
    "Class_data_frame['Class']= label_encoder.fit_transform(Class_data_frame['Class']) \n",
    "  \n",
    "Class_data_frame['Class'].unique() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>NationalITy_Egypt</th>\n",
       "      <th>NationalITy_Iran</th>\n",
       "      <th>NationalITy_Iraq</th>\n",
       "      <th>NationalITy_Jordan</th>\n",
       "      <th>...</th>\n",
       "      <th>Semester_S</th>\n",
       "      <th>Relation_Father</th>\n",
       "      <th>Relation_Mum</th>\n",
       "      <th>ParentAnsweringSurvey_No</th>\n",
       "      <th>ParentAnsweringSurvey_Yes</th>\n",
       "      <th>ParentschoolSatisfaction_Bad</th>\n",
       "      <th>ParentschoolSatisfaction_Good</th>\n",
       "      <th>StudentAbsenceDays_Above-7</th>\n",
       "      <th>StudentAbsenceDays_Under-7</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   raisedhands  VisITedResources  AnnouncementsView  Discussion  gender_F  \\\n",
       "0           15                16                  2          20         0   \n",
       "1           20                20                  3          25         0   \n",
       "\n",
       "   gender_M  NationalITy_Egypt  NationalITy_Iran  NationalITy_Iraq  \\\n",
       "0         1                  0                 0                 0   \n",
       "1         1                  0                 0                 0   \n",
       "\n",
       "   NationalITy_Jordan  ...  Semester_S  Relation_Father  Relation_Mum  \\\n",
       "0                   0  ...           0                1             0   \n",
       "1                   0  ...           0                1             0   \n",
       "\n",
       "   ParentAnsweringSurvey_No  ParentAnsweringSurvey_Yes  \\\n",
       "0                         0                          1   \n",
       "1                         0                          1   \n",
       "\n",
       "   ParentschoolSatisfaction_Bad  ParentschoolSatisfaction_Good  \\\n",
       "0                             0                              1   \n",
       "1                             0                              1   \n",
       "\n",
       "   StudentAbsenceDays_Above-7  StudentAbsenceDays_Under-7  Class  \n",
       "0                           0                           1      2  \n",
       "1                           0                           1      2  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_data_frame = pd.DataFrame(Class_data_frame['Class'])\n",
    "final_data_frame = pd.concat([Without_class_data_frame, Class_data_frame], axis = 1)\n",
    "final_data_frame.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_Iran\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_Iraq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_KW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_Lybia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_Morocco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_venzuela\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_Egypt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_Syria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_Tunis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"NationalITy_lebanon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_Iran\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_Iraq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_KuwaIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_Lybia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_Morocco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_venzuela\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_Egypt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_Syria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_Tunis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data_frame[\"PlaceofBirth_lebanon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specs</th>\n",
       "      <th>Chi2 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>VisITedResources</td>\n",
       "      <td>4700.833099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>raisedhands</td>\n",
       "      <td>4124.551198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AnnouncementsView</td>\n",
       "      <td>2618.905697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>809.349399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>StudentAbsenceDays_Above-7</td>\n",
       "      <td>135.592068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>StudentAbsenceDays_Under-7</td>\n",
       "      <td>89.612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>ParentAnsweringSurvey_No</td>\n",
       "      <td>53.642615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Relation_Mum</td>\n",
       "      <td>47.971767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>ParentAnsweringSurvey_Yes</td>\n",
       "      <td>41.722034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>ParentschoolSatisfaction_Bad</td>\n",
       "      <td>41.652289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Relation_Father</td>\n",
       "      <td>33.393774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>ParentschoolSatisfaction_Good</td>\n",
       "      <td>26.817227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>gender_F</td>\n",
       "      <td>21.176046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Topic_IT</td>\n",
       "      <td>12.695707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>gender_M</td>\n",
       "      <td>12.150190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Topic_Geology</td>\n",
       "      <td>11.781323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NationalITy_Palestine</td>\n",
       "      <td>10.183223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Topic_Biology</td>\n",
       "      <td>8.443757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>GradeID_G-05</td>\n",
       "      <td>8.338583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>GradeID_G-06</td>\n",
       "      <td>7.375718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PlaceofBirth_Palestine</td>\n",
       "      <td>5.808825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PlaceofBirth_Jordan</td>\n",
       "      <td>5.157282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>GradeID_G-02</td>\n",
       "      <td>4.463271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Semester_S</td>\n",
       "      <td>3.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>StageID_lowerlevel</td>\n",
       "      <td>3.971817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Semester_F</td>\n",
       "      <td>3.829349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NationalITy_SaudiArabia</td>\n",
       "      <td>3.715252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Topic_Chemistry</td>\n",
       "      <td>3.575569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>GradeID_G-09</td>\n",
       "      <td>3.035526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>StageID_MiddleSchool</td>\n",
       "      <td>2.891370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Topic_History</td>\n",
       "      <td>2.878063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>SectionID_C</td>\n",
       "      <td>2.794585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NationalITy_Jordan</td>\n",
       "      <td>2.219115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>GradeID_G-08</td>\n",
       "      <td>2.069249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>GradeID_G-11</td>\n",
       "      <td>1.898484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PlaceofBirth_SaudiArabia</td>\n",
       "      <td>1.686143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PlaceofBirth_USA</td>\n",
       "      <td>1.650042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Topic_English</td>\n",
       "      <td>1.487017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>SectionID_B</td>\n",
       "      <td>1.339082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>GradeID_G-12</td>\n",
       "      <td>1.275535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Topic_Science</td>\n",
       "      <td>1.256977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NationalITy_USA</td>\n",
       "      <td>1.216931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Topic_Spanish</td>\n",
       "      <td>1.159190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Topic_Quran</td>\n",
       "      <td>0.636065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Topic_Arabic</td>\n",
       "      <td>0.592839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Topic_Math</td>\n",
       "      <td>0.546638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>GradeID_G-04</td>\n",
       "      <td>0.401466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>SectionID_A</td>\n",
       "      <td>0.305741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>StageID_HighSchool</td>\n",
       "      <td>0.235777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Topic_French</td>\n",
       "      <td>0.120724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>GradeID_G-07</td>\n",
       "      <td>0.090467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>GradeID_G-10</td>\n",
       "      <td>0.064834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Specs  Chi2 Weights\n",
       "1                VisITedResources   4700.833099\n",
       "0                     raisedhands   4124.551198\n",
       "2               AnnouncementsView   2618.905697\n",
       "3                      Discussion    809.349399\n",
       "50     StudentAbsenceDays_Above-7    135.592068\n",
       "51     StudentAbsenceDays_Under-7     89.612751\n",
       "46       ParentAnsweringSurvey_No     53.642615\n",
       "45                   Relation_Mum     47.971767\n",
       "47      ParentAnsweringSurvey_Yes     41.722034\n",
       "48   ParentschoolSatisfaction_Bad     41.652289\n",
       "44                Relation_Father     33.393774\n",
       "49  ParentschoolSatisfaction_Good     26.817227\n",
       "4                        gender_F     21.176046\n",
       "37                       Topic_IT     12.695707\n",
       "5                        gender_M     12.150190\n",
       "35                  Topic_Geology     11.781323\n",
       "7           NationalITy_Palestine     10.183223\n",
       "31                  Topic_Biology      8.443757\n",
       "19                   GradeID_G-05      8.338583\n",
       "20                   GradeID_G-06      7.375718\n",
       "11         PlaceofBirth_Palestine      5.808825\n",
       "10            PlaceofBirth_Jordan      5.157282\n",
       "17                   GradeID_G-02      4.463271\n",
       "43                     Semester_S      3.992300\n",
       "16             StageID_lowerlevel      3.971817\n",
       "42                     Semester_F      3.829349\n",
       "8         NationalITy_SaudiArabia      3.715252\n",
       "32                Topic_Chemistry      3.575569\n",
       "23                   GradeID_G-09      3.035526\n",
       "15           StageID_MiddleSchool      2.891370\n",
       "36                  Topic_History      2.878063\n",
       "29                    SectionID_C      2.794585\n",
       "6              NationalITy_Jordan      2.219115\n",
       "22                   GradeID_G-08      2.069249\n",
       "25                   GradeID_G-11      1.898484\n",
       "12       PlaceofBirth_SaudiArabia      1.686143\n",
       "13               PlaceofBirth_USA      1.650042\n",
       "33                  Topic_English      1.487017\n",
       "28                    SectionID_B      1.339082\n",
       "26                   GradeID_G-12      1.275535\n",
       "40                  Topic_Science      1.256977\n",
       "9                 NationalITy_USA      1.216931\n",
       "41                  Topic_Spanish      1.159190\n",
       "39                    Topic_Quran      0.636065\n",
       "30                   Topic_Arabic      0.592839\n",
       "38                     Topic_Math      0.546638\n",
       "18                   GradeID_G-04      0.401466\n",
       "27                    SectionID_A      0.305741\n",
       "14             StageID_HighSchool      0.235777\n",
       "34                   Topic_French      0.120724\n",
       "21                   GradeID_G-07      0.090467\n",
       "24                   GradeID_G-10      0.064834\n",
       "52                          Class           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(53, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = final_data_frame.iloc[:,:-1]\n",
    "y = final_data_frame.iloc[:,-1:]   \n",
    "\n",
    "dfcolumns =pd.DataFrame(final_data_frame.columns) \n",
    "#chi2\n",
    "bestfeatures = SelectKBest(score_func=sklearn_chi2, k='all')\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Chi2 Weights']\n",
    "# print(featureScores.nlargest(len(data_frame.columns),'Score'))\n",
    "\n",
    "# featureScores.plot(kind='bar', subplots=True, figsize=(20,20))\n",
    "featureScores = featureScores.sort_values(by=['Chi2 Weights'], ascending=False)\n",
    "display(featureScores)\n",
    "display(featureScores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = ['raisedhands','VisITedResources','AnnouncementsView']\n",
    "                        \n",
    "predicted_class_name = ['Class']\n",
    "\n",
    "# Getting feature variable values\n",
    "X = final_data_frame[feature_column_names].values\n",
    "y = final_data_frame[predicted_class_name].values\n",
    "\n",
    "# Saving 30% for testing\n",
    "split_test_size = 0.30\n",
    "\n",
    "# Splitting using scikit-learn train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = split_test_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.00% in training set\n",
      "30.00% in test set\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(data_frame.index)) * 100))\n",
    "print(\"{0:0.2f}% in test set\".format((len(X_test)/len(data_frame.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raisedhands', 'VisITedResources', 'AnnouncementsView']\n",
      "Train on 336 samples\n",
      "Epoch 1/600\n",
      "336/336 [==============================] - 0s 391us/sample - loss: 1.0981 - accuracy: 0.4018\n",
      "Epoch 2/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 1.0937 - accuracy: 0.4256\n",
      "Epoch 3/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 1.0650 - accuracy: 0.4256\n",
      "Epoch 4/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.9838 - accuracy: 0.4256\n",
      "Epoch 5/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.9672 - accuracy: 0.4256\n",
      "Epoch 6/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.9591 - accuracy: 0.4256\n",
      "Epoch 7/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.9581 - accuracy: 0.4256\n",
      "Epoch 8/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.9439 - accuracy: 0.4256\n",
      "Epoch 9/600\n",
      "336/336 [==============================] - 0s 113us/sample - loss: 0.9403 - accuracy: 0.4256\n",
      "Epoch 10/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.9369 - accuracy: 0.4375\n",
      "Epoch 11/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.9275 - accuracy: 0.4613\n",
      "Epoch 12/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.9216 - accuracy: 0.4851\n",
      "Epoch 13/600\n",
      "336/336 [==============================] - 0s 113us/sample - loss: 0.9169 - accuracy: 0.4851\n",
      "Epoch 14/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.9092 - accuracy: 0.5268\n",
      "Epoch 15/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.8990 - accuracy: 0.5238\n",
      "Epoch 16/600\n",
      "336/336 [==============================] - 0s 140us/sample - loss: 0.8838 - accuracy: 0.5387\n",
      "Epoch 17/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.8749 - accuracy: 0.5625\n",
      "Epoch 18/600\n",
      "336/336 [==============================] - 0s 140us/sample - loss: 0.8590 - accuracy: 0.5923\n",
      "Epoch 19/600\n",
      "336/336 [==============================] - 0s 111us/sample - loss: 0.8364 - accuracy: 0.5744\n",
      "Epoch 20/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.8488 - accuracy: 0.5595\n",
      "Epoch 21/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.8460 - accuracy: 0.5387\n",
      "Epoch 22/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.8401 - accuracy: 0.5952\n",
      "Epoch 23/600\n",
      "336/336 [==============================] - 0s 205us/sample - loss: 0.8126 - accuracy: 0.5565\n",
      "Epoch 24/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.8333 - accuracy: 0.5804\n",
      "Epoch 25/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.8129 - accuracy: 0.5565\n",
      "Epoch 26/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7973 - accuracy: 0.5595\n",
      "Epoch 27/600\n",
      "336/336 [==============================] - 0s 113us/sample - loss: 0.7891 - accuracy: 0.5595\n",
      "Epoch 28/600\n",
      "336/336 [==============================] - 0s 186us/sample - loss: 0.7764 - accuracy: 0.5595\n",
      "Epoch 29/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7848 - accuracy: 0.5506\n",
      "Epoch 30/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7744 - accuracy: 0.5506\n",
      "Epoch 31/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.7691 - accuracy: 0.5476\n",
      "Epoch 32/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7959 - accuracy: 0.5506\n",
      "Epoch 33/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7706 - accuracy: 0.5476\n",
      "Epoch 34/600\n",
      "336/336 [==============================] - 0s 140us/sample - loss: 0.7566 - accuracy: 0.5625\n",
      "Epoch 35/600\n",
      "336/336 [==============================] - 0s 113us/sample - loss: 0.7523 - accuracy: 0.5655\n",
      "Epoch 36/600\n",
      "336/336 [==============================] - 0s 205us/sample - loss: 0.7556 - accuracy: 0.5565\n",
      "Epoch 37/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7704 - accuracy: 0.5595\n",
      "Epoch 38/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.7653 - accuracy: 0.5387\n",
      "Epoch 39/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7530 - accuracy: 0.5565\n",
      "Epoch 40/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.7446 - accuracy: 0.5506\n",
      "Epoch 41/600\n",
      "336/336 [==============================] - 0s 186us/sample - loss: 0.7440 - accuracy: 0.5565\n",
      "Epoch 42/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7455 - accuracy: 0.5506\n",
      "Epoch 43/600\n",
      "336/336 [==============================] - 0s 205us/sample - loss: 0.7398 - accuracy: 0.5536\n",
      "Epoch 44/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.7424 - accuracy: 0.5595\n",
      "Epoch 45/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7363 - accuracy: 0.5565\n",
      "Epoch 46/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7370 - accuracy: 0.5595\n",
      "Epoch 47/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7327 - accuracy: 0.5506\n",
      "Epoch 48/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.7325 - accuracy: 0.5595\n",
      "Epoch 49/600\n",
      "336/336 [==============================] - 0s 140us/sample - loss: 0.7336 - accuracy: 0.5565\n",
      "Epoch 50/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7554 - accuracy: 0.5744\n",
      "Epoch 51/600\n",
      "336/336 [==============================] - 0s 186us/sample - loss: 0.7363 - accuracy: 0.5685\n",
      "Epoch 52/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.7349 - accuracy: 0.5625\n",
      "Epoch 53/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7278 - accuracy: 0.5565\n",
      "Epoch 54/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7289 - accuracy: 0.5625\n",
      "Epoch 55/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.7307 - accuracy: 0.5565\n",
      "Epoch 56/600\n",
      "336/336 [==============================] - 0s 140us/sample - loss: 0.7302 - accuracy: 0.5625\n",
      "Epoch 57/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7374 - accuracy: 0.5595\n",
      "Epoch 58/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7231 - accuracy: 0.5536\n",
      "Epoch 59/600\n",
      "336/336 [==============================] - 0s 186us/sample - loss: 0.7203 - accuracy: 0.5685\n",
      "Epoch 60/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7171 - accuracy: 0.5655\n",
      "Epoch 61/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7158 - accuracy: 0.5685\n",
      "Epoch 62/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.7321 - accuracy: 0.5655\n",
      "Epoch 63/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7213 - accuracy: 0.5536\n",
      "Epoch 64/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.7164 - accuracy: 0.5595\n",
      "Epoch 65/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7177 - accuracy: 0.5565\n",
      "Epoch 66/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7219 - accuracy: 0.5714\n",
      "Epoch 67/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7188 - accuracy: 0.5536\n",
      "Epoch 68/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7137 - accuracy: 0.5536\n",
      "Epoch 69/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7231 - accuracy: 0.5565\n",
      "Epoch 70/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7270 - accuracy: 0.5625\n",
      "Epoch 71/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7116 - accuracy: 0.5536\n",
      "Epoch 72/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7107 - accuracy: 0.5655\n",
      "Epoch 73/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7078 - accuracy: 0.5685\n",
      "Epoch 74/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7140 - accuracy: 0.5595\n",
      "Epoch 75/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7101 - accuracy: 0.5685\n",
      "Epoch 76/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.7059 - accuracy: 0.5714\n",
      "Epoch 77/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7084 - accuracy: 0.5625\n",
      "Epoch 78/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7157 - accuracy: 0.5625\n",
      "Epoch 79/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.7129 - accuracy: 0.5744\n",
      "Epoch 80/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7289 - accuracy: 0.5625\n",
      "Epoch 81/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7146 - accuracy: 0.5744\n",
      "Epoch 82/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7098 - accuracy: 0.5655\n",
      "Epoch 83/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.7044 - accuracy: 0.5714\n",
      "Epoch 84/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7033 - accuracy: 0.5685\n",
      "Epoch 85/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6994 - accuracy: 0.5655\n",
      "Epoch 86/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.7096 - accuracy: 0.5595\n",
      "Epoch 87/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.7054 - accuracy: 0.5595\n",
      "Epoch 88/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.7093 - accuracy: 0.5655\n",
      "Epoch 89/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6993 - accuracy: 0.5714\n",
      "Epoch 90/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7020 - accuracy: 0.5714\n",
      "Epoch 91/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6991 - accuracy: 0.5714\n",
      "Epoch 92/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7104 - accuracy: 0.5685\n",
      "Epoch 93/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.7177 - accuracy: 0.5685\n",
      "Epoch 94/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7067 - accuracy: 0.5714\n",
      "Epoch 95/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6937 - accuracy: 0.5744\n",
      "Epoch 96/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.7006 - accuracy: 0.5625\n",
      "Epoch 97/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6975 - accuracy: 0.5685\n",
      "Epoch 98/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.7049 - accuracy: 0.5625\n",
      "Epoch 99/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7207 - accuracy: 0.5625\n",
      "Epoch 100/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.7000 - accuracy: 0.5655\n",
      "Epoch 101/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7054 - accuracy: 0.5714\n",
      "Epoch 102/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6989 - accuracy: 0.5625\n",
      "Epoch 103/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6944 - accuracy: 0.5685\n",
      "Epoch 104/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6919 - accuracy: 0.5714\n",
      "Epoch 105/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.7006 - accuracy: 0.5625\n",
      "Epoch 106/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6970 - accuracy: 0.5685\n",
      "Epoch 107/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6913 - accuracy: 0.5685\n",
      "Epoch 108/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6963 - accuracy: 0.5685\n",
      "Epoch 109/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6913 - accuracy: 0.5685\n",
      "Epoch 110/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.7030 - accuracy: 0.5625\n",
      "Epoch 111/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6958 - accuracy: 0.5595\n",
      "Epoch 112/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6908 - accuracy: 0.5685\n",
      "Epoch 113/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6886 - accuracy: 0.5744\n",
      "Epoch 114/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6860 - accuracy: 0.5685\n",
      "Epoch 115/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6870 - accuracy: 0.5714\n",
      "Epoch 116/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6903 - accuracy: 0.5744\n",
      "Epoch 117/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6839 - accuracy: 0.5774\n",
      "Epoch 118/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6900 - accuracy: 0.5655\n",
      "Epoch 119/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6896 - accuracy: 0.5714\n",
      "Epoch 120/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6850 - accuracy: 0.5625\n",
      "Epoch 121/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6841 - accuracy: 0.5685\n",
      "Epoch 122/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6785 - accuracy: 0.5744\n",
      "Epoch 123/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6863 - accuracy: 0.5774\n",
      "Epoch 124/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6870 - accuracy: 0.5655\n",
      "Epoch 125/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6919 - accuracy: 0.5655\n",
      "Epoch 126/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7029 - accuracy: 0.5714\n",
      "Epoch 127/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6908 - accuracy: 0.5774\n",
      "Epoch 128/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6879 - accuracy: 0.5655\n",
      "Epoch 129/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6787 - accuracy: 0.5833\n",
      "Epoch 130/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6796 - accuracy: 0.5714\n",
      "Epoch 131/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6819 - accuracy: 0.5685\n",
      "Epoch 132/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6801 - accuracy: 0.5714\n",
      "Epoch 133/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6798 - accuracy: 0.5625\n",
      "Epoch 134/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6771 - accuracy: 0.5714\n",
      "Epoch 135/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6735 - accuracy: 0.5744\n",
      "Epoch 136/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6803 - accuracy: 0.5744\n",
      "Epoch 137/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6850 - accuracy: 0.5744\n",
      "Epoch 138/600\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.66 - 0s 47us/sample - loss: 0.6936 - accuracy: 0.5744\n",
      "Epoch 139/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.7171 - accuracy: 0.5476\n",
      "Epoch 140/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6921 - accuracy: 0.5744\n",
      "Epoch 141/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6854 - accuracy: 0.5655\n",
      "Epoch 142/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6990 - accuracy: 0.5655\n",
      "Epoch 143/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6796 - accuracy: 0.5685\n",
      "Epoch 144/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6846 - accuracy: 0.5685\n",
      "Epoch 145/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6783 - accuracy: 0.5714\n",
      "Epoch 146/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6829 - accuracy: 0.5804\n",
      "Epoch 147/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6886 - accuracy: 0.5774\n",
      "Epoch 148/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.7207 - accuracy: 0.5833\n",
      "Epoch 149/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6796 - accuracy: 0.5863\n",
      "Epoch 150/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6786 - accuracy: 0.5714\n",
      "Epoch 151/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6784 - accuracy: 0.5744\n",
      "Epoch 152/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6729 - accuracy: 0.5863\n",
      "Epoch 153/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6686 - accuracy: 0.5774\n",
      "Epoch 154/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6723 - accuracy: 0.5804\n",
      "Epoch 155/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6745 - accuracy: 0.5685\n",
      "Epoch 156/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6907 - accuracy: 0.5774\n",
      "Epoch 157/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6822 - accuracy: 0.5744\n",
      "Epoch 158/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6904 - accuracy: 0.5744\n",
      "Epoch 159/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6831 - accuracy: 0.5804\n",
      "Epoch 160/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6876 - accuracy: 0.5774\n",
      "Epoch 161/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6685 - accuracy: 0.5774\n",
      "Epoch 162/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6717 - accuracy: 0.5774\n",
      "Epoch 163/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6704 - accuracy: 0.5863\n",
      "Epoch 164/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6735 - accuracy: 0.5833\n",
      "Epoch 165/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6926 - accuracy: 0.5774\n",
      "Epoch 166/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6966 - accuracy: 0.5804\n",
      "Epoch 167/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6851 - accuracy: 0.5774\n",
      "Epoch 168/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6970 - accuracy: 0.5685\n",
      "Epoch 169/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6880 - accuracy: 0.5685\n",
      "Epoch 170/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6761 - accuracy: 0.5774\n",
      "Epoch 171/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6713 - accuracy: 0.5833\n",
      "Epoch 172/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6687 - accuracy: 0.5804\n",
      "Epoch 173/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6693 - accuracy: 0.5804\n",
      "Epoch 174/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6666 - accuracy: 0.5893\n",
      "Epoch 175/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6695 - accuracy: 0.5685\n",
      "Epoch 176/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6653 - accuracy: 0.5833\n",
      "Epoch 177/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6639 - accuracy: 0.5893\n",
      "Epoch 178/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6618 - accuracy: 0.5804\n",
      "Epoch 179/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6584 - accuracy: 0.5893\n",
      "Epoch 180/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6525 - accuracy: 0.5923\n",
      "Epoch 181/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6492 - accuracy: 0.5863\n",
      "Epoch 182/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6626 - accuracy: 0.5833\n",
      "Epoch 183/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6560 - accuracy: 0.5952\n",
      "Epoch 184/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6484 - accuracy: 0.5893\n",
      "Epoch 185/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6473 - accuracy: 0.5923\n",
      "Epoch 186/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6501 - accuracy: 0.5952\n",
      "Epoch 187/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6483 - accuracy: 0.5952\n",
      "Epoch 188/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6472 - accuracy: 0.5952\n",
      "Epoch 189/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6534 - accuracy: 0.5893\n",
      "Epoch 190/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6349 - accuracy: 0.5923\n",
      "Epoch 191/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6454 - accuracy: 0.5923\n",
      "Epoch 192/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6444 - accuracy: 0.5923\n",
      "Epoch 193/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6495 - accuracy: 0.6012\n",
      "Epoch 194/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6525 - accuracy: 0.5863\n",
      "Epoch 195/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6435 - accuracy: 0.5952\n",
      "Epoch 196/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6458 - accuracy: 0.5893\n",
      "Epoch 197/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6502 - accuracy: 0.5893\n",
      "Epoch 198/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6379 - accuracy: 0.6042\n",
      "Epoch 199/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6377 - accuracy: 0.5952\n",
      "Epoch 200/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6376 - accuracy: 0.5982\n",
      "Epoch 201/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6466 - accuracy: 0.6012\n",
      "Epoch 202/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6647 - accuracy: 0.5923\n",
      "Epoch 203/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6815 - accuracy: 0.5863\n",
      "Epoch 204/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6590 - accuracy: 0.5923\n",
      "Epoch 205/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6463 - accuracy: 0.5982\n",
      "Epoch 206/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6379 - accuracy: 0.6012\n",
      "Epoch 207/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6508 - accuracy: 0.5923\n",
      "Epoch 208/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6542 - accuracy: 0.6042\n",
      "Epoch 209/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6348 - accuracy: 0.5982\n",
      "Epoch 210/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6533 - accuracy: 0.5833\n",
      "Epoch 211/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6343 - accuracy: 0.5982\n",
      "Epoch 212/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6282 - accuracy: 0.6012\n",
      "Epoch 213/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6313 - accuracy: 0.6012\n",
      "Epoch 214/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6376 - accuracy: 0.5893\n",
      "Epoch 215/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6847 - accuracy: 0.5804\n",
      "Epoch 216/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6428 - accuracy: 0.6012\n",
      "Epoch 217/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6446 - accuracy: 0.6042\n",
      "Epoch 218/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6359 - accuracy: 0.6042\n",
      "Epoch 219/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6369 - accuracy: 0.6012\n",
      "Epoch 220/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6363 - accuracy: 0.6012\n",
      "Epoch 221/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6212 - accuracy: 0.6042\n",
      "Epoch 222/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6563 - accuracy: 0.5923\n",
      "Epoch 223/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6539 - accuracy: 0.5952\n",
      "Epoch 224/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6736 - accuracy: 0.5863\n",
      "Epoch 225/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6598 - accuracy: 0.5893\n",
      "Epoch 226/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6481 - accuracy: 0.5982\n",
      "Epoch 227/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6374 - accuracy: 0.6071\n",
      "Epoch 228/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6220 - accuracy: 0.6071\n",
      "Epoch 229/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6265 - accuracy: 0.6071\n",
      "Epoch 230/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6229 - accuracy: 0.6042\n",
      "Epoch 231/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6407 - accuracy: 0.5982\n",
      "Epoch 232/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6446 - accuracy: 0.5982\n",
      "Epoch 233/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6298 - accuracy: 0.6012\n",
      "Epoch 234/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6224 - accuracy: 0.6101\n",
      "Epoch 235/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6152 - accuracy: 0.6131\n",
      "Epoch 236/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6155 - accuracy: 0.6012\n",
      "Epoch 237/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6121 - accuracy: 0.6161\n",
      "Epoch 238/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6233 - accuracy: 0.6161\n",
      "Epoch 239/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6084 - accuracy: 0.6101\n",
      "Epoch 240/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6076 - accuracy: 0.6101\n",
      "Epoch 241/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6077 - accuracy: 0.6190\n",
      "Epoch 242/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6174 - accuracy: 0.6101\n",
      "Epoch 243/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6454 - accuracy: 0.5952\n",
      "Epoch 244/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6296 - accuracy: 0.6071\n",
      "Epoch 245/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6289 - accuracy: 0.6071\n",
      "Epoch 246/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6305 - accuracy: 0.6042\n",
      "Epoch 247/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6204 - accuracy: 0.6071\n",
      "Epoch 248/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6168 - accuracy: 0.6042\n",
      "Epoch 249/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6203 - accuracy: 0.6071\n",
      "Epoch 250/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6152 - accuracy: 0.6042\n",
      "Epoch 251/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6129 - accuracy: 0.6131\n",
      "Epoch 252/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6229 - accuracy: 0.6071\n",
      "Epoch 253/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6220 - accuracy: 0.6071\n",
      "Epoch 254/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6115 - accuracy: 0.6071\n",
      "Epoch 255/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6046 - accuracy: 0.6161\n",
      "Epoch 256/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6404 - accuracy: 0.6131\n",
      "Epoch 257/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6611 - accuracy: 0.5952\n",
      "Epoch 258/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6376 - accuracy: 0.5923\n",
      "Epoch 259/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6321 - accuracy: 0.5893\n",
      "Epoch 260/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6630 - accuracy: 0.5893\n",
      "Epoch 261/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6618 - accuracy: 0.5774\n",
      "Epoch 262/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6573 - accuracy: 0.5893\n",
      "Epoch 263/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6215 - accuracy: 0.5982\n",
      "Epoch 264/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6134 - accuracy: 0.6071\n",
      "Epoch 265/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6098 - accuracy: 0.6161\n",
      "Epoch 266/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6058 - accuracy: 0.6161\n",
      "Epoch 267/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5997 - accuracy: 0.6161\n",
      "Epoch 268/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6239 - accuracy: 0.6042\n",
      "Epoch 269/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6619 - accuracy: 0.5952\n",
      "Epoch 270/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6336 - accuracy: 0.6042\n",
      "Epoch 271/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6273 - accuracy: 0.6071\n",
      "Epoch 272/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6135 - accuracy: 0.6071\n",
      "Epoch 273/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6117 - accuracy: 0.6101\n",
      "Epoch 274/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6055 - accuracy: 0.6071\n",
      "Epoch 275/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6102 - accuracy: 0.6131\n",
      "Epoch 276/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6031 - accuracy: 0.6190\n",
      "Epoch 277/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6220 - accuracy: 0.6101\n",
      "Epoch 278/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6280 - accuracy: 0.6071\n",
      "Epoch 279/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6139 - accuracy: 0.6190\n",
      "Epoch 280/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5988 - accuracy: 0.6220\n",
      "Epoch 281/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6118 - accuracy: 0.6131\n",
      "Epoch 282/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6016 - accuracy: 0.6131\n",
      "Epoch 283/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6055 - accuracy: 0.6131\n",
      "Epoch 284/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6126 - accuracy: 0.6101\n",
      "Epoch 285/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6144 - accuracy: 0.6012\n",
      "Epoch 286/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5965 - accuracy: 0.6131\n",
      "Epoch 287/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6028 - accuracy: 0.6131\n",
      "Epoch 288/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5996 - accuracy: 0.6161\n",
      "Epoch 289/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6618 - accuracy: 0.5923\n",
      "Epoch 290/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6537 - accuracy: 0.5833\n",
      "Epoch 291/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6431 - accuracy: 0.5893\n",
      "Epoch 292/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6247 - accuracy: 0.6012\n",
      "Epoch 293/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6183 - accuracy: 0.5952\n",
      "Epoch 294/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6266 - accuracy: 0.5923\n",
      "Epoch 295/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6101 - accuracy: 0.6101\n",
      "Epoch 296/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6035 - accuracy: 0.6131\n",
      "Epoch 297/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6137 - accuracy: 0.6101\n",
      "Epoch 298/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6103 - accuracy: 0.6071\n",
      "Epoch 299/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6065 - accuracy: 0.6101\n",
      "Epoch 300/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5953 - accuracy: 0.6161\n",
      "Epoch 301/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6013 - accuracy: 0.6161\n",
      "Epoch 302/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5972 - accuracy: 0.6131\n",
      "Epoch 303/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6314 - accuracy: 0.6131\n",
      "Epoch 304/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6091 - accuracy: 0.6042\n",
      "Epoch 305/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6765 - accuracy: 0.5952\n",
      "Epoch 306/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6734 - accuracy: 0.5863\n",
      "Epoch 307/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6592 - accuracy: 0.5923\n",
      "Epoch 308/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6233 - accuracy: 0.6071\n",
      "Epoch 309/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6242 - accuracy: 0.6071\n",
      "Epoch 310/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6089 - accuracy: 0.6042\n",
      "Epoch 311/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5982 - accuracy: 0.6101\n",
      "Epoch 312/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5997 - accuracy: 0.6101\n",
      "Epoch 313/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5940 - accuracy: 0.6190\n",
      "Epoch 314/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5926 - accuracy: 0.6071\n",
      "Epoch 315/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6008 - accuracy: 0.6161\n",
      "Epoch 316/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5900 - accuracy: 0.6161\n",
      "Epoch 317/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5873 - accuracy: 0.6190\n",
      "Epoch 318/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5858 - accuracy: 0.6220\n",
      "Epoch 319/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5808 - accuracy: 0.6220\n",
      "Epoch 320/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5818 - accuracy: 0.6220\n",
      "Epoch 321/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5889 - accuracy: 0.6220\n",
      "Epoch 322/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6005 - accuracy: 0.6101\n",
      "Epoch 323/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5975 - accuracy: 0.6190\n",
      "Epoch 324/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5946 - accuracy: 0.6190\n",
      "Epoch 325/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6395 - accuracy: 0.5952\n",
      "Epoch 326/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6425 - accuracy: 0.5982\n",
      "Epoch 327/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6240 - accuracy: 0.5982\n",
      "Epoch 328/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6082 - accuracy: 0.6012\n",
      "Epoch 329/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5966 - accuracy: 0.6101\n",
      "Epoch 330/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5889 - accuracy: 0.6161\n",
      "Epoch 331/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5935 - accuracy: 0.6190\n",
      "Epoch 332/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5980 - accuracy: 0.6101\n",
      "Epoch 333/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5930 - accuracy: 0.6101\n",
      "Epoch 334/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5932 - accuracy: 0.6190\n",
      "Epoch 335/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5979 - accuracy: 0.6131\n",
      "Epoch 336/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5865 - accuracy: 0.6131\n",
      "Epoch 337/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5887 - accuracy: 0.6190\n",
      "Epoch 338/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5813 - accuracy: 0.6220\n",
      "Epoch 339/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5871 - accuracy: 0.6131\n",
      "Epoch 340/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5813 - accuracy: 0.6190\n",
      "Epoch 341/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5797 - accuracy: 0.6220\n",
      "Epoch 342/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5771 - accuracy: 0.6250\n",
      "Epoch 343/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5893 - accuracy: 0.6131\n",
      "Epoch 344/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5762 - accuracy: 0.6250\n",
      "Epoch 345/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5862 - accuracy: 0.6190\n",
      "Epoch 346/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5860 - accuracy: 0.6071\n",
      "Epoch 347/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6039 - accuracy: 0.6161\n",
      "Epoch 348/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6044 - accuracy: 0.6042\n",
      "Epoch 349/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5896 - accuracy: 0.6161\n",
      "Epoch 350/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5909 - accuracy: 0.6131\n",
      "Epoch 351/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5882 - accuracy: 0.6131\n",
      "Epoch 352/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5925 - accuracy: 0.6131\n",
      "Epoch 353/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5818 - accuracy: 0.6161\n",
      "Epoch 354/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5801 - accuracy: 0.6250\n",
      "Epoch 355/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5670 - accuracy: 0.6190\n",
      "Epoch 356/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5846 - accuracy: 0.6131\n",
      "Epoch 357/600\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.64 - 0s 47us/sample - loss: 0.5742 - accuracy: 0.6190\n",
      "Epoch 358/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5773 - accuracy: 0.6131\n",
      "Epoch 359/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5911 - accuracy: 0.6161\n",
      "Epoch 360/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5827 - accuracy: 0.6101\n",
      "Epoch 361/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5663 - accuracy: 0.6220\n",
      "Epoch 362/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5665 - accuracy: 0.6220\n",
      "Epoch 363/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5652 - accuracy: 0.6250\n",
      "Epoch 364/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5702 - accuracy: 0.6280\n",
      "Epoch 365/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5621 - accuracy: 0.6190\n",
      "Epoch 366/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5581 - accuracy: 0.6250\n",
      "Epoch 367/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5638 - accuracy: 0.6250\n",
      "Epoch 368/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5726 - accuracy: 0.6101\n",
      "Epoch 369/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5647 - accuracy: 0.6220\n",
      "Epoch 370/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5947 - accuracy: 0.6042\n",
      "Epoch 371/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5969 - accuracy: 0.6071\n",
      "Epoch 372/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5880 - accuracy: 0.6131\n",
      "Epoch 373/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6324 - accuracy: 0.6042\n",
      "Epoch 374/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6101 - accuracy: 0.6131\n",
      "Epoch 375/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6290 - accuracy: 0.6071\n",
      "Epoch 376/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6813 - accuracy: 0.5774\n",
      "Epoch 377/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6554 - accuracy: 0.5714\n",
      "Epoch 378/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6073 - accuracy: 0.6012\n",
      "Epoch 379/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5937 - accuracy: 0.6131\n",
      "Epoch 380/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5865 - accuracy: 0.6101\n",
      "Epoch 381/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5776 - accuracy: 0.6161\n",
      "Epoch 382/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5857 - accuracy: 0.6161\n",
      "Epoch 383/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5631 - accuracy: 0.6220\n",
      "Epoch 384/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5604 - accuracy: 0.6220\n",
      "Epoch 385/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5515 - accuracy: 0.6280\n",
      "Epoch 386/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5887 - accuracy: 0.6131\n",
      "Epoch 387/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5748 - accuracy: 0.6190\n",
      "Epoch 388/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5715 - accuracy: 0.6220\n",
      "Epoch 389/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5632 - accuracy: 0.6131\n",
      "Epoch 390/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5643 - accuracy: 0.6250\n",
      "Epoch 391/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5582 - accuracy: 0.6280\n",
      "Epoch 392/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5703 - accuracy: 0.6220\n",
      "Epoch 393/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5773 - accuracy: 0.6190\n",
      "Epoch 394/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5650 - accuracy: 0.6220\n",
      "Epoch 395/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5948 - accuracy: 0.6190\n",
      "Epoch 396/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5962 - accuracy: 0.6131\n",
      "Epoch 397/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5839 - accuracy: 0.6161\n",
      "Epoch 398/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.6098 - accuracy: 0.6131\n",
      "Epoch 399/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5979 - accuracy: 0.6161\n",
      "Epoch 400/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5865 - accuracy: 0.6190\n",
      "Epoch 401/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5756 - accuracy: 0.6220\n",
      "Epoch 402/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5563 - accuracy: 0.6220\n",
      "Epoch 403/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5634 - accuracy: 0.6190\n",
      "Epoch 404/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5600 - accuracy: 0.6280\n",
      "Epoch 405/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5475 - accuracy: 0.6220\n",
      "Epoch 406/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5363 - accuracy: 0.6310\n",
      "Epoch 407/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5459 - accuracy: 0.6339\n",
      "Epoch 408/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5702 - accuracy: 0.6161\n",
      "Epoch 409/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5837 - accuracy: 0.6190\n",
      "Epoch 410/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5559 - accuracy: 0.6339\n",
      "Epoch 411/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5483 - accuracy: 0.6250\n",
      "Epoch 412/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5348 - accuracy: 0.6339\n",
      "Epoch 413/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5498 - accuracy: 0.6280\n",
      "Epoch 414/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5717 - accuracy: 0.6250\n",
      "Epoch 415/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5348 - accuracy: 0.6310\n",
      "Epoch 416/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5849 - accuracy: 0.6131\n",
      "Epoch 417/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5379 - accuracy: 0.6280\n",
      "Epoch 418/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5329 - accuracy: 0.6310\n",
      "Epoch 419/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5468 - accuracy: 0.6310\n",
      "Epoch 420/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5327 - accuracy: 0.6280\n",
      "Epoch 421/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5729 - accuracy: 0.6190\n",
      "Epoch 422/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5449 - accuracy: 0.6190\n",
      "Epoch 423/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5205 - accuracy: 0.6339\n",
      "Epoch 424/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5343 - accuracy: 0.6250\n",
      "Epoch 425/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5247 - accuracy: 0.6310\n",
      "Epoch 426/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5346 - accuracy: 0.6250\n",
      "Epoch 427/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5527 - accuracy: 0.6220\n",
      "Epoch 428/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6233 - accuracy: 0.6042\n",
      "Epoch 429/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6096 - accuracy: 0.5893\n",
      "Epoch 430/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.6274 - accuracy: 0.6131\n",
      "Epoch 431/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6373 - accuracy: 0.6131\n",
      "Epoch 432/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6028 - accuracy: 0.6161\n",
      "Epoch 433/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5854 - accuracy: 0.6101\n",
      "Epoch 434/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5722 - accuracy: 0.6161\n",
      "Epoch 435/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5753 - accuracy: 0.6071\n",
      "Epoch 436/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5725 - accuracy: 0.6161\n",
      "Epoch 437/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5750 - accuracy: 0.6131\n",
      "Epoch 438/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5519 - accuracy: 0.6190\n",
      "Epoch 439/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5308 - accuracy: 0.6310\n",
      "Epoch 440/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5289 - accuracy: 0.6310\n",
      "Epoch 441/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5238 - accuracy: 0.6369\n",
      "Epoch 442/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5125 - accuracy: 0.6339\n",
      "Epoch 443/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5181 - accuracy: 0.6369\n",
      "Epoch 444/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5303 - accuracy: 0.6310\n",
      "Epoch 445/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5100 - accuracy: 0.6339\n",
      "Epoch 446/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5190 - accuracy: 0.6339\n",
      "Epoch 447/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5137 - accuracy: 0.6369\n",
      "Epoch 448/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5155 - accuracy: 0.6369\n",
      "Epoch 449/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5192 - accuracy: 0.6339\n",
      "Epoch 450/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5130 - accuracy: 0.6310\n",
      "Epoch 451/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5095 - accuracy: 0.6369\n",
      "Epoch 452/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5043 - accuracy: 0.6369\n",
      "Epoch 453/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5127 - accuracy: 0.6369\n",
      "Epoch 454/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5032 - accuracy: 0.6369\n",
      "Epoch 455/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5066 - accuracy: 0.6369\n",
      "Epoch 456/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5092 - accuracy: 0.6369\n",
      "Epoch 457/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5160 - accuracy: 0.6369\n",
      "Epoch 458/600\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.59 - 0s 46us/sample - loss: 0.4937 - accuracy: 0.6369\n",
      "Epoch 459/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5012 - accuracy: 0.6339\n",
      "Epoch 460/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4912 - accuracy: 0.6458\n",
      "Epoch 461/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5071 - accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4946 - accuracy: 0.6458\n",
      "Epoch 463/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4898 - accuracy: 0.6458\n",
      "Epoch 464/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5026 - accuracy: 0.6250\n",
      "Epoch 465/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4903 - accuracy: 0.6429\n",
      "Epoch 466/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5221 - accuracy: 0.6280\n",
      "Epoch 467/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.6619 - accuracy: 0.5952\n",
      "Epoch 468/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6401 - accuracy: 0.5982\n",
      "Epoch 469/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5760 - accuracy: 0.6190\n",
      "Epoch 470/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5636 - accuracy: 0.6190\n",
      "Epoch 471/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.7418 - accuracy: 0.5774\n",
      "Epoch 472/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.6787 - accuracy: 0.6101\n",
      "Epoch 473/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.6157 - accuracy: 0.6190\n",
      "Epoch 474/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5680 - accuracy: 0.6310\n",
      "Epoch 475/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5474 - accuracy: 0.6280\n",
      "Epoch 476/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5339 - accuracy: 0.6250\n",
      "Epoch 477/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5217 - accuracy: 0.6280\n",
      "Epoch 478/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5030 - accuracy: 0.6399\n",
      "Epoch 479/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4959 - accuracy: 0.6399\n",
      "Epoch 480/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5029 - accuracy: 0.6399\n",
      "Epoch 481/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4919 - accuracy: 0.6458\n",
      "Epoch 482/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4892 - accuracy: 0.6458\n",
      "Epoch 483/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4761 - accuracy: 0.6458\n",
      "Epoch 484/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4775 - accuracy: 0.6458\n",
      "Epoch 485/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4711 - accuracy: 0.6458\n",
      "Epoch 486/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4765 - accuracy: 0.6488\n",
      "Epoch 487/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4757 - accuracy: 0.6488\n",
      "Epoch 488/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4768 - accuracy: 0.6429\n",
      "Epoch 489/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4851 - accuracy: 0.6339\n",
      "Epoch 490/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4877 - accuracy: 0.6399\n",
      "Epoch 491/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4787 - accuracy: 0.6399\n",
      "Epoch 492/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.5100 - accuracy: 0.6399\n",
      "Epoch 493/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5006 - accuracy: 0.6399\n",
      "Epoch 494/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5439 - accuracy: 0.6131\n",
      "Epoch 495/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5068 - accuracy: 0.6339\n",
      "Epoch 496/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4939 - accuracy: 0.6280\n",
      "Epoch 497/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5157 - accuracy: 0.6339\n",
      "Epoch 498/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5211 - accuracy: 0.6310\n",
      "Epoch 499/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4785 - accuracy: 0.6399\n",
      "Epoch 500/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4897 - accuracy: 0.6339\n",
      "Epoch 501/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4978 - accuracy: 0.6339\n",
      "Epoch 502/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4982 - accuracy: 0.6339\n",
      "Epoch 503/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5125 - accuracy: 0.6369\n",
      "Epoch 504/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4805 - accuracy: 0.6399\n",
      "Epoch 505/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4887 - accuracy: 0.6429\n",
      "Epoch 506/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4729 - accuracy: 0.6488\n",
      "Epoch 507/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4926 - accuracy: 0.6429\n",
      "Epoch 508/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4768 - accuracy: 0.6458\n",
      "Epoch 509/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4725 - accuracy: 0.6399\n",
      "Epoch 510/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4612 - accuracy: 0.6518\n",
      "Epoch 511/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4616 - accuracy: 0.6518\n",
      "Epoch 512/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4538 - accuracy: 0.6548\n",
      "Epoch 513/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4802 - accuracy: 0.6429\n",
      "Epoch 514/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4867 - accuracy: 0.6458\n",
      "Epoch 515/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5108 - accuracy: 0.6399\n",
      "Epoch 516/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4754 - accuracy: 0.6488\n",
      "Epoch 517/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4638 - accuracy: 0.6458\n",
      "Epoch 518/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4773 - accuracy: 0.6429\n",
      "Epoch 519/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4553 - accuracy: 0.6548\n",
      "Epoch 520/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4532 - accuracy: 0.6548\n",
      "Epoch 521/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.4518 - accuracy: 0.6577\n",
      "Epoch 522/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4536 - accuracy: 0.6548\n",
      "Epoch 523/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4386 - accuracy: 0.6577\n",
      "Epoch 524/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4519 - accuracy: 0.6429\n",
      "Epoch 525/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4481 - accuracy: 0.6548\n",
      "Epoch 526/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4720 - accuracy: 0.6369\n",
      "Epoch 527/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4875 - accuracy: 0.6310\n",
      "Epoch 528/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4923 - accuracy: 0.6399\n",
      "Epoch 529/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.4907 - accuracy: 0.6429\n",
      "Epoch 530/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4964 - accuracy: 0.6339\n",
      "Epoch 531/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.4828 - accuracy: 0.6429\n",
      "Epoch 532/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4745 - accuracy: 0.6429\n",
      "Epoch 533/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4849 - accuracy: 0.6429\n",
      "Epoch 534/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4681 - accuracy: 0.6518\n",
      "Epoch 535/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4851 - accuracy: 0.6518\n",
      "Epoch 536/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4746 - accuracy: 0.6458\n",
      "Epoch 537/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.4748 - accuracy: 0.6429\n",
      "Epoch 538/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5291 - accuracy: 0.6339\n",
      "Epoch 539/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5021 - accuracy: 0.6339\n",
      "Epoch 540/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5388 - accuracy: 0.6310\n",
      "Epoch 541/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5489 - accuracy: 0.6250\n",
      "Epoch 542/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.5115 - accuracy: 0.6369\n",
      "Epoch 543/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4902 - accuracy: 0.6310\n",
      "Epoch 544/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.4831 - accuracy: 0.6310\n",
      "Epoch 545/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5244 - accuracy: 0.6339\n",
      "Epoch 546/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5177 - accuracy: 0.6458\n",
      "Epoch 547/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5461 - accuracy: 0.6250\n",
      "Epoch 548/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5525 - accuracy: 0.6369\n",
      "Epoch 549/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5476 - accuracy: 0.6399\n",
      "Epoch 550/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.5418 - accuracy: 0.6488\n",
      "Epoch 551/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.4995 - accuracy: 0.6399\n",
      "Epoch 552/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5243 - accuracy: 0.6369\n",
      "Epoch 553/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.5109 - accuracy: 0.6458\n",
      "Epoch 554/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.5101 - accuracy: 0.6399\n",
      "Epoch 555/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.5294 - accuracy: 0.6339\n",
      "Epoch 556/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4975 - accuracy: 0.6280\n",
      "Epoch 557/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4907 - accuracy: 0.6399\n",
      "Epoch 558/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4884 - accuracy: 0.6458\n",
      "Epoch 559/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4643 - accuracy: 0.6488\n",
      "Epoch 560/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4538 - accuracy: 0.6548\n",
      "Epoch 561/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4754 - accuracy: 0.6488\n",
      "Epoch 562/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4539 - accuracy: 0.6518\n",
      "Epoch 563/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4526 - accuracy: 0.6458\n",
      "Epoch 564/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4414 - accuracy: 0.6518\n",
      "Epoch 565/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4342 - accuracy: 0.6518\n",
      "Epoch 566/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4418 - accuracy: 0.6488\n",
      "Epoch 567/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4527 - accuracy: 0.6518\n",
      "Epoch 568/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4368 - accuracy: 0.6518\n",
      "Epoch 569/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4345 - accuracy: 0.6518\n",
      "Epoch 570/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4468 - accuracy: 0.6548\n",
      "Epoch 571/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4784 - accuracy: 0.6458\n",
      "Epoch 572/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4647 - accuracy: 0.6458\n",
      "Epoch 573/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4774 - accuracy: 0.6458\n",
      "Epoch 574/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4582 - accuracy: 0.6518\n",
      "Epoch 575/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.4464 - accuracy: 0.6488\n",
      "Epoch 576/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4460 - accuracy: 0.6488\n",
      "Epoch 577/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4367 - accuracy: 0.6577\n",
      "Epoch 578/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4370 - accuracy: 0.6548\n",
      "Epoch 579/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4317 - accuracy: 0.6548\n",
      "Epoch 580/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4233 - accuracy: 0.6518\n",
      "Epoch 581/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4485 - accuracy: 0.6577\n",
      "Epoch 582/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.4229 - accuracy: 0.6607\n",
      "Epoch 583/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4234 - accuracy: 0.6548\n",
      "Epoch 584/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4337 - accuracy: 0.6548\n",
      "Epoch 585/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4503 - accuracy: 0.6458\n",
      "Epoch 586/600\n",
      "336/336 [==============================] - 0s 47us/sample - loss: 0.4963 - accuracy: 0.6310\n",
      "Epoch 587/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4813 - accuracy: 0.6429\n",
      "Epoch 588/600\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.66 - 0s 46us/sample - loss: 0.4458 - accuracy: 0.6458\n",
      "Epoch 589/600\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.69 - 0s 47us/sample - loss: 0.4561 - accuracy: 0.6548\n",
      "Epoch 590/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4263 - accuracy: 0.6577\n",
      "Epoch 591/600\n",
      "336/336 [==============================] - 0s 159us/sample - loss: 0.4335 - accuracy: 0.6548\n",
      "Epoch 592/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4250 - accuracy: 0.6637\n",
      "Epoch 593/600\n",
      "336/336 [==============================] - 0s 46us/sample - loss: 0.4269 - accuracy: 0.6548\n",
      "Epoch 594/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4377 - accuracy: 0.6548\n",
      "Epoch 595/600\n",
      "336/336 [==============================] - 0s 93us/sample - loss: 0.4358 - accuracy: 0.6607\n",
      "Epoch 596/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4283 - accuracy: 0.6518\n",
      "Epoch 597/600\n",
      "336/336 [==============================] - 0s 140us/sample - loss: 0.4349 - accuracy: 0.6696\n",
      "Epoch 598/600\n",
      "336/336 [==============================] - 0s 112us/sample - loss: 0.4329 - accuracy: 0.6607\n",
      "Epoch 599/600\n",
      "336/336 [==============================] - 0s 139us/sample - loss: 0.4595 - accuracy: 0.6548\n",
      "Epoch 600/600\n",
      "336/336 [==============================] - 0s 66us/sample - loss: 0.4393 - accuracy: 0.6548\n",
      "[0.03338906 0.0054262  0.784639  ]\n",
      "[5.2243471e-05 1.2716651e-04 9.9970996e-03]\n",
      "[9.9868351e-01 2.9802322e-08 1.0000000e+00]\n",
      "[3.6644936e-04 1.7929694e-01 9.6750867e-01]\n",
      "[0.952549   0.00688252 0.9999163 ]\n",
      "[2.5033951e-06 2.6945853e-01 9.1305798e-01]\n",
      "[0.         0.00058797 0.        ]\n",
      "[2.0861626e-07 6.0143518e-01 1.6860336e-01]\n",
      "[0.00176415 0.5666028  0.3443623 ]\n",
      "[0.44784075 0.15863323 0.95740986]\n",
      "[0.99978375 0.         1.        ]\n",
      "[0.9301207  0.00187358 0.99999493]\n",
      "[0.8909719  0.00826743 0.9999031 ]\n",
      "[0.00017989 0.02848908 0.11624599]\n",
      "[0.00786343 0.00263667 0.9998317 ]\n",
      "[3.0222771e-01 1.6987324e-06 1.0000000e+00]\n",
      "[0.011347   0.00162077 0.0375776 ]\n",
      "[0.26814848 0.01638165 0.9997134 ]\n",
      "[0.00125238 0.00122452 0.01377153]\n",
      "[0.01688135 0.08006784 0.276716  ]\n",
      "[0.13840532 0.29922754 0.76630014]\n",
      "[0.99999684 0.         1.        ]\n",
      "[5.6412220e-03 3.0949712e-04 9.9997395e-01]\n",
      "[0.92757577 0.00507718 0.9999573 ]\n",
      "[0.         0.25776446 0.        ]\n",
      "[0.         0.06404752 0.        ]\n",
      "[9.949673e-01 8.940697e-08 1.000000e+00]\n",
      "[9.3179613e-01 5.9604645e-08 1.0000000e+00]\n",
      "[5.0221384e-03 2.9331446e-04 9.9990278e-01]\n",
      "[1.3192594e-03 8.8393688e-05 3.0941176e-01]\n",
      "[9.9938190e-01 1.7881393e-07 1.0000000e+00]\n",
      "[0.         0.06153324 0.        ]\n",
      "[1.5109777e-05 3.3310026e-02 2.2351742e-06]\n",
      "[0.9999533 0.        1.       ]\n",
      "[0.02502689 0.06595841 0.98658943]\n",
      "[0.00393763 0.22791696 0.62028813]\n",
      "[5.0067902e-06 4.4992983e-02 6.2584877e-07]\n",
      "[9.8541379e-04 5.5465102e-04 9.9952644e-01]\n",
      "[0.536166   0.10635546 0.98270214]\n",
      "[1.0788441e-05 7.8754872e-02 9.9735039e-01]\n",
      "[2.0980835e-04 8.3889365e-02 9.9470538e-01]\n",
      "[9.9971741e-01 4.7683716e-07 1.0000000e+00]\n",
      "[0.         0.07112879 0.        ]\n",
      "[9.7811311e-01 5.6028366e-06 1.0000000e+00]\n",
      "[7.2410464e-02 1.6093254e-06 1.0000000e+00]\n",
      "[0.         0.01274514 0.        ]\n",
      "[0.6252482  0.05947891 0.9951637 ]\n",
      "[0.00537303 0.46596187 0.5556327 ]\n",
      "[9.9860525e-01 1.2189150e-05 1.0000000e+00]\n",
      "[2.3841858e-07 1.9238174e-02 0.0000000e+00]\n",
      "[9.9842483e-01 4.4703484e-07 1.0000000e+00]\n",
      "[9.8900688e-01 8.4763765e-04 9.9999690e-01]\n",
      "[0.         0.00028282 0.        ]\n",
      "[0.4721196  0.04584658 0.9977318 ]\n",
      "[0.00837579 0.00148022 0.9980743 ]\n",
      "[0.14001769 0.27459168 0.74671733]\n",
      "[0.0000000e+00 3.9219856e-05 7.3611736e-06]\n",
      "[9.8668748e-01 2.9802322e-07 1.0000000e+00]\n",
      "[8.6501813e-01 2.9802322e-08 1.0000000e+00]\n",
      "[0.         0.05888736 0.        ]\n",
      "[0.96286386 0.00418821 0.999966  ]\n",
      "[0.00050014 0.00195384 0.00239056]\n",
      "[0.        0.0309293 0.       ]\n",
      "[2.819695e-01 3.978908e-04 9.999998e-01]\n",
      "[0.0745807 0.5184345 0.3335677]\n",
      "[0.00132075 0.00334805 0.92173845]\n",
      "[2.4217367e-04 4.7158301e-03 2.9027462e-05]\n",
      "[9.8491019e-01 4.7683716e-07 1.0000000e+00]\n",
      "[0.         0.00343677 0.        ]\n",
      "[9.9916518e-01 7.4505806e-07 1.0000000e+00]\n",
      "[0.00727037 0.07902983 0.07518688]\n",
      "[9.993324e-01 8.940697e-08 1.000000e+00]\n",
      "[0.01755723 0.24242628 0.14149296]\n",
      "[4.215926e-01 1.308322e-04 1.000000e+00]\n",
      "[0.01697198 0.00175595 0.9999851 ]\n",
      "[1.1920929e-07 3.2941166e-01 5.9604645e-08]\n",
      "[0.21341687 0.00780451 0.99993503]\n",
      "[0.         0.00019568 0.        ]\n",
      "[0.         0.00050625 0.        ]\n",
      "[6.5864915e-01 8.9406967e-08 1.0000000e+00]\n",
      "[0.9999993 0.        1.       ]\n",
      "[5.6098402e-03 5.2329898e-04 9.9991894e-01]\n",
      "[5.8710575e-06 7.5765550e-03 8.4305459e-01]\n",
      "[0.9999984 0.        1.       ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67112434 0.00226736 0.9999952 ]\n",
      "[0.00562111 0.00389361 0.95288944]\n",
      "[0.99782395 0.         1.        ]\n",
      "[0.         0.00154397 0.        ]\n",
      "[0.         0.02086306 0.        ]\n",
      "[0.00844121 0.2106412  0.11602455]\n",
      "[9.9554932e-01 1.5854836e-05 1.0000000e+00]\n",
      "[9.9863780e-01 2.5779009e-05 1.0000000e+00]\n",
      "[0.47211435 0.00287974 0.9999922 ]\n",
      "[6.123394e-03 4.851818e-05 1.000000e+00]\n",
      "[2.9802322e-08 9.5888555e-01 5.4806471e-05]\n",
      "[0.96887076 0.00351483 0.99997884]\n",
      "[0.         0.22700143 0.        ]\n",
      "[0.51290184 0.0998081  0.98551047]\n",
      "[0.41623837 0.13876736 0.9724877 ]\n",
      "[7.0840120e-05 2.4620891e-03 1.5079975e-05]\n",
      "[0.4711252  0.01434276 0.9996324 ]\n",
      "[0.         0.14046237 0.        ]\n",
      "[0.       0.692396 0.      ]\n",
      "[0.9992985 0.        1.       ]\n",
      "[9.9645364e-01 5.9604645e-08 1.0000000e+00]\n",
      "[9.984535e-01 2.115965e-06 1.000000e+00]\n",
      "[0.70224863 0.01248473 0.9998381 ]\n",
      "[5.2183867e-05 4.7773123e-05 3.0147314e-02]\n",
      "[5.9513772e-01 6.1649084e-04 9.9999976e-01]\n",
      "[0.         0.01741552 0.        ]\n",
      "[0.         0.09219187 0.        ]\n",
      "[5.8848262e-03 4.2116642e-04 9.9999440e-01]\n",
      "[2.0861626e-07 5.0568193e-02 4.1723251e-07]\n",
      "[0.9999248 0.        1.       ]\n",
      "[0.9449531  0.00832996 0.99987423]\n",
      "[0.000000e+00 7.688999e-06 8.994341e-05]\n",
      "[6.7948908e-01 1.1742115e-05 1.0000000e+00]\n",
      "[0.01588327 0.00948343 0.99663234]\n",
      "[0.7603388  0.04544467 0.99668455]\n",
      "[0.         0.14047539 0.        ]\n",
      "[0.         0.02583727 0.7918157 ]\n",
      "[0.         0.01662442 0.        ]\n",
      "[9.9676061e-01 2.9802322e-07 1.0000000e+00]\n",
      "[1.6391277e-06 2.4445981e-02 9.9986386e-01]\n",
      "[0.000000e+00 9.712279e-01 8.249283e-05]\n",
      "[0.05366832 0.00957876 0.9991554 ]\n",
      "[0.         0.15782824 0.        ]\n",
      "[2.3841858e-07 6.0143477e-01 1.6860381e-01]\n",
      "[0.01327395 0.24473909 0.8953136 ]\n",
      "[0.02524135 0.005725   0.999918  ]\n",
      "[9.8147458e-01 4.3573976e-04 9.9999964e-01]\n",
      "[0.       0.014263 0.      ]\n",
      "[6.5545499e-02 3.0100346e-06 1.0000000e+00]\n",
      "[0.        0.1740951 0.       ]\n",
      "[5.9604645e-07 1.0864705e-02 3.3676624e-06]\n",
      "[0.0000000e+00 9.0152025e-05 0.0000000e+00]\n",
      "[1.1345446e-03 3.0446053e-04 9.9999994e-01]\n",
      "[3.8076371e-02 2.5668740e-04 9.9926287e-01]\n",
      "[0.88148177 0.         1.        ]\n",
      "[2.9802322e-08 9.4430447e-03 0.0000000e+00]\n",
      "[4.1932374e-02 5.6588650e-04 9.9906683e-01]\n",
      "[9.9971849e-01 3.2186508e-06 1.0000000e+00]\n",
      "[2.0861626e-07 6.0143518e-01 1.6860336e-01]\n",
      "[2.0406169e-01 2.8544664e-04 9.9953318e-01]\n",
      "Accuracy: 85.95079183578491%\n"
     ]
    }
   ],
   "source": [
    "  print(feature_column_names)\n",
    "  classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "  classifier.add(Dense(units = 76, kernel_initializer = 'uniform', activation = 'relu', input_dim = 3))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "  classifier.add(Dense(units = 62, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "  classifier.add(Dense(units = 56, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the fourth hidden layer\n",
    "  classifier.add(Dense(units = 52, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the fifth hidden layer\n",
    "  classifier.add(Dense(units = 46, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "  classifier.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "  classifier.compile(Adam(lr=.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "  classifier.fit(X_train, y_train, batch_size =42 , epochs = 600)\n",
    "  \n",
    "\n",
    "  # Predicting the Test set results\n",
    "  predictions = classifier.predict(X_test)\n",
    "  \n",
    "  for p in predictions:\n",
    "    print(p)\n",
    "\n",
    "  accuracy = (predictions[0][0]+predictions[1][1])/(predictions[0][0]+predictions[0][1]+predictions[1][0]+predictions[1][1])\n",
    "  acc = str(accuracy*100)\n",
    "  print(\"Accuracy: \"+ acc+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
